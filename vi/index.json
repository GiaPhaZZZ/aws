[{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.1-event1/","title":"Vietnam Cloud Day 2025","tags":[],"description":"","content":"Bài thu hoạch “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” Mục Đích Của Sự Kiện Nâng cao nhận thức về tầm quan trọng của AI Nêu bật sự ứng dụng của gen AI vào nhiều lĩnh vực trong cuộc sống Giới thiệu các dịch vụ Amazon Web Service mới Danh Sách Diễn Giả Eric Yeo - Country General Manager, Vietnam, Cambodia, Laos \u0026amp; Myanmar, AWS Dr. Jens Lottner - CEO, Techcombank Ms. Trang Phung - CEO \u0026amp; Co-Founder, U2U Network Jaime Valles - Vice President, General Manager Asia Pacific and Japan, AWS Nội Dung Nổi Bật Việt Nam lấy công nghệ số hóa và đám mây làm nền tảng phát triển trong cách mạng công nghiệp 4.0 Kết nối mở rộng hạ tầng điện toán đám mây và điện tử số. Tăng cường cấp phép các công ty và nhà đầu tư không giới hạn vào Việt Nam. Đảm bảo tính bảo mật và an toàn thông tin. U2U Network – Hạ tầng công nghệ kết hợp gen AI cho phép người dùng và hoạt động kinh doanh tiếp xúc với blockchain dễ dàng Sự kết hợp giữa công nghệ hiện có của công ty với Gen AI nhằm tạo nên sự thân thiện, dễ hiểu cho người dùng mới khi lần đầu tiếp xúc với công nghệ blockchain. Dẫn chứng một vài ví dụ về AI giúp định hình tương lai công nghệ trong nước và hướng phát triển của hãng:\n60% học sinh Việt Nam dùng edtech apps. Có hơn 765 start up về AI, đứng thứ hai trong Đông Nam Á. Giúp dịch vụ chăm sóc sức khỏe dễ tiếp cận với giá thành rẻ hơn, … bác sĩ ở bệnh viện 10A dùng ai khám giảm xuống còn 5 phút/ca. Kết họp sử dụng của gen AI giúp cho người dùng dễ ra quyết định hơn trong cuộc sống hằng ngày. Sự đầu tư trong giáo dục của AWS AWS đã thực hiện trainning cho hơn 100,000 builder tại Việt Nam. Giúp cho dịch vụ và công nghệ đám mây trở nên dễ tiếp cận hơn trong nội địa. Tổ chức First Cloud Journey kéo dài 6 tháng, đảm bảo cơ hội việc làm. Văn hóa của AWS là yếu tố khác biệt quan trọng tạo nên điểm nhấn. Sự quan trọng của chuyển giao công nghệ AI Thời điểm hiện tại đang là khoảng khắc độc nhất trong lịch sử mà AI sẽ biến đổi tất cả mọi thứ. Không chỉ gói gọn trong công nghệ, mà còn bao gồm kỹ năng, con người, văn hóa, xã hội, … giúp cho tất cả hướng theo con đường học mãi (continue learning) Sử dụng các mô hình theo hướng an toàn và có trách nhiệm. Chuyển từ ‘training mode sang interference. AWS cung cấp dịch vụ để tiếp cận với các mô hình mới này. Ví dụ như Nearmap giúp khách hàng tập trung vào đưa ra quyết định/suy nghĩ/sáng tạo và để các công việc nhàm chán cho máy móc giải quyết. AWS SageMaker Dịch vụ hỗ trợ developers và data scientist xây dựng, huấn luyện và triển khai các mô hình học máy ở nhiều quy mô lên nền tảng cloud mà không cần lo lắng về các cơ sở hạ tầng. Sở hưu nhiều tính năng tiện tích như:\nData Preparation: Sở hữu các công cụ giúp làm sạch, đánh thứ tự, biến đổi cơ sở dữ liệu của khách hàng. Model Building and Training: Có sẵn Jupyter notebooks và hỗ trợ cho các frameworks như Tensorflow, Pytorch, … **Deployment **: Hỗ trợ triển khai lên cloud và kết nối với các dịch vụ khách của AWS AI Driven Development life cycle. Vibe coding làm AI đảm nhận mọi nhiệm vụ, khi gặp lỗi sửa sẽ rất khó, thiếu tính giải thích cho các mô hình. Phương thức truyền thông lại chỉ dùng AI để làm việc ngoài lề, không tận dụng được tối đa khả năng của AI.\nADD life cycle là quy trình giao nhiều việc cho AI, tuy nhiên vẫn đảm nhận chức vụ điều khiển chính. Các thao tác như confirm, clarify, review, … đều sẽ do con người thực hiện. Tổng thể bao gồm ba bước chính:\nInception: Lên ý tưởng, xác định các việc cần làm, … Contruction: Domain model, dùng AI tạo code, kiểm nghiệm, … Operation: Triển khai hoàn chỉnh, quản lý các incidents, tiếp tục phát triển lâu dài, … Bảo mật cho AI Applications Bàn về việc các mô hình thường thiếu an toàn và dễ sinh ra ảo tưởng, tự tin thái quá vào câu trả lời đưa ra không có thật. Chính vì thế các cần chính sách đê tăng cường độ bảo mật, an toàn và đáng tin cậy cho mô hình AI\nThực hiện các chính sách về AI Phân tích nguyên nhân dẫn tới Hallucination của AI Data Poisoning Bảo mật Prompt Kiểm soát truy cập và phân quyền Những Gì Học Được Tư Duy Làm Việc Problem Understandng: Tìm hiểu vấn đề và yêu cầu của khách hàng trước nhất. Choosing Plans: Lên kế hoạch phát triển cho dự án, lựa chọn các công cụ và dịch vụ phù hợp. Data Preparation: Bỏ ra một khoảng thời gian để hiểu và chuẩn bị dữ liệu, sao cho nó đồng nhất và tốt nhất để sau này không cần quay lại thực hiện. Áp Dụng Kỹ Thuật Mới Amazon Web Service: Thử tận dụng các dịch vụ và lợi ích của công nghệ đám mây để góp phần tạo nên sản phẩm tốt nhất. New Technology: Tìm hiểu và xem thêm các nghiên cứu, kỹ thuật mới nhất để có thể bắt kịp với công nghệ thời đại liên tục đổi mới. Chiến Lược Kết Hợp Với AI AI in work: Không để cho AI làm hết mọi thứ mà cũng không tự mình làm hết. Phải có sự kết hợp của cả hai để tối ưu hóa hiệu suất và khả năng mà AI mang lại. Từ đó giảm thiểu thời gian và chi phí để thực hiện hoàn thiện một công việc nào đó. Increase Sercurity: Tăng cường tính bảo mật, giảm thiểu các rủi ro cho dự án và đồng thời tăng khả năng của AI để tránh sinh ra rò rỉ, ảo tưởng dữ liệu trong quá trình training. Ứng Dụng Vào Công Việc Áp dụng AWS SageMaker dùng để xây dựng các mô hình học máy cho các dự án sắp tới. Tận dụng nhằm kết hợp với công nghệ cloud cho ra kết quả tốt hơn. Amazon Q: Dùng cho dashboard dễ dàng, nhìn dữ liệu tổng quát và thân thiện hơn. Ứng dụng quy trình AI Driven Developemnt life-cycle: Thực hiện theo ba bước từ Inception – Contructions – Operation với sự tận dụng tối đa của AI. Sử dụng Gen AI: Kết hợp sự hiện đại của gen AI cho các việc tìm hiểu và nghiên cứu đề tài trước và trong khi thực hiện dự án. Trải nghiệm trong event Tham gia sự kiện “Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders” là trong những trải nghiệm khó quên và ấn tượng nhất. Mỗi năm AWS chỉ tổ chức Cloud day một lần và dịp này tôi đã may mắn tham gia được. Không chỉ ngồi nghe các diễn giả giới thiệu về công nghệ mới mà còn đồng thời nhận thức được tầm quan trọng của việc ứng dụng AI và công nghệ đám mây vào công việc để góp phần tạo nên các sản phẩm tốt hơn, mới hơn, đáp ứng được nhu cầu của nhiều người dùng hơn. Sau đây là một vài trải nghiệm đáng chú ý:\nTiếp thu kiến thức từ các diễn giả nổi tiếng, có trình độ chuyên môn cao Nhiều kiến thức về Gen AI và tầm quan trọng của nó trong việc định hình tương lai công nghệ đã được chia sẽ bởi các diễn giả và những đại diện tập đoàn công nghệ lớn.\nQua nhiều ví dụ thực tế và giải thích, tôi hiểu rõ hơn cách áp dụng AI-Driven Development Lifecycle (AI-DLC) và Securing Generative AI Applications with AWS vào các dự án lớn.\nTrải nghiệm kỹ thuật thực tế Tham gia các phiên trình bày về U2U Network giúp tôi hiểu ra hơn cách họ đưa gen AI vào để cho các khách hàng mới dễ tiếp cận được hơn với công nghệ blockchain và ảnh hưởng đến việc ra quyết định. Học cách tăng cường bảo mật và độ tin cậy cho các mô hình machine learning nhằm tránh hiện tưởng rò rỉ bảo mật hoặc sinh ra câu trả lời ảo tưởng. Hiểu rõ phương pháp và chiến lược nhằm vận dụng được tối đa sức mạnh của AI trong việc xây dựng một dự án. Ứng dụng công cụ hiện đại Trực tiếp tìm hiểu về Amazon Sagemaker, dịch vụ trợ các developers và data scientists xây dựng, huấn luyện và triển khai mô hình học máy. Học cách sử dụng Amazon Q cho việc tạo dashboard, trực quan hóa dữ liệu trở nên thân thiện và dễ dàng hơn. Kết nối và trao đổi Sự kiện còn tổ chức buổi trao đổi, thảo luận giữa các chuyên gia và CEO của những tập đoàn lớn để bàn về định hướng cách mạng GenAI và chiến lược để lãnh đạo điều hành. Mang đến các nhìn tổng quan về việc xu hướng phát triễn hiện nay của ngành công nghệ là như thế nào. Nhờ đó, tôi biết được cách để tiếp cận và sử dụng hiệu quả AI hơn , thay vì để cho AI toàn quyển kiểm soát hoặc chỉ tham gia trong những công việc ngoài lề. Tối đa hóa sức mạnh của AI để hỗ trợ cho công việc. Bài học rút ra Việc áp dụng AI-DLC vào chiến lược phát triển dự án giúp tăng cao hiệu suất làm việc, đồng thời tiết kiệm được nhiều thời gian và chi phí phải bỏ ra. Sử dụng Gen AI cho các hoạt động nghiên cứu và học hỏi kiến thức mới là vô cùng hiệu quả. Không chỉ đỡ công sức tìm kiếm tài liệu mà còn giúp người dùng đưa ra các quyết định tốt hơn. Vận dụng các công cụ như Amazon Q, SageMaker để có thể boost productivity khi được tích hợp vào các dự án sắp tới. Một số hình ảnh khi tham gia sự kiện Hình 1 Hình 2 Hình 3 Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp tôi thay đổi cách tư duy về thiết kế ứng dụng, hiện đại hóa hệ thống và phối hợp hiệu quả hơn giữa các team.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.1-week1/","title":"Worklog Tuần 1","tags":[],"description":"","content":"1. Mục tiêu tuần 1: Giao lưu và làm quen với các thành viên khác cùng tham gia FJC. Tìm hiểu về AWS và các dịch vụ được cung cấp. Mở tài khoản và có khả năng thao tác các tính năng cơ bản. 2. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tiến hành tìm hiểu chuyên sâu về AWS và các dịch vụ hiện có: + Tạo tài khoản AWS đầu tiên + Thiết lập MFA + Thực hành thao tác với AWS management console + Tìm hiểu về các phương thức support 08.09.2025 08.09.2025 https://000001.awsstudygroup.com/ 3 - Đọc và nghiên cứu nội quy của FJC AWS. + Gia nhập nhóm Facebook FJC và xem thêm các tài liệu về workshop của chương trình. + Đến văn phòng AWS trực buổi đầu. + Gặp gỡ, làm quen và lập nhóm. + Thực hiện buổi họp online đầu tiên, giao lưu thành viên, bầu nhóm trưởng. 09.09.2025 09.09.2025 https://policies.fcjuni.com/ 4 - Tìm hiểu về quản lý chi phí và các kiến thức khác: + Hiểu và sử dụng Billing and Cost Management + Thử nghiệm tạo group, user, policy, role với IAM 10.09.2025 10.09.2025 https://000007.awsstudygroup.com/ 5 - Khám phá dịch vụ Amazon Virtual Private Cloud (VPC) và thực hành thử nghiệm với nó. 11.09.2025 11.09.2025 https://000003.awsstudygroup.com/ 6 - Dịch bài log \u0026ldquo;Exploring Quantum Measurements, Observables and Operators: Practical insights with Amazon Braket\u0026rdquo; từ tiếng Anh sang tiếng Việt 12.09.2025 12.09.2025 https://aws.amazon.com/blogs/quantum-computing/exploring-quantum-measurements-observables-and-operators-practical-insights-with-amazon-braket/ 3. Kết quả đạt được tuần 1: A - Tạo thành công tài khoản AWS đầu tiên\nLiên kết mail, xác minh tài khoản, thêm visa làm phương thức trả phí.\nQuản lý đăng nhập IAM\nThử nghiệm tạo, xóa, chỉnh sửa Account Alias.\nHoàn tất thiết lập MFA\nSử dụng mật khẩu của thiết bị local cho MFA Cho phép hoạt động U2F security key Tạo Admin Group và Admin User sử dụng các chính sách đã thiết lập sẵn.\nTạo thử support case cho mục đích thử nghiệm.\nThử nghiệm sử dụng AWS management consule:\nChuyển đổi sang Region Singapore gần khu vực Thử tìm kiếm các dịch vụ hiện có của AWS (EC2, Cloud9, Sercurity Lake, …) cùng các tài liệu và blogs khác. Thêm/Loại bỏ service trong danh sách yêu thích Thêm/Bớt widgets vào console home B - Tính toán chi phí và kiến thức thêm\nSử dụng dịch vụ Billing and cost management tạo Buget và dùng theo template monthly cost budget.\nHiểu về quản lý các loại chi phí (bao gồm cost, usage, R, … )\nHoàn tất tìm hiểu về các gói package hỗ trợ của AWS:\nBasic Developer Bussiness Enterprise Tìm hiểu chuyên sâu về AWS Identity and Access Management (IAM)\nBiết về các khái niệm và cách vận hàng của IAM Group, User, Policy, Role, … Tiến hành tạo Group và các User Thử nghiệm đổi vai trò của User được tạo. C - Amazon Virtual Private Cloud (VPC)\nHoàn thành tìm hiểu các khái niệm về Amazon Virtual Private Cloud (VPC)\nSubnets Route Table Internet Gateway NAT Gateway Tạo thử VPC để test.\nThêm subnets, gateway, route table, sercurity group vào VPC đã tạo để hoàn chỉnh bản thử nghiệm.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Khám Phá Quantum Measurements, Observables và Operators: Góc nhìn thực tiễn với Amazon Braket Sudarsan Srinivasan và Charunethran Panchalam Govindarajan | 12 THÁNG 9 2025 | Amazon Braket, Quantum Technologies |\nGiới Thiệu Trong bài viết này, chúng ta sẽ lần lượt khai mở nền tảng toán học và ứng dụng thực tế của các kỹ thuật quantum measurement bằng Amazon Braket. Cùng nhau xem xét đề tài qua nhiều góc nhìn, chẳng hạn: dùng action of gates như một basis transformation, projection như inner product, projector formalism và observable formalism. Điểm quan trọng mà chúng ta đang muốn hướng đến đó là hiểu được basis transformations như một công cụ cho việc chuyển đổi phase information thành amplitude information – khái niệm trọng tâm của nhiều thuật toán lượng tử.\nMục tiêu của bài viết này là cung cấp cái nhìn trực quan cùng các ý tưởng có thể triển khai cho những ai đang muốn tìm tòi học hỏi nhằm hiểu rõ hơn về các kỹ thuật quantum measurement.\nSuperposition và Measurement trong Arbitrary Basis Một one-qubit state tổng quát có thể được viết dưới dạng tổng hợp trong cơ sở tính toán { |0⟩, |1⟩ }:\n$$ |ψ⟩ = α_0|0⟩ + α_1|1⟩ $$\ntrong đó α₀ và α₁ là các biên độ xác suất thỏa mãn:\n$$ |α_0|^2 + |α_1|^2 = 1 $$\nCác biên độ này đo lường độ projection (hoặc độ trùng lặp) của trạng thái lên các basis vectors.\nQuantum measurement xác định mức độ projection của trạng thái lên cơ sở đo lường. Giờ hãy cùng xem xét việc đo lường trạng thái này trong một orthonormal basis khác { |u_0⟩, |u_1⟩ }. Để biểu diễn trạng thái trong arbitrary basis này dưới dạng:\n$$ |ψ⟩ = β_0|u_0⟩ + β_1|u_1⟩ $$\nchúng ta cần tìm các hệ số β₀ và β₁.\nXem xét ma trận đơn vị U với { |u_0⟩, |u_1⟩ } là các cột:\n$$ U = [|u_0⟩ \\ |u_1⟩] $$\nĐể tìm β₀ và β₁ trong:\n$$ |ψ⟩ = β_0|u_0⟩ + β_1|u_1⟩, $$\nchúng ta biểu diễn các basis vectors mới theo cơ sở tính toán. Lưu ý rằng:\n$$ U|0⟩ = |u_0⟩, \\quad U|1⟩ = |u_1⟩ $$\nKhi đó:\n$$ |ψ⟩ = β_0U|0⟩ + β_1U|1⟩ = U(β_0|0⟩ + β_1|1⟩) $$\nVì U là phép biến đổi đơn vị, áp dụng U† cho cả hai bên cho kết quả:\n$$ U†|ψ⟩ = β_0|0⟩ + β_1|1⟩ $$\nCác hệ số β₀ và β₁ là các projection của U†|ψ⟩ lên các trạng thái cơ sở tính toán. Do đó, đo U†|ψ⟩ trong cơ sở tính toán cho kết quả tương tự như đo trạng thái ban đầu |ψ⟩ trong cơ sở { |u_0⟩, |u_1⟩ }.\nNguyên lý này mở rộng tự nhiên cho n-qubit system. Hệ thống n-qubit tồn tại trong không gian Hilbert có chiều N = 2^n (với 2^n basis vectors). Trong cơ sở tính toán, 2^n basis vectors này được biểu diễn bằng các chuỗi nhị phân từ 0 đến 2^(n - 1): |00…0⟩, |00…1⟩, …, |11…1⟩.\nMột trạng thái tổng quát |ψ⟩ có thể được biểu diễn trong cơ sở tính toán dưới dạng:\n$$ |ψ⟩ = α_0|00…0⟩ + α_1|00…1⟩ + … + α_{N-1}|11…1⟩ = \\sum_k α_k|k⟩ $$\ntrong đó 0 ≤ k ≤ 2^n - 1 và:\n$$ \\sum_k |α_k|^2 = 1 $$\nGiả sử bây giờ chúng ta muốn đo trạng thái này trong bất kỳ arbitrary orthonormal basis nào { |u_0⟩, |u_1⟩, …, |u_k⟩, …, |u_{N-1}⟩ }. Khi đo |ψ⟩ trong basis này, chúng ta thực chất đang hỏi: “Xác suất tìm thấy hệ thống ở trạng thái |u_k⟩ là bao nhiêu?”\nTrạng thái |ψ⟩ có thể được biểu diễn trong basis này như sau:\n$$ |ψ⟩ = β_0|u_0⟩ + β_1|u_1⟩ + … + β_{N-1}|u_{N-1}⟩ $$\ntrong đó β_k = ⟨u_k|ψ⟩ là biên độ của trạng thái được chiếu lên cơ sở |u_k⟩.\nNhư trước đây, nếu U là ma trận đơn vị có các cột là { |u_0⟩, |u_1⟩, …, |u_{N-1}⟩ }, thì:\n$$ U†|ψ⟩ = \\sum_k β_k|k⟩ = β_0|00…0⟩ + β_1|00…1⟩ + … + β_{N-1}|11…1⟩ $$\nĐo trạng thái |ψ⟩ trong basis { |u_k⟩ } tương đương với áp dụng U† lên trạng thái và đo trong cơ sở tính toán.\nNgược lại, giả sử V là bất kỳ phép toán đơn vị (quantum gate) nào. Khi áp dụng cổng V lên trạng thái |ψ⟩ và đo kết quả V|ψ⟩ trong cơ sở tính toán, điều này tương đương với việc đo trạng thái ban đầu |ψ⟩ trong basis được hình thành bởi các cột của V†.\nĐây là một nguyên lý quan trọng của quantum measurement. Các thiết bị vật lý cho phép thực hiện phép đo trong Z basis (cơ sở tính toán). Khái niệm về phép đo trong một cơ sở khác được thực hiện thông qua một biến đổi đơn vị tương đương.\nHãy cùng suy ngẫm điều này qua ví dụ. Trong sơ đồ sau (hình 1), trạng thái lượng tử của một qubit duy nhất |\\ψ⟩ được biểu diễn trong không gian vectơ 2D thực (với các biên độ xác suất là số thực).\nHình 1: Biểu diễn trạng thái theo các basis khác nhau trên mặt phẳng 2D thực. |0⟩ và |1⟩ đại diện cho cơ sở tính toán, trong khi |u_0⟩ và |u_1⟩ đại diện cho bất kỳ arbitrary basis nào. |\\ψ⟩ đại diện cho trạng thái của một qubit duy nhất. Các phép chiếu của trạng thái lên mỗi basis vectors là inner products của trạng thái đó với các basis vectors tương ứng..\nXem xét vectơ trạng thái |\\ψ⟩ được định hướng ở góc π/6 (30°) từ |0⟩. Sau đó, trạng thái có thể được biểu diễn trong cơ sở tính toán như sau:\n$$ |\\psi⟩ = \\cos(\\pi/6)|0⟩ + \\sin(\\pi/6)|1⟩ = \\frac{\\sqrt{3}}{2}|0⟩ + \\frac{1}{2}|1⟩ $$\nTrong cơ sở tính toán { |0⟩, |1⟩ }:\nXác suất đo được |0⟩: ( | cos(π/6)|^2 = 3/4 = 75% ) Xác suất đo được |1⟩: ( | sin(π/6)|^2 = 1/4 = 25% ) Giờ hãy xem xét việc đo trạng thái này trong một arbitrary orthonormal basis { |u_0⟩, |u_1⟩ } nằm ở góc π/8 (22,5°) so với cơ sở tính toán { |0⟩, |1⟩ }:\n$$ |u_0⟩ = \\cos(\\pi/8)|0⟩ + \\sin(\\pi/8)|1⟩ $$\n$$ |u_1⟩ = -\\sin(\\pi/8)|0⟩ + \\cos(\\pi/8)|1⟩ $$\nKết quả đo lường sẽ phụ thuộc vào phép chiếu của trạng thái |\\ψ⟩ lên các basis vectors này.\nNhư đã phân tích, chúng ta có thể thấy rằng:\n$$ |\\psi⟩ = \\cos(\\pi/24)|u_0⟩ + \\sin(\\pi/24)|u_1⟩ $$\nTrong arbitrary orthonormal basis { |u_0⟩, |u_1⟩ }:\nXác suất đo được |u_0⟩: ( | cos(π/24)|^2 ~ 0.983 = 98.3% ) Xác suất đo được |u_1⟩: ( | sin(π/24)|^2 ~ 0.017 = 1.7% ) Ghi chú về biểu diễn trên Bloch Sphere Trên Bloch Sphere, các thông số góc là gấp đôi các góc vật lý trong không gian trạng thái. Một phép quay với góc θ trong không gian trạng thái tương ứng với phép quay với góc 2θ trên Bloch Sphere. Điều này liên quan đến nhóm SU(2) là một lớp phủ kép của SO(3) (xem các tài liệu tham khảo để biết chi tiết).\nHãy xem điều này bằng cách sử dụng Amazon Braket.\nNhư được thể hiện trong đoạn code dưới đây, trước tiên, chúng ta tạo một instance của Local Simulator và một Circuit. Amazon Braket khởi tạo các qubit trong trạng thái |0⟩ (hướng theo trục Z của Bloch Sphere). Sau đó, chúng ta xoay trạng thái với góc 30° (π/6) theo trục Y. Lưu ý rằng một vòng xoay vật lý (π/6) tương ứng với một vòng xoay (π/3) trên hình Bloch Sphere.\nTrạng thái qubit nằm trong mặt phẳng XZ của Bloch Sphere. Điều này tương ứng với biểu diễn trong Hình 1.\nChúng ta tạo ra hai vectơ u_0 và u_1 để biểu thị cơ sở đo lường mà chúng ta quan tâm. Dễ dàng nhận thấy rằng hai vectơ này vuông góc với nhau (inner product bằng 0). Sau đó, chúng ta tạo ra một ma trận với hai vectơ này làm cột. Đối với các chiều cao hơn, mô hình tương tự được áp dụng.\nTiếp theo, chúng ta lấy ma trận đối ngẫu của ma trận này – do tình huống của chúng ta sử dụng giá trị thực, ta lấy ma trận chuyển vị của ma trận này (điều này tương đương với ma trận đối ngẫu). Ma trận kết quả cũng sẽ là ma trận đơn vị.\nToán tử đơn vị này sau đó được áp dụng cho trạng thái (Circuit object) bằng phương thức Circuit.unitary. Sau đó, chúng ta đo trạng thái trong cơ sở tính toán. Lưu ý rằng phương pháp đo lường trong Amazon Braket mặc định được thực hiện trên cơ sở tính toán.\nCode: Đo lường trong arbitrary basis import numpy as np from braket.circuits import Circuit from braket.devices import LocalSimulator device = LocalSimulator() circuit = Circuit() # Số lượng qubit trong Braket được khởi tạo ở trạng thái |0⟩ và thẳng hàng với trục Z. # Sau đó, ta xoay qubit quanh trục Y một góc (tính bằng radian). # Mặc dù ta biết rõ hướng và trạng thái chính xác của qubit, # nhưng trong ví dụ này ta sẽ giả vờ như không biết và tìm cách xác định trạng thái đó # thông qua các phép đo — đây chính là mục đích của ví dụ này. state_angle = np.pi / 3 circuit.ry(0, state_angle) # Định nghĩa một vector cơ sở có góc lệch là π/8 so với cơ sở tính toán |0⟩ u_0 = np.array([[np.cos(np.pi/8)], [np.sin(np.pi/8)]]) # Định nghĩa một vector cơ sở khác có góc lệch là π/8 so với cơ sở tính toán |1⟩ u_1 = np.array([[-np.sin(np.pi/8)], [np.cos(np.pi/8)]]) # Tạo một ma trận mà các cột của nó là các vector cơ sở dùng để đo matrix_formed_from_basis_vectors = np.hstack((u_0, u_1)) # Cổng đơn vị (unitary gate) là phép liên hợp (adjoint) của ma trận vừa tạo # Với ma trận thực, phép liên hợp (adjoint) chính là chuyển vị (transpose) basis_rotation_gate = matrix_formed_from_basis_vectors.T # Áp dụng cổng đơn vị này vào mạch lượng tử — về bản chất, đây là một phép quay hệ tọa độ circuit.unitary(matrix=basis_rotation_gate, targets=[0]) circuit.probability(target=0) task = device.run(circuit, shots=1000) taskResult = task.result() measurement_probabilties = taskResult.values[0] counts = taskResult.measurement_counts print(\u0026#34;Probability : \u0026#34;, measurement_probabilties) print(\u0026#34;Counts : \u0026#34;, counts) Khi chạy đoạn code trên, bạn sẽ nhận được kết quả tương tự như sau (lưu ý rằng bạn có thể nhận được một con số hơi khác, nhưng kết quả sẽ gần và có xu hướng tiến tới giá trị này):\nProbability : [0.983 0.017] Counts : Counter({\u0026#39;0\u0026#39;: 983, \u0026#39;1\u0026#39;: 17}) Kết quả này trùng khớp với các giá trị được tính toán trước đó.\nTại sao lại đo lường trên một basis khác? Các cơ sở đo lường khác nhau tiết lộ các khía cạnh bổ sung của quantum states. Sự bổ sung này xuất phát từ bản chất xác suất của quantum measurement: chúng ta quan sát các kết quả với xác suất cụ thể thông qua quy tắc Born, chứ không phải các biên độ phức tạp cơ bản trực tiếp.\nXem xét một trạng thái tổng quát |ψ⟩ = α|0⟩ + β|1⟩, trong đó α và β là các số phức. Đo lường trong cơ sở tính toán tiết lộ |α|² và |β|² (xác suất của các kết quả |0⟩ và |1⟩), nhưng không tiết lộ pha tương đối giữa α và β. Thông tin pha này vẫn được mã hóa trong quantum state và không thể truy cập thông qua các phép đo trong basis đó. Các trạng thái chỉ khác nhau về pha tương đối sẽ cho ra thống kê đo lường giống hệt nhau trong basis đó, mặc dù chúng là các quantum states khác nhau.\nVí dụ: Truy Cập Thông Tin Pha Ẩn\nXét |+⟩ = (|0⟩ + |1⟩)/ √2 và |−⟩ = (|0⟩ − |1⟩)/ √2. Các trạng thái này chỉ khác nhau ở pha tương đối giữa các thành phần |0⟩ và |1⟩ của chúng. Đáng chú ý, mặc dù cả hai đều là các trạng thái chồng chập bằng nhau, |+⟩ và |−⟩ là các orthogonal states — tức là có thể phân biệt tối đa với nhau như |0⟩ và |1⟩.\nTrong các phép đo cơ sở tính toán, cả hai trạng thái đều cho kết quả 50% |0⟩ và 50% |1⟩. Mối quan hệ pha ± không thể quan sát được. Tuy nhiên, trong cơ sở {|+⟩, |−⟩}, |+⟩ luôn cho kết quả |+⟩ và |−⟩ luôn cho kết quả |−⟩ (cả hai đều với xác suất = 1). Thông tin pha trở nên có thể quan sát trực tiếp.\nĐiều này minh họa tính bổ sung trong đo lường lượng tử: việc mô tả đầy đủ một trạng thái lượng tử yêu cầu thực hiện đo lường trong nhiều cơ sở không tương thích — các cơ sở mà các toán tử đo lường của chúng không giao hoán, ngăn cản việc đo lường chính xác đồng thời. Mỗi cơ sở đo lường truy cập vào thông tin lượng tử cụ thể trong khi làm cho các khía cạnh khác không thể quan sát được.\nLàm cách nào sự thay đổi của basis tiết lộ các khía cạnh của quantum information? Hãy quay lại với nguyên lý đo lường. Xác suất của kết quả phụ thuộc vào phép chiếu của trạng thái lượng tử lên các trạng thái basis (vectơ hoặc không gian con). Điều này có thể được hình dung rõ ràng hơn trong trường hợp 1 qubit trên Bloch sphere. Một trạng thái tùy ý là một điểm trên Bloch sphere và phép chiếu của trạng thái đó lên trục Z xác định xác suất trạng thái đó cho ra trạng thái |0⟩ hoặc |1⟩ khi đo lường. Các trạng thái nằm trên cùng một vĩ độ có cùng giá trị xác suất. Các điểm khác nhau trên quả cầu Bloch ở cùng một vĩ độ chỉ khác nhau về pha tương đối.\nKhi chúng ta đo trạng thái từ các basis khác nhau, chúng ta đang tìm hiểu về hình chiếu của cùng một vectơ trạng thái lên một vectơ hoặc hướng khác với cơ sở tính toán. Các trạng thái chỉ khác nhau về pha so với cơ sở tính toán (và có cùng hình chiếu trên trục Z) sẽ có hình chiếu khác nhau trên cơ sở đo lường / trục khác với cơ sở tính toán.\nLấy một ví dụ minh họa, hãy xem xét hai thành phố trên một quả địa cầu có cùng vĩ độ. Chúng sẽ có cùng một hình chiếu dọc theo trục bắc-nam, nhưng nếu chúng ta xoay và định hướng lại quả địa cầu theo trục xích đạo, những thành phố này sẽ có các hình chiếu khác nhau dọc theo trục mới này.\nĐiểm mấu chốt là những gì xuất hiện dưới dạng “phase” trong cơ sở tính toán sẽ thể hiện dưới dạng “amplitude” trong một cơ sở khác. Vì amplitude quyết định kết quả đo lường, việc biến đổi cơ sở có thể được xem như cơ chế cho phép sự chuyển đổi từ phase sang amplitude.\nĐây là lý do tại sao Hadamard transform đóng vai trò quan trọng trong các thuật toán lượng tử. Như chúng ta đã thấy trong phần trước, bất kỳ biến đổi đơn vị (như Hadamard) nào cũng có thể được xem và giải thích như một basis transformation (xoay tọa độ). Biến đổi Hadamard thay đổi góc nhìn của cơ sở tính toán { |0⟩, |1⟩ } sang góc nhìn { |+⟩, |−⟩ }. Thông tin được mã hóa trong pha (trong các thuật toán như Simon’s, Shor’s và bất kỳ quy trình phụ thuộc vào phản hồi pha nào) sử dụng phương pháp biến đổi cơ sở để phát hiện mẫu trong thông tin lượng tử.\nChúng ta có thể rút ra một số điểm chính từ phân tích này:\nLựa chọn cơ sở đo lường cung cấp cho chúng ta những góc nhìn duy nhất mà có thể không có sẵn từ một cơ sở khác; và chúng ta không thể có được tất cả các góc nhìn cùng một lúc. Một độ chắc chắn cao hơn trong phép đo ở một tập cơ sở có thể dẫn đến độ không chắc chắn cao hơn trong cơ sở tương ứng từ một tập khác. Chúng ta có thể giải thích hoạt động của ma trận Unitary trên một trạng thái theo hai cách – hoặc là ma trận Unitary thay đổi trạng thái của hệ thống, hoặc là biến đổi cơ sở cho phép phép đo (hoặc góc nhìn) trên qubit từ một hệ tọa độ khác. Công thức projector để đo trạng thái trong một arbitrary basis Trong cơ học lượng tử, các phép đo vật lý được mô tả bằng các Observables. Phép đo này nhằm xác định lượng trạng thái lượng tử “chiếu lên” mỗi basis vector. Khái niệm này được thể hiện thông qua khái niệm các phép chiếu, đóng vai trò là các khối xây dựng cơ bản cho việc hiểu những phép đo sử dụng các Observables.\nChúng ta đã thấy rằng xác suất của trạng thái |ψ⟩, khi được đo trong một arbitrary basis { |u₀⟩, |u₁⟩, …, |u_k⟩, …, |u_{N−1}⟩ }, được quan sát trong trạng thái |u_k⟩ là\n$$ |\\langle u_k | ψ \\rangle|^2 = \\langle u_k | ψ \\rangle \\langle u_k | ψ \\rangle^* = \\langle u_k | ψ \\rangle \\langle ψ | u_k \\rangle = \\langle ψ | u_k \\rangle \\langle u_k | ψ \\rangle $$\nBiểu thức tích ngoài |u_k⟩⟨u_k| được gọi là phép chiếu cho basis state |u_k⟩. Hãy ký hiệu nó bằng P_k. Do đó, xác suất thu được trạng thái kết quả |u_k⟩ khi |ψ⟩ được đo trong cơ sở { |u₀⟩, |u₁⟩, …, |u_k⟩, …, |u_{N−1}⟩ } là\n$$ \\langle ψ | P_k | ψ \\rangle $$\nPhép chiếu P_k có thể được hiểu là một phép toán trích xuất thành phần của |ψ⟩ nằm dọc theo hướng |u_k⟩:\n$$ P_k | ψ \\rangle = |u_k⟩ \\langle u_k | ψ \\rangle $$\n⟨u_k|ψ⟩ là biên độ phức tạp đo lường sự “trùng lặp” giữa |ψ⟩ và |u_k⟩, và P_k|ψ⟩ nhân |u_k⟩ với biên độ này, cho ra thành phần của |ψ⟩ nằm dọc theo |u_k⟩.\nCác phép chiếu có thể được xem là các khối xây dựng cơ bản của các đại lượng quantum observables. Hành động của một phép chiếu đại diện cho loại đo lường cơ bản nhất trong cơ học lượng tử. Một phép chiếu P đặt ra câu hỏi cơ bản (“có”/“không”): “Hệ thống có ở trạng thái được định nghĩa bởi phép chiếu không?”. Chúng ta sẽ nhận được câu trả lời “Có” với xác suất\n$$ \\langle ψ | P | ψ \\rangle $$\nProjectors là các toán tử Hermitian có các giá trị riêng là 0 và 1. Chúng bảo toàn các thành phần trong không gian con đích (giá trị riêng 1) đồng thời loại bỏ các thành phần vuông góc (giá trị riêng 0).\nTừ Projectors đến Observables Các phép chiếu trả lời các câu hỏi nhị phân “có/không” về trạng thái lượng tử trong một hướng hoặc không gian con cụ thể. Một Observable mở rộng khái niệm này bằng cách gán các giá trị số cho các kết quả đo lường khác nhau.\nMột Observable về cơ bản là một cấu trúc đo lường trạng thái lượng tử trong cơ sở được xác định bởi các vectơ riêng của nó. Mỗi observable ngầm định một cơ sở đo lường – eigenbasis của nó – xác định “reference frame” mà trong đó trạng thái lượng tử được quan sát.\nCụ thể, một observable là tổng có trọng số của các projector vuông góc:\n$$ A = \\lambda_0 P_0 + \\lambda_1 P_1 + \\dots + \\lambda_{n-1} P_{n-1} $$\n(Spectral Decomposition của một observable)\ntrong đó mỗi λᵢ là một eigenvalue và Pᵢ là phép chiếu lên không gian riêng tương ứng.\nKhi đo lường một observable A trong trạng thái |ψ⟩, mỗi phép đo cho ra chính xác một trong các giá trị riêng λᵢ. Xác suất thu được λᵢ là\n$$ \\langle ψ | P_i | ψ \\rangle $$\nKhi đo lường, trạng thái “collapses” thành một trạng thái mới:\n$$ \\frac{P_i | ψ \\rangle}{\\sqrt{\\langle ψ | P_i | ψ \\rangle}} $$\nPhần tử mẫu là hệ số chuẩn hóa để đáp ứng yêu cầu chuẩn hóa đơn vị của trạng thái lượng tử.\nNói cách khác, một đại lượng quan sát cung cấp một mô hình đo lường sử dụng các vectơ riêng của nó làm cơ sở đo lường và tạo ra các giá trị riêng làm kết quả đo lường.\nVí dụ: đo lường với đại lượng quan sát Pauli X tương đương với đo lường trong cơ sở {|+⟩, |−⟩}, và đo lường với Pauli Z chỉ đơn giản là đo lường trong cơ sở {|0⟩, |1⟩}. (|+⟩ và |−⟩ là các vectơ riêng của X, còn |0⟩ và |1⟩ là các vectơ riêng của Z).\nKết quả đo tuân theo phân phối xác suất được xác định bởi sự chiếu của trạng thái lượng tử lên từng không gian riêng.\nMỗi lần đo trên thiết bị (máy mô phỏng hoặc quantum hardware thực) đại diện cho một lần đo lường riêng lẻ, khiến trạng thái lượng tử sụp đổ vào một trong các không gian riêng đồng thời cho ra giá trị riêng tương ứng làm kết quả đo lường.\nGiá trị kỳ vọng của một phép đo là tổng có trọng số của tất cả các lần đo lường. Cần nhấn mạnh rằng mỗi lần đo lường luôn cho ra một trong các giá trị riêng. Chúng ta không bao giờ thấy \u0026ldquo;giá trị kỳ vọng\u0026rdquo; trong bất kỳ quan sát cụ thể nào. Đây là giá trị trung bình thống kê được tính toán sau từ kết quả của các lần đo lường riêng lẻ.\nMột projector operator có thể được xem là observable cơ bản nhất chỉ có một giá trị riêng và giá trị của nó là 1. Nói cách khác, nó là observable chỉ có một thành phần trong spectral decomposition của nó.\nMột Observable, nói chung, cho giá trị kỳ vọng – đây là giá trị trung bình thống kê của các giá trị riêng mà chúng ta gán cho từng cơ sở đo lường (eigenstate – lưu ý rằng khi sử dụng một observable, chúng ta đang ngầm đo lường trạng thái trong vectơ riêng của observable). Một phép đo sử dụng phép chiếu cơ bản (như observable) sẽ cho xác suất trực tiếp – điều này là do giá trị riêng của phép chiếu là 1 và giá trị đơn vị này không ảnh hưởng đến thống kê của phép đo.\nObservable dưới dạng tổng của Pauli Terms Theo nguyên tắc chung, bất kỳ toán tử Hermitian A nào có các vectơ riêng vuông góc đều có thể đóng vai trò là quantum observable, nơi các phép đo được chiếu lên các eigenstates này với các giá trị riêng tương ứng λᵢ.\nObservable\n$$ A = \\sum_i \\lambda_i |u_i⟩⟨u_i| $$\nđại diện cho phép đo hoàn chỉnh trong custom basis này.\nHầu hết các thiết bị lượng tử chỉ có thể thực hiện phép đo trong một cơ sở tính toán cố định duy nhất — Z-basis (|0⟩, |1⟩).\nCác Quantum computing frameworks giải quyết vấn đề này thông qua quá trình phân tích hệ thống:\nBất kỳ toán tử Hermitian đơn qubit A nào cũng có thể được phân tích độc nhất thành:\n$$ A = a_0 I + a_1 X + a_2 Y + a_3 Z $$\nỞ đây, aᵢ là các hệ số số thực và X, Y, Z là ba ma trận Pauli (Observables) cùng với ma trận đơn vị I.\nCác phép đo Pauli sử dụng ma trận Pauli làm các Observables. Khi sử dụng một phép toán Hermitian tùy chỉnh làm Observables, Amazon Braket phân tích nó thành tổ hợp tuyến tính của các đại lượng quan sát Pauli.\nMỗi phép đo Pauli có thể được tái diễn giải thông qua các phép đo cơ sở tính toán Pauli-Z bằng cách sử dụng các phép basis rotations thích hợp, hoàn thành việc chuyển đổi từ các phép đo arbitrary sang các phép toán có thể thực hiện được về mặt vật lý.\nPhép đo Pauli X được thực hiện bằng cách áp dụng cổng Hadamard (H) trước phép đo Z basis; phép đo Pauli Y được thực hiện bằng cách áp dụng S† (phase gate) trước, sau đó là Hadamard gate và cuối cùng là phép đo Z basis.\nĐo lường trong arbitrary basis bằng cách sử dụng Observable của Amazon Braket Đoạn code sau minh họa việc sử dụng một phép chiếu để đo trạng thái của hệ thống trong basis { |u_0⟩, |u_1⟩ } như ví dụ trước.\nĐầu tiên, chúng ta định nghĩa một phương thức để tạo phép chiếu, dựa trên một basis vector. Phép chiếu ở dạng cơ bản nhất là outer product của basis vector với chính nó. Projector này cho xác suất trạng thái được quan sát trong basis được định nghĩa bởi vectơ được sử dụng để tạo ra nó.\nChúng ta định nghĩa hai basis vectors như trước đây và xây dựng các toán tử projector cho chúng. Như đã từng làm, chúng ta khởi tạo và xoay state vector bằng cổng RY. Sau đó, chúng ta sử dụng phương thức expectation trên Circuit để chỉ định các observable quan tâm – trong trường hợp này là hai projector.\nMột điểm cần lưu ý là trong Braket, chúng ta chỉ có thể áp dụng một observable duy nhất không phải là hằng số cho mỗi qubit (trừ khi shots được đặt là 0). Để minh họa tác động của cả hai phép chiếu (mỗi phép chiếu là một đại lượng quan sát) tương ứng với hai basis vectors, chúng ta đặt shots=0 ở đây, mặc dù chúng ta có thể đặt shots không bằng 0 cho từng phép chiếu riêng lẻ để xem kết quả đó.\nCode: Sử dụng Projector làm Observable cho đo đạc trong arbitrary basis import numpy as np from braket.circuits import Circuit from braket.devices import LocalSimulator from braket.circuits import observables # Projector là toán tử Hermitian được tạo bằng tích ngoài (outer product) của một vector với chính nó. # Một projector như vậy là một observable cơ bản def get_projector(basis_vector): projector = np.linalg.outer(basis_vector, basis_vector) return observables.Hermitian(projector) # Định nghĩa một vector cơ sở có hướng lệch là π/8 so với cơ sở tính toán |0⟩. basis_u0 = np.array([np.cos(np.pi/8), np.sin(np.pi/8)]) # Định nghĩa một vector cơ sở có hướng lệch là π/8 so với cơ sở tính toán |1⟩. # Cơ sở này trực chuẩn (orthonormal) với basis_u0. basis_u1 = np.array([-np.sin(np.pi/8), np.cos(np.pi/8)]) # Tạo projector cho (basis) vector thứ nhất projector_u0 = get_projector(basis_u0) # Tạo projector cho (basis) vector thứ hai projector_u1 = get_projector(basis_u1) circ = Circuit() device = LocalSimulator() # Các qubit trong Braket được khởi tạo ở trạng thái |0⟩ và thẳng hàng với trục Z. # Xoay qubit quanh trục Y một góc (tính bằng radian). state_angle = np.pi / 3 circ.ry(0, state_angle) # Giá trị kỳ vọng (expectation value) của một projector cho ta xác suất đo được trong cơ sở mà projector đó tạo ra — trong trường hợp này là u_0 circ.expectation(projector_u0) # Giá trị kỳ vọng (expectation value) của projector khác cho ta xác suất đo được trong cơ sở u_1 circ.expectation(projector_u1) # Chạy mạch task = device.run(circ, shots=0) taskResult = task.result() counts = taskResult.measurement_counts probability_u0 = taskResult.values[0] probability_u1 = taskResult.values[1] print(\u0026#34;Probability that state is in basis u_0 : \u0026#34;, np.round(probability_u0, 4)) print(\u0026#34;Probability that state is in basis u_1 : \u0026#34;, np.round(probability_u1, 4)) Kết quả khi chạy đoạn code trên:\nProbability that state is in basis u_0 : [0.983] Probability that state is in basis u_1 : [0.017] Do đó, chúng ta thấy rằng các xác suất thu được từ phương pháp biểu diễn bằng phép chiếu trùng khớp với các giá trị từ phép xoay tọa độ (sử dụng các cổng đơn vị). Về mặt toán học, hai phương pháp này là tương đương. Việc sử dụng phương pháp này hay phương pháp kia phụ thuộc vào perspective và intuition mà chúng ta muốn áp dụng.\nTổng Kết Quantum measurement liên quan đến việc chiếu các trạng thái lượng tử lên các bases khác nhau, cho ra các kết quả xác suất mô tả hệ thống. Chúng ta đã thấy rằng việc đo lường trong một arbitrary basis về mặt toán học tương đương với việc áp dụng một phép quay đơn vị tiếp theo là đo lường trong cơ sở tính toán. Sau đó, chúng ta đã khám phá cách chuyển đổi cơ sở này hoạt động như một công cụ để chuyển đổi thông tin pha không quan sát được thành thông tin biên độ có thể đo lường được. Chúng ta đã xem xét các phép chiếu như các observables cơ bản, lưu ý vai trò của chúng trong việc đo lường xác suất trạng thái trong các cơ sở cụ thể. Cuối cùng, chúng ta đã xem xét cách các observables tổng quát có thể được phân tích thành các toán tử Pauli, tạo nền tảng cho quantum measurement trong Amazon Braket.\nTài liệu tham khảo\n“Bloch Sphere.” Wikipedia, https://en.wikipedia.org/wiki/Bloch_sphere. Truy cập [20/8/2025].\n“Pauli matrices.” Wikipedia, https://en.wikipedia.org/wiki/Pauli_matrices. Truy cập [20/7/2025].\nTownsend, J. S. (2012). A Modern Approach to Quantum Mechanics (2nd ed.). University Science Books, Chapter 2: Rotation of Basis States and Matrix Mechanics.\nTAGS: Amazon Braket , quantum algorithms , quantum computing , Quantum Technologies\nSudarsan Srinivasan Sudarsan Srinivasan là Senior Solutions Architect tại AWS. Anh có niềm đam mê đặc biệt với Vật lý, Toán học và Triết học, điều này đã dẫn anh đến lĩnh vực Quantum Computing. Sudarsan có kinh nghiệm trong lĩnh vực kiến trúc doanh nghiệp và kiến trúc giải pháp, với chuyên môn về thiết kế khả năng phục hồi và hiện đại hóa ứng dụng.\nCharunethran Panchalam Govindarajan Charunethran Panchalam Govindarajan là Sr. Product Marketing Manager tại AWS, chuyên về High-Performance Computing and Quantum Technologies. Anh đã làm việc trong nhiều lĩnh vực công nghệ khác nhau, với sự quan tâm chính vào sự giao thoa giữa nghiên cứu và phát triển (R\u0026amp;D) và phát triển sản phẩm. Charunethran có bằng Thạc sĩ Electrical Engineering từ Đại học Stanford. Ngoài công việc, anh thích vẽ phác thảo và tham gia vào các cuộc trò chuyện triết học.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.1-workshop-overview/","title":"Giới thiệu","tags":[],"description":"","content":"WEBSITE TRỰC TUYẾN THEO DÕI VÀ DỰ BÁO QUỸ ĐẠO BÃO Trong workshop này, nhóm chúng em trình bày cách xây dựng một nền tảng trực tuyến cho phép người dùng truy cập Internet có thể tự do kiểm tra, theo dõi và thậm chí dự đoán đường đi của các cơn bão đang hoạt động tại khu vực Tây Thái Bình Dương. Nền tảng này giúp người dùng chủ động chuẩn bị cho các thảm họa tự nhiên sắp xảy ra và giảm thiểu thiệt hại tiềm tàng.\nNền tảng cung cấp hai chức năng chính:\nHiển thị các cơn bão gần nhất – Cho phép người dùng xem đường đi, cường độ, tốc độ gió và các đặc điểm khác của bão gần đây trong khu vực Tây Thái Bình Dương.\nDự đoán quỹ đạo bão – Cho phép người dùng nhập dữ liệu vị trí bão trong quá khứ (vĩ độ và kinh độ; tối thiểu 9 điểm dữ liệu) để hệ thống dự đoán hướng di chuyển trong tương lai.\nPhân chia theo tiến độ, chúng em sẽ lần lượt trình bày về bộ dữ liệu, quá trình tiền xử lý, pipeline huấn luyện mô hình, và quá trình xây dựng nền tảng trực tuyến bằng các dịch vụ AWS. Chúng em cũng sẽ perform kỹ thuật tăng cường dữ liệu được đề xuất — Stepwise Temporal Fading Augmentation (STFA) cùng với việc ứng dụng machine learning dựa trên các quy tắc vật lý (physics-informed ML). Những phương pháp này giúp dữ liệu huấn luyện trở nên chân thực hơn và cải thiện đáng kể độ chính xác trong dự đoán đường đi bão, tuổi thọ bão và tổng quãng đường di chuyển.\nHình 1 : Pipeline mô hình Sau khi hoàn thành quá trình huấn luyện mô hình, chúng em triển khai xây dựng nền tảng trực tuyến bằng kiến trúc serverless. Đây là kiến trúc tiết kiệm chi phí, có khả năng mở rộng tốt, và dễ dàng bảo trì/triển khai — rất phù hợp cho mục tiêu dự án. Dưới đây là các dịch vụ AWS chính được sử dụng:\nAWS Lambda – Chạy các mô hình ML và xử lý logic phía backend Amazon S3 – Lưu trữ file tĩnh, mô hình ML và dữ liệu bão Amazon API Gateway – Định tuyến và phần luồng các yêu cầu của người dùng đến Lambda phù hợp, tùy theo việc họ xem dữ liệu bão gần đây hay chạy dự đoán Amazon CloudFront – Tăng tốc phân phối nội dung thông qua các edge location AWS Secrets Manager – Lưu trữ khóa API và các thông tin nhạy cảm … – Các dịch vụ hỗ trợ bổ sung khác khi cần Hình 2 : Kiến trúc nền tảng "},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Worklog thực tập FJC – Tổng quan 12 tuần\nTrong suốt 12 tuần thực tập tại FJC, tôi đã hoàn thành chương trình đào tạo và thực hành với AWS, từ làm quen cơ bản đến triển khai các workflow serverless và ML trên cloud. Dưới đây là tổng quan công việc theo từng tuần:\nTuần 1: Làm quen với AWS và các dịch vụ cơ bản\nGiao lưu, làm quen với các thành viên khác cùng tham gia FJC. Tìm hiểu tổng quan về AWS và các dịch vụ được cung cấp. Mở tài khoản AWS và thực hành các tính năng cơ bản. Tuần 2: Trang bị kiến thức cơ bản về EC2, Cloud9, S3\nNắm vững cách sử dụng EC2, Cloud9, S3 để phục vụ cho các project AWS. Tiếp tục tìm hiểu các thao tác cơ bản để xây dựng workflow. Tuần 3: Khám phá Amazon Lightsail và scaling EC2\nTìm hiểu khái niệm Lightsail. Thực hành các bước scaling cho EC2 instances. Tuần 4: Nắm vững kiến thức sơ bộ về Cloud\nHọc các khái niệm cơ bản về cloud. Tìm hiểu AWS CloudWatch, CloudFront, CLI và các công cụ quản lý. Tuần 5: Migrate to AWS \u0026amp; tối ưu Lambda\nHiểu các mục trong module “Migrate to AWS”. Học cách tối ưu chi phí khi sử dụng AWS Lambda. Tuần 6: Quản lý hệ thống AWS và thực hành lab\nTìm hiểu Grafana tags và quản lý AWS System Manager. Thực hành với các bài lab do FJC cung cấp. Tuần 7: AWS CloudFormation \u0026amp; CDK\nTìm hiểu chi tiết về AWS CloudFormation và CDK. Nắm bắt cách tự động hóa triển khai hạ tầng và ứng dụng. Tuần 8: Iac, VPC Flow Logs và Billing\nKhám phá các khái niệm Infrastructure as Code (IaC), VPC flow logs. Hoàn thiện các bài thực hành liên quan đến billing và quản lý chi phí. Tuần 9: Security và AWS SSO\nTìm hiểu các module liên quan đến Security. Làm quen với AWS Single Sign-On và Security Hub. Tuần 10: Containerization \u0026amp; Deployment\nHiểu quy trình container hóa ứng dụng với Docker. Triển khai trên AWS Cloud, làm quen ECS, CDK và CodePipeline. Tuần 11: AWS Serverless\nLàm quen với các dịch vụ serverless của AWS. Thực hành qua AWS SAM, Cognito, Lambda,\u0026hellip; Tuần 12: Data Lake \u0026amp; ML workflow\nHiểu khái niệm Data Lake và các thành phần cơ bản: S3, Glue, Athena, QuickSight. Thực hành ingest, xử lý, truy vấn và trực quan hóa dữ liệu trên AWS. Làm quen với serverless analytics và workflow machine learning bằng SageMaker. "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.2-event2/","title":"Data Science on AWS","tags":[],"description":"","content":"Bài thu hoạch “Data Science on AWS” Mục Đích Của Sự Kiện Giới thiệu các dịch vụ chuyên dụng của AWS dành cho lĩnh vực AI\nGiải thích các khái niệm về học máy\nDemo sử dụng một vài dịch vụ\nDanh Sách Diễn Giả Văn Hoàng Kha - Cloud Solutions Architect, AWS Community Builder Bạch Doãn Vương - Cloud Develops Engineer, AWS Community Builder Nội Dung Nổi Bật Các tiện ích của dịch vụ Cloud cho Data Science Cung cấp api cho các mô hình, giảm thời gian phải code. Hỗ trợ làm sạch, chuyển đổi dữ liệu hiệu quả Giúp xử lý hàng loạt, song song Huấn luyện mô hình trên AWS có nhiều nền tảng hỗ trợ Trợ giúp triển khai, dùng và đóng gói mô hình. Các khái niệm cơ bản trong lĩnh vực Data Science AI: Kỹ thuật cho phép máy tính mimic trí tuệ ngươi bằng logic, mệnh đề if-then và học máy. Machine Learning: Là một tâp hợp con của AI, dùng máy để tìm kiếm pattern trong data và xây dựng logic model. Deep Learning: Tập hợp con của Machine Learning, bao gồm mạng neural nhiều lớp phục vụ được nhiều tác vụ. Generative AI: Mạng tạo sinh, học từ mô hình và bộ dữ liệu của các hãng công nghệ lớn, có khả năng sáng tạo và tạo mới hoàn toàn. Amazon Comprehend Là dịch vụ của AWS giúp phân loại và phân tích văn bản. Hỗ trợ cá nhân hóa PII (Personal Identifile Information) Hiểu được nhiều ngôn ngữ và sentiment trong văn bản Chắt lọc được event và key phrase Amazon Translate Chuyên về dịch thuật và tóm tắt thông tin, co thể dùng để tạo data cho chatbot. Dễ tương tác với các ứng dụng, có độ chính xác cao. Đây là dịch vụ fully-managed, hoàn toàn do người dùng kiểm soát. Amazon Textract Hỗ trợ trích xuất văn bản, dữ liệu từ mọi virtally document. Giúp Chuyển đổi văn bản từ ngôn ngữ này sang ngôn ngữ khác. Amazon Polly và Amazon Transcribe Là dịch vụ text-to-speech (Polly) và speech-to-text (Transcribe) Hỗ trợ khả năng chuyển đổi sang nhiều ngôn ngữ. Amazon Lex Giúp tạo conversational interface cho bất cứ application nào Tạo giao diện nhanh chónh - đẹp, tiết kiệm thời gian. Dễ dùng, cho ra high-quality text với built-in intergration. Amazon Rekognition Cho phép người dùng phân tích ảnh và video với độ chính xác cao Ví dụ như dùng để kiểm duyệt các chi tiết nhạy cảm trong phim ảnh. Amazon Personalise Cá nhân hóa trải nghiệm của người dùng Không cần tích hợp machine learning Thu thập và dùng các user metadata, item metadata, \u0026hellip; Feature Engineering Feature Engineering là quá trình làm cho máy hiểu dữ liệu được đưa vào. Giải quyết các vấn đề làm sao để encode, chuyển đổi về ngôn ngữ máy nhanh nhất - tốt nhất. Ví dụ như chỉnh sửa file dữ liệu thiếu, bị lỗi không hoàn chỉnh -\u0026gt; Làm sạch dữ liệu là một phần của feature engineering Machine Learning Process Không chỉ đơn giản về xây dựng mô hình ML. Bao gồm cả các bước phân tích bussniness problem, đánh giá mô hình đã đạt được như mong muốn hay chưa. Kèm theo cả phần triển khai cho end-user dùng và cải thiện lâu dài. Những Gì Học Được Hiểu rõ hơn về Data Science Biết được định nghĩa kỹ thuật của nhiều khái niệm: Artifical Intellegence, Machine Learning, Deep Learning, Generative AI. Học về quy trình ML Process: Đó không chỉ là code và tạo mô hình, mà còn gồm nhiều bước đánh giá và triển khai. Hiểu được sự tiện ích khi sử dụng dịch vục AWS: Giúp tiết kiệm thời gian hơn, cho ra kết quả tốt và tối ưu chi phí. Ứng Dụng Vào Công Việc Áp dụng Amazon Translate Tích hợp vào các dự án sắp tới trong tương lại Dùng Amazon Textract: Dùng để hỗ trợ trích xuất thông tin torng văn bản nhanh, tiết kiệm thời gian. Chú tâm vào Feature Engineering: Vì quá trình xử lý bài toàn và dữ liệu là bước đầu và khá quan trọng, sẽ ảnh hưởng đến những phần sau nên cần được chú ý nhiều hơn khi làm việc. Trải nghiệm trong event Tham dự workshop “Data Science on AWS” là một cuộc phiêu lưu ấn tượng khi được dấn thân vào miền tri thức tràn đầy các kiến thức và dịch vụ cloud bổ ích sẽ hỗ trợ rất nhiều trong công việc và học tập.\nGặp gỡ các diễn giả có chuyên môn cao Hai anh diễn giả từ AWS đã mang lại phần trình bày tuyệt vời và đầy bổ ích, mang lại cho bản thân em sự hứng thú về nền tảng cloud cũng như các dịch vụ mà nó offer. Nhiều câu hỏi hay từ phía khán giả đã được đặt ra, giúp em hiểu sâu hơn về chuyên nghành mình đang theo học cùng xu hướng công nghệ hiện nay. Trực tiếp xem qua Demo độc đáo Anh Kha đã cho xem một phần demo sử dụng các dịch vụ để xây dựng một mô hình machine learning là thế nào. Phần demo rất dễ hiểu và gãy gọn, cho thấy được nhiều sự tiện ích của AWS. Bài học rút ra Việc áp dụng các dịch vụ AWS cho xây dựng và triển khai mô hình ML hiện nay là không thể thiếu. Không chỉ tiết kiệm thời gian mà còn mang lại hiệu suất cao với độ chính xác tốt. Machine Learning Process không chỉ nằm ở quá trình xây dựng mô hình mà còn phải đi giải bài toán bussiness problem cho khách hàng cũng như phải tính toán việc triển khai, nâng cấp lâu dài cho sản phẩm sau khi ra mắt. Các dịch vụ như Amazon Regkognition có hỗ trợ api rất tiện lợi nếu được tích vào các project để sử dụng. Một số hình ảnh khi tham gia sự kiện Hình 1 Hình 2 Hình 3 Hình 4 Tổng thể, sự kiện không chỉ cung cấp kiến thức kỹ thuật mà còn giúp em thay đổi cách tư duy về Machine Learning và Cloud Engineer.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.2-week2/","title":"Worklog Tuần 2","tags":[],"description":"","content":"Mục tiêu tuần 2: Tiếp tục trang bị thêm kiến thức cho xây dựng mô hình project. Nắm rõ các kiến thức về sử dụng EC2, Cloud 9, S3, … Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu các thuật toán cần thiết cho project: + Hình học cầu + Đại số tuyến tính và xác suất thống kê + Các thuật toán machine learning + Dự đoán điểm mới từ điểm cũ + hướng + quãng đường 15/09/2025 15/09/2025 3 - Đọc hiểu các kiến thức về EC2 + Chức năng chính của dịch vụ + Thử nghiệm triển khai + Chi phí sử dụng 16/09/2025 16/09/2025 https://000004.awsstudygroup.com/ 4 - Khám phá dịch vụ hỗ trợ lập trình Cloud 9 + Triển khai và thực hiện các thiết lập cơ bản + Thử sử dụng dịch vụ 17/09/2025 17/09/2025 https://000049.awsstudygroup.com/ 5 - Tìm hiểu về dịch vụ lưu trữ Amazon S3 + Tạo S3 bucket và tải data lên + Dùng thử vài tính năng chính 18/09/2025 18/09/2025 https://000057.awsstudygroup.com/ 6 - Dịch bài log \u0026ldquo;Implement network connectivity patterns for Oracle Database@AWS\u0026rdquo; từ tiếng Anh sang tiếng Việt 19/09/2025 19/09/2025 https://aws.amazon.com/blogs/database/implement-network-connectivity-patterns-for-oracle-databaseaws/ Kết quả đạt được tuần 2: A – EC2\nTìm hiểu căn bản Elastic Compute Cloud (EC2)\nDịch vụ cung cấp tính toán và chạy (launch) server ảo mà không cần hardware upfront.\nAMI (Amazon Machine Images) làm template cho các instances của EC2, bao gồm các hệ thống operating, aplication server, block device mapping, …\nCác lựa chọn lưu trữ (storage cho EC2) gồm có Amzong EBS volumes và Instance store volumes.\nKhám phá các chức năng chính của Amazon EC2:\nElastic Infrastructure Khả năng kết nối mở rộng (Networking Capabilities) Đa dạng Availability Zones để lựa chọn Quản lý tài nguyên Theo dõi performance và cài đặt thông báo. Thực hiện hoàn tất các bước chuẩn bị triển khai EC2:\nTạo VPC cho Windows Instance Tạo Security Group cho Windows Intstance Thành công khởi tạo Microsoft Window Instantce cho EC2 và kết nối tới máy tính.\nHọc sâu hơn về EC2\nChỉnh sửa loại Instance EC2 Tạo và quản lý EBS Snapshots Tạo Custom AMI Triển khai instances từ Custom AMI Thử nghiệm recovering access từ Windows Instances Thử deploy Node,js applications lên amazon EC2 windows\nHiểu rõ về phí sử dụng của EC2 thông qua restricting service usage và liming EC2 usage.\nKiểm soát tốt EC2 deployment Quản lý EB2 volumn storage types Giới hạn quyền xóa resource bởi IP adderess của công ty và theo time period. Tiến hành dọn dẹp tài nguyên sau khi khởi tạo và sử dụng EC2 *Xóa EC2 instances, AMIs, EBS Snapshots, … *Xóa sercurity group, key pairs, tài nguyên, VPC, …\nB – AWS CLOUD 9\nThực hiện khám phá các thông tin cơ bản về Cloud 9:\nBiết về Cloud9 là môi trường pha triển (IDE) hoạt động trực tiếp trên web browser. Cung cấp khả năng chạy, build, edit code và hỗ trợ triển khai lên cloud. Cho phép thay đổi IDE theo mong muốn (màu sắc nền, keyborad shortcuts,\u0026hellip;) Tiến hành khởi tạo Cloud9 instance để sử dụng:\nTạo evnviroment trên dịch vụ Cloud9 Đặt tên, thực hiện các thiết lập cần thiết Hoàn tất create enviroment và chờ cho hoàn tất khởi tạo. Thử sử dụng các tính năng cơ bản:\nDùng terminal trong cloud9 cho comman line Làm vài thử nghiệm với text files Tự thử thêm các chức năng khác. C – Amazon S3\nBiết về khái niệm Amazon Simple Storage Service (Amazon S3):\nCung cấp nơi lưu trữ thông tin tốt và an toàn Được tạo ra để đáp ứng mọi data về kích thước và lĩnh vực của khách hàng. Sử dụng nhiều trường hợp như data warehouse, website, mobile apps, … Tiến hành tạo S3 bucket và tải data lên\nThực hiện các bước chỉnh sửa, mở rộng khả năng dùng S3:\nCho phép các chức năng của static website Chỉnh sửa khối public access và public oject Test lại website Tăng tốc static website với cloudfront Thử nghiệm vài tính năng khác của S3:\nSử dụng bucket versioning Di chuyển các objects trong dịch vụ Sao chép đối tượng nhiều vùng (Replication object multi-region) Dọn dẹp tài nguyên sau khi thử nghiệm với S3\n"},{"uri":"https://giaphazzz.github.io/aws/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Triển khai network connectivity patterns cho Oracle Database@AWS Sameer Malik, Anvesh Koganti, và Shubham Singh | vào ngày 11 Tháng 9 2025 | AWS Cloud WAN, AWS Transit Gateway, Expert (400), Networking \u0026amp; Content Delivery, Oracle Database@AWS, Technical How-to |\nOracle Database@AWS (ODB@AWS) là một dịch vụ cho phép khách hàng truy cập vào hạ tầng Oracle Exadata được quản lý bởi Oracle Cloud Infrastructure (OCI) trong các trung tâm dữ liệu của Amazon Web Services (AWS). Bạn có thể sử dụng ODB@AWS để di chuyển workloads Oracle Exadata của mình sang AWS trong khi vẫn duy trì cùng mức hiệu suất và tính năng như các triển khai Oracle Exadata on-premise. Tất nhiên, bạn được hưởng lợi từ việc giảm độ trễ ứng dụng bằng cách thiết lập low-latency connectivity giữa Oracle Exadata và các ứng dụng đang chạy trên AWS. Không những thế, bạn còn có thể tích hợp Oracle Database@AWS với các dịch vụ AWS khác để cải thiện availability và scalability cho các ứng dụng Oracle database của mình.\nTrong bài viết lần này, chúng tôi sẽ trình bày cách triển khai các IP routing-based network connectivity patterns khác nhau cho kết nối giữa ODB network của bạn cùng những tài nguyên khác được triển khai trong AWS cũng như mạng on-premises của bạn. Các patterns này hoạt động tốt khi bạn có non-overlapping IP address spaces và cần traditional Layer 3 connectivity.\nCác connectivity patterns được đề cập trong bài viết này bao gồm:\nOne-to-one connectivity giữa application virtual private cloud (VPC) và ODB network\nScalable single-Region connectivity giữa multi-VPC hoặc on-premises infrastructure và ODB network sử dụng AWS Transit Gateway\nScalable global connectivity giữa multi-VPC hoặc on-premises infrastructure và ODB network sử dụng AWS Cloud WAN\nTrước khi đi tiếp, chúng tôi khuyến khích bạn nên làm quen với các dịch vụ AWS như Amazon Virtual Private Cloud (Amazon VPC), AWS Direct Connect, Amazon Route 53 Resolver endpoints, Transit Gateway, và AWS Cloud WAN.\nThông tin cơ bản Dưới đây là tổng quan chung về những thành phần chính trong ODB@AWS cần thiết cho kết nối mạng. Để biết thêm thông tin, vui lòng tham khảo Oracle Database@AWS User Guide.\nODB network – ODB network là một mạng private và cách ly, chứa Oracle infrastructure trong một AWS Availability Zone. Khác với VPC tiêu chuẩn, mạng ODB không có kết nối internet và chỉ hỗ trợ các tài nguyên ODB@AWS.\nODB peering – ODB peering thiết lập private network connectivity giữa ODB network của bạn và một Amazon VPC, cho phép các ứng dụng giao tiếp với Oracle databases như thể chúng nằm trên cùng một mạng. ODB peering kết nối mọi trường AWS và Oracle, đồng thời cung cấp khả năng hỗ trợ routing cho phép lưu lượng sử dụng các dịch vụ AWS networking cụ thể được kết nối tới peered VPC để đến ODB network. Hình minh họa sau đây thể hiện mối quan hệ peering này giữa một peered VPC và ODB network.\nKiểm soát truy cập với peered CIDRs – Peered CIDRs là một cấu hình đóng vai trò như một danh sách kiểm soát truy cập (ACL) ở cấp độ mạng. Bạn có thể chỉ định và quản lý các IP CIDR ranges được phép truy cập vào Oracle database resources trong ODB network của bạn. Việc thiết lập peered CIDRs kích hoạt automation phía Oracle OCI để cấu hình route rules và security rules liên kết với Oracle Virtual Cloud Network (tương đương Amazon VPC) nơi các resources tồn tại, để cho phép traffic từ/tới các CIDRs cụ thể trên các protocols và ports nhất định. Bạn có thể chỉ định subnet CIDRs cụ thể thay vì toàn bộ VPC ranges, cung cấp kiểm soát bảo mật chi tiết. Tham khảo phần considerations ở cuối bài viết này để biết thêm chi tiết về peered CIDRs và OCI automation specifics.\nPeered VPC usage patterns – Một peered VPC phục vụ nhiều mục đích. Nó có thể hoạt động như một ứng dụng trực tiếp VPC, cung cấp đường dẫn mạng đơn giản nhất cho các tác vụ Oracle chuyên dụng. Ngoài ra, nó có thể đóng vai trò như một VPC trung chuyển sử dụng transitive routing để cho phép mạng ODB truy cập từ nhiều VPC và on-premises networks thông qua Transit Gateway hoặc các hub-and-spoke architectures dựa trên AWS Cloud WAN. Một peered VPC cũng có thể đồng thời thực hiện cả hai vai trò, vừa làm VPC ứng dụng lưu trữ các tác vụ, vừa là VPC trung chuyển kết nối các mạng khác với mạng ODB.\nThiết lập cấu Hình DNS ODB@AWS tự động quản lý DNS trong ODB network, tạo ra Fully Qualified Domain Names (FQDNs) cho các cụm máy ảo (VM). Theo mặc định, các FQDN này sử dụng domain pattern *.oraclevcn.com (nơi mà bạn có thể chỉ định tiền tố được gắn thêm vào oraclevcn.com, ví dụ: myhost.oraclevcn.com). Ngoài ra, bạn còn có thể thiết lập tên miền tùy ý bằng cách sử dụng tên miền hoàn chỉnh của riêng mình (ví dụ: myhost.myodb.com). Dù chọn cấu hình tên miền nào, các truy vấn DNS từ VPC của bạn phải được chuyển tiếp đến hạ tầng DNS của mạng ODB để giải quyết các tên miền này.\nKiến trúc DNS bao gồm các thành phần sau:\nRoute 53 Resolver outbound endpoint – Chuyển tiếp các truy vấn DNS từ VPC của bạn đến cơ sở hạ tầng DNS của mạng ODB. Sau khi mạng ODB được tạo, nó cung cấp địa chỉ IP của DNS listener IP mà điểm cuối ra ngoài phải có kết nối đến mạng.\nForwarding rules – Chuyển giao các truy vấn trực tiếp đến các miền Oracle (ví dụ: client.xxxxx.oraclevcn.com) tới DNS listener IP của ODB network bằng outbound endpoint. Quy tắc này phải khớp với cả tên miền chính xác và các tên miền con của nó (ví dụ: nếu rule cho example.com, nó khớp cả example.com và sub.example.com). Bạn có thể chia sẻ các quy tắc này giữa các tài khoản AWS Resource Access Manager (AWS RAM) và liên kết chúng với các VPC cần giải quyết tên miền Oracle. Để hiểu chi tiết hơn về domain matching, xem qua How Resolver determines whether the domain name in a query matches any rules.\nTrong hình minh họa tiếp theo, outbound endpoint được triển khai trong application VPC để cấu hình đơn giản hơn và kết nối trực tiếp tới peered ODB network. Các tùy chọn triển khai thay thế và chiến lược quản lý DNS tập trung được thảo luận sau trong bài viết này. Để biết các bước cấu hình DNS chi tiết, xem Configuring DNS for Oracle Database@AWS.\nNetwork connectivity patterns Trong phần này, chúng ta sẽ thảo luận về ba patterns kết nối mạng phổ biến cho ODB@AWS, từ kết nối trực tiếp đơn giản đến các kiến trúc đa vùng có khả năng mở rộng. Mỗi mô hình sẽ đáp ứng được các nhu cầu kinh doanh và mở rộng khác nhau. Nhằm đơn giản hóa, các sơ đồ sẽ không hiển thị vị trí tài nguyên cấp tài khoản (account-level resource placement). Những cân nhắc về vị trí tài khoản cho từng mô hình sẽ được nêu chi tiết trong phần tiếp theo.\nConnectivity pattern 1: Kết nối trực tiếp giữa application VPC và ODB network Pattern 1 sử dụng VPC được kết nối trực tiếp như một application VPC , lưu trữ các ứng dụng cơ sở dữ liệu trực tiếp trong VPC được kết nối với mạng ODB. Phương pháp này cung cấp đường dẫn mạng đơn giản nhất giữa các ứng dụng và cơ sở dữ liệu.\nPattern này hoạt động tốt khi Oracle databases chủ yếu phục vụ applications trong một VPC. Như hình dưới đây minh họa, ODB network được gắn với một Availability Zone duy nhất (được định nghĩa khi ODB network được tạo), trong khi application VPC và tài nguyên của nó có thể trải rộng qua nhiều Availability Zones. Đối với các kiến trúc multi-VPC hoặc hybrid, hãy xem xét các ODB transit VPC patterns ở những phần sau.\nWorkflow bao gồm các thành phần:\nA. Amazon Elastic Compute Cloud (Amazon EC2) instances trong application VPC giải quyết database hostname để lấy địa chỉ IP và sau đó thiết lập kết nối cơ sở dữ liệu sử dụng địa chỉ IP này.\nB. VPC route tables điều hướng lưu lượng truy cập đến mạng ODB thông qua kết nối peering ODB.\nC. Vì VPC CIDR được bao gồm trong danh sách peered CIDRs, các cấu hình phía Oracle OCI tồn tại để cho phép traffic này. Lưu lượng phản hồi theo đường dẫn ngược trở lại các instance EC2 ban đầu.\nConnectivity pattern 2: Single-Region scalable connectivity sử dụng Transit Gateway Trong pattern này, chúng ta sẽ tìm hiểu về kết nối mạng tới ODB network ở quy mô lớn trong một AWS Region duy nhất. Tại thời điểm viết bài, ODB network chỉ hỗ trợ direct peering với một VPC duy nhất; one-to-many peering connection giữa một ODB network và nhiều VPCs chưa được hỗ trợ. Transit gateway là một thành phần mạng tập trung hoạt động đóng vai trò như điểm điểm kết nối cho nhiều VPCs và on-premises networks. Tại thời điểm bài viết, ODB network chưa hỗ trợ built-in transit gateway attachment. Tuy nhiên, bạn có thể thiết lập kết nối peering giữa mạng ODB và một VPC Transit duy nhất, sau đó kết nối VPC Transit đó với Transit Gateway, như minh họa trong hình dưới đây.\nTrong pattern này, peered VPC chỉ hoạt động như một VPC trung chuyển ODB (đã mô tả trước đó). Tuy nhiên, như đã nhấn mạnh trong mô hình sử dụng VPC được kết nối, VPC được kết nối có thể đồng thời lưu trữ các tải công việc nếu cần thiết. Transit gateway attachment tới transit VPC phải được tạo trong một Availability Zone duy nhất, cụ thể là Availability Zone nơi ODB network được tạo. Để nhấn mạnh điều này, trong hình trước, chúng tôi minh họa workloads trải rộng qua nhiều Availability Zones trong application VPC, nhưng transit VPC chỉ có một transit gateway attachment trong Availability Zone 1. Để biết thêm các bước cấu hình chi tiết, xem Configuring Amazon VPC Transit Gateways for Oracle Database@AWS.\nWorkflow bao gồm các thành phần:\nEC2 instances trong application VPC giải quyết tên máy chủ cơ sở dữ liệu để lấy địa chỉ IP và sau đó thiết lập kết nối cơ sở dữ liệu sử dụng địa chỉ IP này. Bảng định tuyến của subnet VPC được tra cứu, và gói tin được chuyển tiếp tới transit gateway thông qua kết nối cổng chuyển tiếp.\nTransit Gateway route table có một đường dẫn tĩnh cho mạng ODB CIDR với đích đến là kết nối VPC chuyển tiếp.\nLưu lượng từ transit VPC sử dụng ODB peering route trong VPC subnet route table và traffic được chuyển tiếp tới ODB network.\nVì VPC CIDR được bao gồm trong danh sách peered CIDRs, các cấu hình trên phía Oracle OCI đã được thiết lập để cho phép lưu lượng này. Lưu lượng phản hồi theo đường dẫn ngược trở lại các instance EC2 ban đầu.\nConnectivity pattern 3: Multi-Region scalable connectivity sử dụng AWS Cloud WAN Trong pattern này, chúng ta xem xét network connectivity tới ODB từ nhiều vùng và on-premises networks. AWS Cloud WAN đơn giản hóa multi-Region connectivity thông qua dynamic route propagation. đơn giản hóa kết nối đa vùng thông qua việc truyền tải đường dẫn động. Bạn có thể sử dụng điều này để kết nối các trung tâm dữ liệu, branch offices và VPC của mình trên nhiều khu vực thành một mạng thống nhất, tất cả đều được kiểm soát thông qua một global policy duy nhất. AWS Cloud WAN hỗ trợ built-in segmentation, nghĩa là bạn có thể dễ dàng quản lý sự cách ly mạng giữa các Regions và on-premises locations. Bằng cách sử dụng network segments, bạn có thể chia global network thành các isolated networks riêng biệt. Để biết thêm thông tin, xem qua AWS Cloud WAN User Guide.\nTại thời điểm viết bài, tính năng kết nối tích hợp cho mạng ODB không được hỗ trợ với AWS Cloud WAN. Bằng cách kết nối mạng ODB của bạn với một VPC trung chuyển và sau đó kết nối VPC trung chuyển đó với mạng lõi AWS Cloud WAN, bạn có thể sử dụng AWS Cloud WAN để định tuyến lưu lượng mạng giữa mạng ODB của bạn và nhiều VPC trên các Regions cũng như on-premises locations. Trong pattern này, peered VPC đóng vai trò như transit VPC dựa trên peered VPC usage pattern. Bạn cần đảm bảo rằng transit VPC attachment tới AWS Cloud WAN core network được tạo trong một Availability Zone duy nhất — giống như ODB network.\nNhằm đơn giản hóa, chúng tôi đã hiển thị tất cả application VPCs cần truy cập ODB network được liên kết với ODB application VPC segment, trong khi Direct Connect gateway được liên kết với hybrid segment và segment sharing được bật giữa cả hai segments. Để hiểu rõ các bước cấu hình chi tiết, xem Configuring AWS Cloud WAN for Oracle Database@AWS.\nWorkflow bao gồm các thành phần sau:\nEC2 instances trong application VPC resolve database hostname nhằm lấy IP address và khởi tạo database connections bằng IP này. Việc tra cứu bảng định tuyến của subnet VPC diễn ra, và gói tin được chuyển tiếp đến AWS Cloud WAN core network thông qua kết nối VPC AWS Cloud WAN.\nApplication VPC 1 được liên kết với ODB application VPC segment, trong đó các attachment CIDRs liên kết được truyền động. Vì việc liên kết tích hợp với mạng ODB hiện chưa được hỗ trợ trên AWS Cloud WAN, chúng tôi tạo một đường dẫn tĩnh nối đến kết nối VPC trung chuyển.\nTraffic từ VPC trung chuyển sử dụng đường dẫn kết nối ODB trong bảng định tuyến mạng con và lưu lượng được chuyển tiếp đến mạng ODB.\nNhư đã nêu trong phần trước, các CIDRs cần thiết cho application VPCs và on-premises network được thêm vào danh sách peered CIDR trên ODB network. Lưu lượng phản hồi theo đường dẫn ngược trở lại các instance EC2 gốc.\nCác yếu tố cần xem xét Khi triển khai kết nối mạng ODB@AWS, hãy lưu ý các yếu tố kỹ thuật và thiết kế quan trọng sau đây để giúp bạn lập kế hoạch và triển khai một kiến trúc thành công:\nkhi tạo ODB network, hãy cân nhắc các yêu cầu IP address space requirements , bao gồm non-overlapping CIDRs với các connected networks và reserved IP ranges không thể sử dụng. Các CIDR ranges này không thể thay đổi sau khi ODB network được tạo.\nThiết lập ODB peering không tự động thêm routes cho ODB network CIDRs (client CIDR hoặc backup CIDR) vào peered VPC route tables. Bạn phải thủ công chạy lệnh aws ec2 create-route để thêm các routes này vào VPC route tables khi cần. Xem thêm configuring VPC route tables for ODB peering cho lệnh AWS Command Line Interface (AWS CLI) cụ thể.\nKhi thiết lập ODB peering với một VPC, primary VPC CIDR sẽ tự động được thêm vào danh sách peered CIDR. Secondary CIDRs của peered VPC phải được thêm thủ công. Hiện tại, bạn không thể chỉnh sửa primary CIDR được thêm tự động này để giới hạn nó chỉ với các subnet CIDRs cụ thể của VPC.\nKhi một entry được thêm vào danh sách peered CIDR, automation phía OCI sẽ diễn ra để hỗ trợ kết nối. Một static route mới được thêm vào trong route rules (tương đương VPC route table) gắn với Virtual Cloud Network (tương đương Amazon VPC) để cho phép traffic tới CIDR range đó. Ngoài ra, các entries cũng được thêm vào security rules (tương đương AWS security groups và network ACLs) để cho phép ICMP traffic (cho MTU path discovery và ping), TCP traffic trên port 22 (cho SSH), và các TCP ports khác cần cho database traffic.\nRoute 53 Resolver outbound endpoints có thể được triển khai trong peered VPC hoặc một VPC riêng biệt do networking team của bạn quản lý. Nếu bạn đã có outbound endpoints để hỗ trợ hybrid DNS resolution, bạn có thể sử dụng chúng. Trong cả hai trường hợp, hãy đảm bảo VPC CIDR chứa endpoint được thêm vào danh sách peered CIDRs của ODB và tồn tại network connectivity giữa endpoint VPC và peered VPC (thông qua Transit Gateway hoặc AWS Cloud WAN).\nRoute 53 profiles có thể được sử dụng để share resolver rules giữa nhiều AWS accounts thay vì chia sẻ trực tiếp từng rule riêng lẻ bằng AWS RAM.\nMulti-Region connectivity cũng có thể đạt được bằng cách sử dụng Transit Gateway inter-Region peering thay vì Cloud WAN. Cách tiếp cận này yêu cầu static routing configuration giữa các peered transit gateways.\nMột transit VPC không thể đồng thời attach tới cả Transit Gateway và AWS Cloud WAN, hoặc nhiều transit gateways hay Cloud WAN core networks. Bạn phải chọn một transit service duy nhất cho connectivity.\nVới pattern 1 account placement, ODB network được cung cấp trong tài khoản của người mua và có thể được chia sẻ bằng AWS RAM với nhiều tài khoản khác. Tuy nhiên, tại thời điểm viết, chỉ một peering connection có thể được thiết lập tới ODB network. Điều này đồng nghĩa rằng bạn có thể chia sẻ ODB network bằng AWS RAM cho một tài khoản khác và tạo ODB peering connection với application VPC trong tài khoản đó, cung cấp sự linh hoạt cho cross-account application deployments. Xem thêm Resource sharing in Oracle Database@AWS cho các thông tin chi tiết.\nVới pattern 2 và 3 account placements, khi triển khai Transit Gateway và AWS Cloud WAN connectivity, cả transit VPC và ODB network phải nằm trong cùng một tài khoản AWS — cụ thể là tài khoản của người mua nơi ODB network được cung cấp. Tuy nhiên, Transit Gateway và AWS Cloud WAN có thể nằm trong một tài khoản khác (chẳng hạn như central networking account) và được chia sẻ với tài khoản mua hàng bằng AWS RAM để thiết lập kết nối cần thiết.\nĐó là các hạn chế tính đến thời điểm xuất bản blog hiện tại và có thể được cải thiện sớm trong tương lai.\nKết Luận Trong bài viết này, chúng tôi đã trình bày khả năng tích hợp mạng của Oracle Database@AWS, cung cấp một giải pháp mạnh mẽ và linh hoạt cho các doanh nghiệp để mở rộng sức mạnh của cơ sở dữ liệu Oracle Exadata một cách liền mạch trong AWS Cloud. Oracle Database@AWS cung cấp cho các tổ chức nhiều tùy chọn linh hoạt để tích hợp các Oracle database deployments với AWS infrastructure rộng hơn và hybrid environments. Bằng cách lựa chọn peer trực tiếp ODB network với một VPC duy nhất, sử dụng Transit Gateway để kết nối nhiều VPCs, hoặc tận dụng kết nối tập trung của AWS Cloud WAN, bạn có thể chọn cấu hình mạng phù hợp nhất với yêu cầu cụ thể của mình. Đối với các tổ chức cần IP-agnostic connectivity, hỗ trợ IP address space trùng lặp, hoặc các tích hợp chuyên biệt như zero-ETL và Amazon Simple Storage Service (Amazon S3) access, hãy tham khảo Oracle Database@AWS network connectivity Using Amazon VPC Lattice.\nVề các tác giả\nSameer Malik\nSameer đã có hơn 23 năm kinh nghiệm làm việc với cơ sở dữ liệu quan hệ và hiện đang giữ vị trí Principal Database Solution Architect tại AWS, tập trung vào RDS và Aurora. Anh đã hỗ trợ nhiều khách hàng trong việc di chuyển và hiện đại hóa các tải công việc cơ sở dữ liệu của họ sang AWS.\nAnvesh Koganti\nAnvesh là Solutions Architect tại AWS chuyên về Networking. Anh tập trung vào việc giúp khách hàng xây dựng kiến trúc mạng cho các môi trường AWS có khả năng mở rộng cao và độ tin cậy. Ngoài công việc, Anvesh đam mê công nghệ tiêu dùng và thích nghe podcast về công nghệ và kinh doanh. Khi rời xa thế giới kỹ thuật số, Anvesh dành thời gian ngoài trời đi bộ đường dài và đạp xe.\nShubham Singh\nShubham là Senior Network Specialist Solutions Architect tại AWS. Anh giúp khách hàng thiết kế các giải pháp sáng tạo, bền vững và hiệu quả về chi phí bằng cách sử dụng các dịch vụ AWS. Anh đam mê công nghệ và thích xây dựng các giải pháp trong lĩnh vực Mạng và Bảo mật. Anh có bằng Thạc sĩ Telecommunication Systems Management từ Đại học Northeastern, chuyên ngành Computer Networking.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"NỀN TẢNG TRỰC TUYẾN ĐỂ THEO DÕI VÀ DỰ BÁO QUỸ ĐẠO BÃO Kỹ thuật tự nhận thức trắc địa (Geodesic-Aware Deep Learning) cho dự đoán hướng di chuyển chính xác: Một phương pháp tiếp cận dựa trên kêt hợp \u0026ldquo;mô phỏng vật lý\u0026rdquo; và \u0026ldquo;tăng cường dữ liệu\u0026rdquo; Proposal Document Xem Proposal Document\n1. Tóm tắt điều hành Dữ liệu chuỗi thời gian đóng vai trò là một trong những dạng biểu diễn thông tin quan trọng nhất trong các ứng dụng khoa học và công nghiệp hiện đại. Nó cần thiết để hiểu các quá trình động như xu hướng kinh tế, mô hình tiêu thụ năng lượng và sự thay đổi khí tượng theo thời gian. Đặc biệt, dự báo thời tiết phụ thuộc mạnh mẽ vào dữ liệu chuỗi thời gian để dự đoán điều kiện khí quyển trong tương lai, quỹ đạo bão và các biến động theo mùa dựa trên dữ liệu lịch sử.\nVới sự phát triển nhanh chóng trong nghiên cứu về học sâu và mạng nơ-ron, dự án của chúng tôi hướng đến việc phát triển một mô hình dự báo tiên tiến có khả năng dự đoán chính xác đường đi, cường độ và tổng quãng đường di chuyển của các cơn bão trong vài ngày tiếp theo. Các dự đoán này có thể hỗ trợ hệ thống cảnh báo sớm, giúp chính quyền và cư dân tại các khu vực bị ảnh hưởng có thể đưa ra biện pháp phòng tránh trước khi bão đổ bộ.\nĐể vượt qua những hạn chế của công nghệ và nghiên cứu hiện tại, nghiên cứu này giới thiệu một số kỹ thuật và thuật toán mới, bao gồm hai phương pháp tăng cường dữ liệu mới cho chuỗi thời gian trắc địa và một cơ chế mã hóa không gian được thiết kế để nâng cao hiệu suất dự đoán của điện toán tích chập. Hệ thống cuối cùng sẽ được tích hợp vào kiến trúc đám mây không máy chủ trên AWS, đảm bảo khả năng mở rộng, tính khả dụng cao và hiệu quả chi phí cho việc theo dõi và phân tích bão theo thời gian thực.\nKiến trúc hệ thống tận dụng một số dịch vụ AWS để tạo thành một quy trình xử lý và triển khai dữ liệu được quản lý hoàn toàn. Các hàm AWS Lambda đóng vai trò là là xương sống cho hoạt động tính toán không máy chủ, được kích hoạt tự động bởi Amazon EventBridge để thu thập và xử lý dữ liệu bão mới từ các nguồn khí tượng mở theo lịch trình. Dữ liệu đã xử lý được lưu trữ an toàn trên Amazon S3, trong khi AWS CodePipeline và CodeBuild tự động hóa việc tích hợp và triển khai liên tục các phiên bản mô hình mới. Mô hình sau khi huấn luyện được lưu trữ và cung cấp qua Amazon API Gateway, cho phép nền tảng dự báo trực tuyến thực hiện các yêu cầu suy luận nhẹ, theo thời gian thực. Mọi hoạt động của hệ thống được giám sát thông qua Amazon CloudWatch, cung cấp khả năng quan sát hoạt động, phát hiện lỗi và các số liệu hiệu suất.\nPhương pháp đầu tiên được đề xuất, Khung Tăng cường Dữ liệu Phai mờ Theo Thời Gian Theo Từng Bước (Stepwise Temporal Fading Augmentation - STFA), là một khuôn khổ tăng cường dữ liệu chuỗi thời gian mới, mô phỏng sự suy giảm tự nhiên của ảnh hưởng từ các quan sát trong quá khứ. Khác với các phương pháp tiếp cận truyền thống dựa trên việc gây nhiễu ngẫu nhiên hoặc bơm nhiễu, STFA áp dụng các trọng số phai mờ cho các bước thời gian trước đó trong khi vẫn bảo toàn thông tin gần đây. Quá trình này tạo ra các chuỗi tổng hợp đa dạng và chân thực, từ đó cải thiện độ mạnh mẽ và khả năng khái quát hóa của mô hình. Kỹ thuật này sẽ được đánh giá trên các tác vụ dự báo quỹ đạo bão, vốn dựa trên dữ liệu vĩ độ-kinh độ tuần tự.\nPhương pháp thứ hai, Tăng cường Hướng đi Trắc địa Hợp lý (Plausible Geodesic Bearing Augmentation - PGBA), giới thiệu một chiến lược tăng cường dựa trên phạm vi khả thi của hướng di chuyển và khoảng cách của bão. Bằng cách phân tích hướng đi trắc địa (geodesic bearing) và khoảng cách giữa các vị trí bão liên tiếp, PGBA xác định một biên giới chuyển động thực tế, trong đó các quỹ đạo tổng hợp mới được tạo ra. Cách tiếp cận này nâng cao khả năng của mô hình trong việc nắm bắt sự biến đổi không gian tự nhiên và độ bất định về hướng trong chuyển động của bão.\nNgoài ra, nghiên cứu này còn khám phá một biểu diễn không gian-thời gian (spatial-temporal representation) của dữ liệu chuỗi thời gian, cho phép áp dụng các mạng nơ-ron tích chập (Convolutional Neural Networks - CNNs) để nắm bắt cả sự phụ thuộc về không gian và thời gian. Biểu diễn này tận dụng thế mạnh của điện toán tích chập để mô hình hóa các tương tác cục bộ trên không gian và thời gian. Nó sẽ đóng vai trò là cơ sở (baseline) để so sánh với các mô hình Mạng Tích chập Thời gian (Temporal Convolutional Network - TCN) được huấn luyện bằng các phương pháp tăng cường dữ liệu đã được đề xuất.\nCác mạng nơ-ron truyền thống, dù được sử dụng cho mô hình hóa dữ liệu chuỗi thời gian hay dữ liệu ảnh, chủ yếu chỉ học các mẫu thống kê từ dữ liệu. Tuy nhiên, trong nhiều hệ thống vật lý thực tế, các mô hình hoàn toàn dựa trên dữ liệu như vậy có thể không tuân thủ các ràng buộc tự nhiên, chẳng hạn như các mối quan hệ trọng lực hoặc trắc địa. Để khắc phục hạn chế này, chúng tôi kết hợp các nguyên lý của Học máy Thông tin Vật lý (Physics-Informed Machine Learning - PIML) vào phương pháp tiếp cận của mình.khoảng cách trắc địa và phương vị được lấy từ dữ liệu vĩ độ-kinh độ và được tích hợp vào quá trình huấn luyện của mô hình như như những đặc trưng mang ý nghĩa vật lý. Hơn nữa, chúng tôi sử dụng công thức Haversine — công thức tính khoảng cách hình cầu giữa hai điểm - làm một số hạng mất mát phụ, bổ sung cho các số liệu sai số chuẩn như MSE, RMSE, MAE và MAPE.\nBằng cách kết hợp các phương pháp tăng cường dữ liệu được đề xuất, các nguyên tắc học máy thông tin vật lý (PIML) và một cơ sở hạ tầng học sâu không máy chủ được vận hành bởi các dịch vụ AWS, nghiên cứu này hướng đến mục tiêu phát triển một khuôn khổ dự báo quỹ đạo bão có khả năng mở rộng, mạnh mẽ và chính xác. Hệ thống thu được không chỉ nâng cao trình độ mô hình hóa chuỗi thời gian trắc địa mà còn chứng minh tính thực tiễn của việc triển khai các hệ thống dự báo môi trường dựa trên AI như các ứng dụng bản địa đám mây (cloud-native) bền bỉ, giúp tăng cường khả năng chuẩn bị và đảm bảo an toàn cho các khu vực dễ bị ảnh hưởng bởi bão.\n2. Tuyên bố vấn đề Vấn đề hiện tại? Để phát triển một nền tảng đáng tin cậy nhằm theo dõi và đưa ra cảnh báo về đường đi của bão trong tương lai, việc xây dựng một mô hình máy học vừa chính xác vừa có khả năng đưa ra các dự đoán đáng tin cậy là hết sức quan trọng. Thành phần theo dõi có thể được giải quyết bằng cách liên tục thu thập và cập nhật dữ liệu từ các nguồn khí tượng công cộng. Tuy nhiên, các tập dữ liệu này thường bị giới hạn về mặt địa lý và chứa nhiều thông tin trùng lặp hoặc không đầy đủ.\nNgược lại, thành phần dự báo lại có độ phức tạp cao hơn. Việc đạt được dự báo chuỗi thời gian chính xác trong bối cảnh này thường phải đối mặt với hai thách thức chính: (1) tính đa dạng và phạm vi bao phủ của dữ liệu có sẵn còn hạn chế, và (2) sự thiếu vắng các nguyên tắc vật lý nền tảng, điều này làm hạn chế khả năng của mô hình trong việc phản ánh các động lực địa vật lý cơ bản của hành vi bão.\nThiếu dữ liệu: Nhiều tác vụ dự báo chuỗi thời gian gặp hạn chế về lượng dữ liệu huấn luyện. Mặc dù có nhiều phương pháp tăng cường dữ liệu, nhưng rất ít phương pháp tập trung trực tiếp vào sự suy giảm tầm quan trọng của các giá trị trong quá khứ theo thời gian.\nBỏ qua yếu tố vật lý:: Hầu hết các mạng nơ-ron chỉ học từ dữ liệu thô mà không xét đến các ràng buộc vật lý trong thế giới thực. Trong các tác vụ dự đoán quỹ đạo (ví dụ: bão), điều này thường dẫn đến những kết quả phi thực tế.\nMục tiêu của nhóm :\nPhát triển một phương pháp tăng cường chuỗi thời gian mới (STFA) nhằm cải thiện độ bền vững và khả năng khái quát của mô hình. Tích hợp các ràng buộc dựa trên vật lý vào quá trình huấn luyện mô hình, thu hẹp khoảng cách giữa học máy dựa trên dữ liệu và động lực học của thế giới thực. Kiểm tra sức mạnh của mạng tích chập (convolution2D) trong việc dự báo quỹ đạo. Xây dựng một nền tảng trực tuyến cung cấp thông tin mới nhất về các cơn bão hiện tại và các dự đoán chính xác về quỹ đạo của chúng. Giải Pháp A - Tăng cường cường dữ liệu bằng Stepwise Temporal Fading (STFA) STFA biến đổi các chuỗi thời gian bằng cách giảm dần ảnh hưởng của các giá trị trong quá khứ. Khác với phương pháp thêm nhiễu ngẫu nhiên, nó áp dụng một cách có hệ thống các hệ số phai mờ theo từng bước vào các nhóm dữ liệu cũ.\nCho một chuỗi đơn biến là:\n$$ X = [x_0, x_1, \\ldots, x_{T-1}] $$\ntrong đó $T$ là độ dài của chuỗi $X$.\nCác tham số:\n$n$: khoảng giá trị gần nhất muốn giữ nguyên $S$: số dải được áp dụng phai dần $L = T - n$: độ dài của vùng phai dần $k = \\frac{L}{S}$: số giá trị trong mỗi dải $I_b$: tập chỉ số của dải thứ $b$ \\[ I_b = {, i \\mid L - b \\cdot k ;\\leq; i ;\\leq; L - (b-1)\\cdot k - 1 ,} \\]\nBiến đổi::\nKý hiệu chuỗi dữ liệu đã được tăng cường là:\n$$ X = [x_0, \\ldots, x_{T-1}] $$\nvới các quy tắc biến đổi sau:\n$$ x_t = \\begin{cases} x_t, \u0026amp; t \\in {T-n, \\ldots, T-1}, \\\\ m_b , x_t, \u0026amp; t \\in I_b, \\\\ m_{S+1} , x_t, \u0026amp; t \u0026lt; \\min(I_S), \\end{cases} $$\ntrong đó các hệ số nhân $m_b \\in (0,1)$ giảm dần đều từ các nhóm dữ liệu gần nhất tới các dữ liệu cũ hơn.\nCông thức này duy trì độ thực tế, chính xác của các dữ liệu gần đây trong khi kiểm soát chặt chẽ hơn ảnh hưởng của các giá trị xa trong chuỗi. Việc tăng cường này buộc mô hình tập trung vào các mẫu hình mạnh mẽ hơn thay vì chỉ phụ thuộc vào dữ liệu thô, đồng thời gia tăng tính đa dạng của dữ liệu theo các tham số được chọn.\nB - Tăng Cường theo Hướng Di Chuyển Hợp Lý (PGBA - Plausible Geodesic Bearing Augmentation) Kỹ thuật Tăng cường Hướng Di chuyển (dựa trên) Trắc địa Hợp lý (PGBA) nâng cao tính chân thực và khả năng kiểm soát của việc tạo ra quỹ đạo trong các tác vụ dự báo chuỗi thời gian không gian địa lý. Khác với các phương pháp nhiễu loạn ngẫu nhiên thông thường, PGBA đưa vào yếu tố ngẫu nhiên nhưng vẫn đảm bảo sự hợp lý trong các ràng buộc vật lý của chuyển động cơ bản. Các quỹ đạo được tạo ra bắt nguồn từ các mối quan hệ hình học của các quan sát trong quá khứ thay vì từ các bước hoàn toàn ngẫu nhiên, dẫn đến các đường đi mượt mà hơn và tính biến thiên có ý nghĩa trong tập dữ liệu huấn luyện. Kỹ thuật này được áp dụng cho mỗi bốn vị trí trong một chuỗi dữ liệu.\nPGBA đóng vai trò là phương pháp tăng cường bổ trợ cho STFA, làm phong phú thêm tính đa dạng của các mẫu huấn luyện trong khi vẫn bảo toàn cấu trúc động học ban đầu. Mục tiêu của nó là tạo ra các quỹ đạo dư thừa nhưng vẫn đảm bảo tính nhất quán vật lý, từ đó nắm bắt được các biến thể tiềm năng trong chuyển động của bão hoặc các hiện tượng không gian địa lý tương tự.\nCơ chế cốt lõi\nXét một quỹ đạo bão được biểu diễn bằng một chuỗi $n$ các vị trí địa lý theo thứ tự:\n$$ P = [P_1, P_2, \\ldots, P_n] $$\nChúng tôi chia chuỗi này thành các khối nhỏ gồm 4 điểm, với $P_i$ là điểm bắt đầu của mỗi khối, được xác định bởi vĩ độ và kinh độ:\n$$ P_i = (\\phi_i, \\lambda_i) $$\nỞ đây, $\\phi_i$ và $\\lambda_i$ lần lượt biểu thị cho vĩ độ và kinh độ theo đơn vị radian.\nKhoảng cách trắc địa $d_i$ và góc phương vị $\\theta_i$ giữa hai điểm liên tiếp $P_i$ và $P_{i+1}$ được xác định như sau:\n$$ d_i = \\text{Distance}(P_i, P_{i+1}), \\qquad \\theta_i = \\text{Bearing}(P_i, P_{i+1}) $$\nĐể tạo ra biến đổi hợp lý, PGBA làm nhiễu góc phương vị bằng cách thêm một nhiễu ngẫu nhiên nhỏ có phân phối đều $\\epsilon_i$:\n$$ \\theta_i^{\\text{aug}} = \\theta_i + \\epsilon_i, \\qquad \\epsilon_i \\sim \\text{Uniform}(-\\delta, \\delta) $$\ntrong đó $\\delta$ là giới hạn góc có thể điều chỉnh để kiểm soát phạm vi lệch.\nHai điểm đầu tiên luôn được giữ nguyên và được sử dụng để tính toán khoảng cách và hướng di chuyển. Điểm tiếp theo được tăng cường sau đó được tính toán bằng công thức định vị trắc địa, giữ nguyên khoảng cách trong khi cho phép hướng di chuyển thay đổi trong phạm vi nhiễu ngẫu nhiên:\n$$ P_{i+2}^{\\text{aug}} = \\text{Destination}(P_i, d_i, \\theta_i^{\\text{aug}}) $$\nQuá trình này bảo toàn khoảng cách giữa các điểm $d_i$ trong khi làm lệch hướng một cách nhẹ để tạo ra các độ lệch hợp lý về mặt vật lý.\nLàm mượt và Hiệu chỉnh Đa Bước\nĐể nâng cao độ mượt và tạo ra các quỹ đạo cong tự nhiên, PGBA áp dụng một hiệu chỉnh tại mỗi điểm thứ tư. Gọi $P_{i+3}^{\\text{aug}}$ là điểm thứ tư. Nó được tính toán lại sao cho góc phương vị $\\theta_{i+3}^{\\text{corr}}$ của nó tối thiểu hóa độ lệch so với điểm gốc $P_{i+3}$:\n$$ \\theta_{i+3}^{\\text{corr}} = \\arg\\min_{\\theta}; \\text{Distance}\\Big( \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta),; P_{i+3} \\Big) $$\nSau đó, điểm tăng cường đã hiệu chỉnh được xác định như sau:\n$$ P_{i+3}^{\\text{aug}} = \\text{Destination}(P_{i+2}^{\\text{aug}}, d_{i+2}, \\theta_{i+3}^{\\text{corr}}) $$\nBước này đảm bảo sự chuyển tiếp mượt mà giữa nhiều điểm trong khi vẫn duy trì tính hợp lý về mặt vật lý.\nLưu ý rằng hai điểm đầu tiên và điểm cuối cùng trong mỗi chuỗi thời gian trắc địa luôn được giữ nguyên không thay đổi.\nC - Học máy (Machine Lerning) dựa trên vật lý Các mô hình mạng nơ-ron như RNNs, CNNs, và Transformers không cần công thức hay quy tắc đặc thù cho từng tác vụ để đạt hiệu suất tốt, miễn là chúng được huấn luyện với đủ dữ liệu. Ví dụ, trong tác vụ dịch máy như dịch từ tiếng Đức sang tiếng Anh bằng RNN, không có quy tắc ngữ pháp nào được cung cấp trong quá trình huấn luyện (không tính stemming, letmat, pos tagging, \u0026hellip; chỉ nói đến quá trình huấn luyện). Tuy nhiên, mô hình vẫn có thể tạo ra bản dịch mạch lạc, thể hiện một trong những điểm mạnh chính của học sâu: khả năng học trực tiếp các mẫu phức tạp từ dữ liệu. Ngược lại, các phương pháp truyền thống — chẳng hạn như các hệ thống dịch dựa trên quy tắc (ví dụ: Google Translate trước những năm 2000) — phụ thuộc nhiều vào quy tắc ngữ pháp và từ điển. Mặc dù chính xác, nhưng các hệ thống này thường thiếu linh hoạt và thất bại khi gặp từ có nhiều nghĩa hoặc các cấu trúc phụ thuộc vào ngữ cảnh.\nLấy cảm hứng từ sự khác biệt đó, mục tiêu của chúng tôi là kết hợp sức mạnh của học sâu với các công thức do con người định nghĩa để đạt hiệu suất tốt hơn. Cụ thể trong lĩnh vực địa lý này, chúng tôi sẽ thử đưa các lợi ích từ công thức Haversine vào quá trình huấn luyện để tính toán khoảng cách và góc phương vị giữa hai vị trí trên một hình cầu. Những yếu tố này cung cấp cho mô hình một cấu trúc bổ sung và độ lệch quy nạp, định hướng việc học vượt ra ngoài các tương quan thuần túy thống kê.\nCông thức Haversine\nĐối với việc tính toán khoảng cách\nCông thức Haversine được sử dụng để tính khoảng cách cung lớn giữa hai điểm trên bề mặt hình cầu — tức là đường đi ngắn nhất trên bề mặt Trái Đất.\n$$ d = 2r , \\arcsin!\\left( \\sqrt{ \\sin^2!\\left(\\frac{\\Delta \\varphi}{2}\\right) + \\cos(\\varphi_1)\\cos(\\varphi_2) \\sin^2!\\left(\\frac{\\Delta \\lambda}{2}\\right) } \\right) $$\nTrong đó:\n$$(\\varphi_1, \\lambda_1)$$ và $$(\\varphi_2, \\lambda_2)$$ là vĩ độ và kinh độ của hai điểm (tính bằng raidian). $\\Delta \\varphi = \\varphi_2 - \\varphi_1$ $\\Delta \\lambda = \\lambda_2 - \\lambda_1$ $r$ là bán kính Trái Đất (≈ 6,371 km). Trong khuôn khổ của chúng tôi, thay vì chỉ dựa vào các hàm mất mát tiêu chuẩn như MSE, RMSE hay MAPE, chúng tôi đề xuất sử dụng công thức Haversine để tính khoảng cách làm hàm mất mát chính. Khi mô hình xuất ra tọa độ vĩ độ và kinh độ cho vị trí bão tiếp theo, công thức Haversine trực tiếp đo lường khoảng cách giữa điểm dự đoán và điểm thực tế. Khoảng cách gần 0 cho thấy dự đoán có độ chính xác cao, trong khi khoảng cách lớn báo hiệu một sai số đáng kể.\nĐối với việc tính toán góc phương vị (bearing)\nCông thức tính góc phương vị được suy ra từ Công thức Haversine, cho biết hướng đi từ một điểm địa lý này đến một điểm khác dọc theo đường tròn lớn:\n$$\\theta = \\text{atan2}!\\left(\\sin(\\Delta \\lambda)\\cos(\\varphi_2),, \\cos(\\varphi_1)\\sin(\\varphi_2) - \\sin(\\varphi_1)\\cos(\\varphi_2)\\cos(\\Delta \\lambda)\\right)$$\nTrong đó:\n$(\\varphi_1, \\lambda_1)$ là điểm xuất phát. $(\\varphi_2, \\lambda_2)$ là điểm kết thúc. $\\Delta \\lambda$ là hiệu số kinh độ. Kết quả $\\theta$ đại diện cho góc phương vị ban đầu (azimuth) được đo theo chiều kim đồng hồ từ hướng Bắc thực.\nTrong quá trình triển khai, chúng tôi tận dụng triệt để việc sử dụng Công thức Haversine để tính toán hai đặc trưng bổ sung — \u0026ldquo;khoảng cách\u0026rdquo; và \u0026ldquo;góc phương vị\u0026rdquo; — được thêm vào tập dữ liệu. Các đặc trưng này cung cấp cho mô hình thông tin phong phú hơn về quỹ đạo bão, đồng thời vẫn duy trì mục tiêu cốt lõi là dự đoán vị trí địa lý tiếp theo.\nD - Tổng quan ngắn về những hiểu lầm phổ biến trong các phương pháp tiếp cận mô hình hóa chuỗi Trong lĩnh vực mô hình hóa chuỗi thuộc học sâu, các kiến trúc dạng hồi quy như RNN, LSTM và GRU thường được coi là giải pháp mặc định. Nhận thức này đã khiến nhiều người thực hành và nhà nghiên cứu bỏ qua các kiến trúc thay thế, đặc biệt là Mạng Nơ-ron Tích chập (CNN) - vốn thường được liên hệ chủ yếu với các tác vụ xử lý hình ảnh. Sách giáo khoa và các khóa học thường phân loại các tác vụ như mô hình hóa ngôn ngữ, dịch máy, hoặc các dự đoán tuần tự khác là lĩnh vực của các mạng hồi quy, trong khi các mạng tích chập thường chỉ được giới thiệu trong bối cảnh dữ liệu không gian như hình ảnh. Kết quả là, tiềm năng của CNN cho mô hình hóa chuỗi thường bị đánh giá thấp hoặc bị bỏ qua.\nCác mạng tích chập (Convolutional networks) mang lại một số ưu điểm khiến chúng phù hợp cho dữ liệu tuần tự. Tính song song vốn có của chúng cho phép huấn luyện nhanh hơn đáng kể so với các mô hình tuần tự nghiêm ngặt. Ngoài ra, CNN có hiệu quả cao trong việc nắm bắt các quan hệ không gian và thời gian cục bộ - một đặc tính có thể được tận dụng trong dự báo chuỗi thời gian và các tác vụ tuần tự khác. Tuy vậy, CNN thường bị hiểu nhầm là không phù hợp cho chuỗi do thiếu cơ chế bộ nhớ rõ ràng và không có thứ tự thời gian nội tại.\nTrong nghiên cứu của chúng tôi, chúng tôi tập trung vào dự báo quỹ đạo bão, nơi dữ liệu bao gồm các bản ghi chuỗi thời gian của tọa độ vĩ độ và kinh độ. Chúng tôi chứng minh rằng loại dữ liệu tuần tự này có thể được mô hình hóa hiệu quả bằng cách sử dụng CNN, tận dụng hiệu suất tính toán và khả năng nắm bắt các mẫu hình không-thời gian cục bộ của chúng. Để hỗ trợ điều này, chúng tôi mã hóa các vị trí thành một biểu diễn ma trận 2D, cho phép mạng tích chập trích xuất và học các mẫu hình từ dữ liệu hiệu quả hơn. Mỗi mục trong ma trận tương ứng với một \u0026ldquo;điểm ảnh\u0026rdquo; của một hình ảnh, một cách tiếp cận mà chúng tôi gọi là Quỹ đạo-dưới-dạng-Hình ảnh (Trajectory-as-Image). Phương pháp của chúng tôi sử dụng một CNN tiêu chuẩn làm cơ sở, sau đó so sánh nó với các mô hình chuỗi chuyên biệt hơn, bao gồm TCN, LSTM và RNN, đồng thời kết hợp các kỹ thuật tăng cường dữ liệu khác nhau, bao gồm hai phương pháp mới được đề xuất trong công trình này.\nThông qua quá trình thử nghiệm và đánh giá có hệ thống, chúng tôi mong muốn thách thức quan điểm phổ biến cho rằng kiến trúc tích chập không phù hợp với dữ liệu chuỗi. Bằng cách làm nổi bật hiệu quả của CNN trong mô hình hóa chuỗi, chúng tôi hy vọng mở rộng góc nhìn của cộng đồng nghiên cứu và thực hành, khuyến khích họ xem xét điện toán tích chập như một hướng tiếp cận khả thi và cạnh tranh trong dự báo chuỗi thời gian cũng như các tác vụ dự đoán tuần tự khác.\nLợi ích và Hiệu quả đầu tư Tăng hiệu suất: STFA + PGBA tạo ra các chuỗi tổng hợp có cấu trúc giúp tăng cường độ mạnh mẽ của mô hình, giảm hiện tượng quá khớp và cải thiện khả năng khái quát hóa trên các quỹ đạo bão chưa từng thấy.\nNhận thức vật lý: Việc tích hợp các nguyên lý địa lý như khoảng cách và góc phương vị giúp tăng khả năng diễn giải và đảm bảo kết quả dự đoán phù hợp với các ràng buộc vật lý.\nHướng nghiên cứu mới: Thiết lập hai mô hình mới cho việc tăng cường chuỗi thời gian dựa trên sự phai mờ liên quan theo thời gian, mở rộng bộ công cụ phương pháp luận cho học máy chuỗi.\nScalability and Reusability: Khuôn khổ kết hợp STFA + PGBA + PIML có thể được mở rộng sang các lĩnh vực dự báo chuỗi khác như nhu cầu năng lượng, lưu lượng giao thông và xu hướng tài chính.\nTác động tổng thể: Bằng cách cải thiện độ ổn định và khả năng diễn giải của mô hình trong khi vẫn duy trì tính mở rộng, phương pháp được đề xuất mang lại cả giá trị khoa học lẫn hiệu quả thực tiễn trong đầu tư tính toán.\n3. Kiến trúc giải pháp Nền tảng trực tuyến cung cấp cho người dùng thông tin cập nhật về các cơn bão gần đây và một công cụ mạnh mẽ để dự báo quỹ đạo bão. Người dùng có thể xem dữ liệu bão gần đây hoặc chạy các dự đoán bằng các mô hình ML. Kết quả được hiển thị trực quan trên bản đồ, cho thấy vị trí, thời gian và đường đi dự đoán của bão.\nNền tảng được xây dựng bằng kiến trúc không máy chủ trên AWS để giảm chi phí vận hành trong khi vẫn đảm bảo khả năng mở rộng và độ tin cậy. Nội dung frontend được lưu trữ trên Amazon S3 và phân phối toàn cầu thông qua CloudFront, đảm bảo truy cập với độ trễ thấp. Yêu cầu của người dùng được định tuyến qua API Gateway tới các hàm Lambda, nơi xử lý tính toán dự đoán và truy xuất dữ liệu. Các mô hình ML đã được huấn luyện trước và tập dữ liệu bão gần đây được lưu trữ an toàn trong S3, với các bản cập nhật hàng tuần được quản lý tự động bởi trình thu thập dữ liệu kích hoạt qua EventBridge. Các khóa API nhạy cảm được lưu trữ trong Secrets Manager, và hiệu suất hệ thống được giám sát thông qua nhật ký và số liệu trên CloudWatch. IAM thực thi quyền truy cập tối thiểu cho tất cả các dịch vụ.\nCác mô hình dự báo tận dụng các kỹ thuật STFA (Tăng cường Phai mờ Thời gian Theo từng Bước) và PGBA (Tăng cường Hướng đi Trắc địa Hợp lý) được đề xuất. Các phương pháp này tạo ra các quỹ đạo chuỗi thời gian tổng hợp chân thực, bảo toàn mức độ liên quan theo thời gian và tính nhất quán không gian, giúp cải thiện đáng kể độ mạnh mẽ và độ chính xác của mô hình. Bằng cách tích hợp STFA và PGBA, nền tảng cung cấp các dự báo đường đi bão chính xác hơn, giúp người dùng hiểu rõ hơn về hành vi của bão và đưa ra quyết định sáng suốt.\nKiến trúc này cho phép tạo ra một nền tảng phản hồi nhanh, hiệu quả về chi phí và bảo mật, nơi người dùng có thể trực quan hóa thông tin bão theo thời gian thực và khám phá các dự báo quỹ đạo bão với bản đồ tương tác, được hỗ trợ bởi các phương pháp tăng cường tiên tiến để nâng cao hiệu suất mô hình.\nHình 1 : Sơ đồ huấn luyện mô hình Machine Learning Hình 2 : Kiến Trúc Platform Các dịch vụ AWS được sử dụng Amazon S3: Lưu trữ các tệp frontend tĩnh, các mô hình ML đã được huấn luyện trước và dữ liệu bão mới nhất. AWS Lambda: Chạy các mô hình dự đoán, truy xuất dữ liệu bão và thực thi tự động hóa thu thập dữ liệu web. Amazon API Gateway: Xử lý các yêu cầu từ frontend cho dự báo và dữ liệu bão. Amazon CloudFront: Phân phối nội dung tĩnh trên toàn cầu với độ trễ thấp. Amazon Route 53: Định tuyến lưu lượng người dùng đến CloudFront. Amazon EventBridge: Lập lịch trình thu thập dữ liệu hàng tuần. AWS Secrets Manager: Lưu trữ an toàn các khóa API từ bên ngoài. Amazon CloudWatch: Giám sát nhật ký Lambda, số liệu hiệu suất và tình trạng hệ thống. AWS IAM: Gắn quyền truy cập tối thiểu (least-privilege) cho tất cả các dịch vụ. Thiết kế thành phần Lớp Frontend: Được lưu trữ trên S3 và phân phối thông qua CloudFront. Lớp Backend: Xử lý dự báo và truy xuất dữ liệu bằng API Gateway và Lambda. lưu trữ Dữ liệu: Các mô hình ML được lưu trữ trong S3, dữ liệu bão mới nhất được cập nhật hàng tuần bởi trình thu thập dữ liệu. Tự động hóa: EventBridge kích hoạt Crawler Lambda hàng tuần để lấy dữ liệu bão từ các nguồn bên ngoài. Bảo mật \u0026amp; Giám sát: Các thông tin nhạy cảm được lưu trữ trong Secrets Manager, số liệu và nhật ký được thu thập thông qua CloudWatch. 4. Triển Khai Kỹ Thuật Các Giai Đoạn Triển Khai Dự án này có ba phần chính: xây dựng pipeline dự đoán, thiết lập thu thập dữ liệu và triển khai nền tảng web. Mỗi phần trải qua bốn giai đoạn:\nThiết Kế Kiến Trúc: Lên kế hoạch cho hệ thống serverless AWS, các hàm Lambda, cấu trúc S3. (Tuần 1-2) Ước Tính Chi Phí: Sử dụng AWS Pricing Calculator để đánh giá tính khả thi và điều chỉnh thiết kế (Tuần 1-2). Tối Ưu Hóa Kiến Trúc: Điều chỉnh bộ nhớ Lambda, cách sử dụng S3 và bộ nhớ đệm để giảm chi phí (Tuần 2-4). Phát Triển, Kiểm Thử, Triển Khai: Triển khai các hàm Lambda, lập lịch sự kiện, tích hợp mô hình ML và frontend web với Next.js (Tuần 4-8). Yêu Cầu Kỹ Thuật\nCác Mô Hình ML: Các mô hình quỹ đạo được đào tạo sẵn lưu trữ trong S3 (.h5/.pth), được tải bởi hàm Lambda dự đoán. Dữ Liệu Bão: Các tệp JSON được cập nhật hàng tuần, lưu trữ trong S3, được sử dụng để hiển thị frontend và xác thực dự đoán. Cơ Sở Hạ Tầng Serverless: Lambda cho dự đoán, truy xuất và thu thập; API Gateway cho các yêu cầu frontend; CloudFront/S3 để phân phối nội dung. Bảo Mật: Secrets Manager cho khóa API, IAM cho quyền truy cập tối thiểu. Giám Sát: CloudWatch để ghi log và các số liệu Lambda Insights. 5. Tiến Độ \u0026amp; Các Mốc Quan Trọng Dòng Thời Gian Dự Án\nTrước Kỳ Thực Tập (Tuần 1): Lập kế hoạch, nghiên cứu các API thời tiết bên ngoài và chuẩn bị mô hình ML.\nTrong Kỳ Thực Tập (Tuần 1-8):\nTuần 1-2: Nghiên cứu AWS, thiết kế kiến trúc và ước tính chi phí. Tuần 2-4: Tối ưu hóa kiến trúc, cấu hình quy trình không máy chủ và tích hợp các mô hình ML. Tuần 4-8: Triển khai các hàm Lambda, thiết lập frontend, kiểm thử hệ thống và triển khai lên môi trường production. Sau Khi Ra Mắt: Thu thập dữ liệu liên tục và giám sát trong tối đa 1 năm.\n6. Ước Tính Ngân Sách Khu vực: ap-southeast-1 (Singapore)\nChi phí ước tính hàng tháng để vận hành nền tảng dự đoán bão trên AWS như sau:\nA. Frontend \u0026amp; Phân Phối Nội Dung\nAmazon S3 (Tệp Tĩnh): Lưu trữ 5 GB tệp frontend (HTML, CSS, JS) và xử lý 10 GB chuyển dữ liệu mỗi tháng. Chi phí ≈ $0.54/tháng. Amazon CloudFront: Xử lý 50 GB chuyển dữ liệu và lên đến 1 triệu yêu cầu (trong phạm vi miễn phí). Chi phí ≈ $6.00/tháng. Amazon Route 53: 1 hosted zone và 1 triệu truy vấn DNS mỗi tháng. Chi phí ≈ $0.90/tháng. AWS Certificate Manager (ACM): Cung cấp chứng chỉ TLS cho truy cập HTTPS bảo mật. Miễn phí. Tổng cho Frontend \u0026amp; CDN: ≈ $7.4/tháng\nB. Backend (Xử Lý API \u0026amp; ML)\nAmazon API Gateway: Xử lý 1 triệu yêu cầu HTTP API mỗi tháng, mỗi yêu cầu có kích thước khoảng 1 MB. Chi phí ≈ $2.5/tháng. Lambda (Dự đoán Bão): Dự đoán quỹ đạo bão sử dụng các mô hình ML. Chạy ~1,000 lần mỗi ngày với 512 MB bộ nhớ được cấp phát và 1 GB bộ nhớ tạm thời. Mỗi lần thực thi kéo dài ~5 giây. Chi phí ≈ $2.54/tháng. Lambda (Lấy Dữ Liệu Bão Gần Đây): Lấy dữ liệu bão từ S3 cho frontend. Chạy ~20,000 lần mỗi ngày với 512 MB bộ nhớ và 512 MB bộ nhớ tạm thời trong 1 giây mỗi lần thực thi. Chi phí ≈ $0.00/tháng (nằm trong free tier). Tổng cho Backend: ≈ $4.54/tháng\nC. Tự Động Hóa \u0026amp; Thu Thập Dữ Liệu\nAmazon EventBridge: Lập lịch thu thập dữ liệu bão hàng tuần (1 cron trigger mỗi ngày). Miễn phí theo AWS free tier. Lambda (Trình Thu Thập Web): Lấy dữ liệu từ các API bên ngoài hàng tuần. Sử dụng 128 MB bộ nhớ và 512 MB bộ nhớ tạm thời, ~30 giây mỗi lần thực thi. Chi phí ≈ $0.00/tháng (free tier). AWS Secrets Manager: Lưu trữ 5 khóa API để truy cập an toàn vào các dịch vụ thời tiết bên ngoài. Chi phí ≈ $2.00/tháng. Tổng cho Tự Động Hóa \u0026amp; Thu Thập Dữ Liệu: ≈ $2.0/tháng\nD. Giám Sát \u0026amp; Ghi Log\nAmazon CloudWatch Logs: Thu thập logs từ tất cả các hàm Lambda và chuyển đến S3 với thời gian lưu giữ 1 tháng. Khoảng 2 GB logs mỗi tháng. Chi phí ≈ $0.57/tháng. CloudWatch Metrics (Lambda Insights): Giám sát 8 metrics trên các hàm Lambda. 10 metrics đầu tiên miễn phí, và chỉ ghi lại cho dự đoán và dữ liệu thu thập. Chi phí ≈ $0.00/tháng. Tổng cho Giám Sát \u0026amp; Ghi Log: ≈ $0.57/tháng\nE. Lưu Trữ \u0026amp; Truyền Dữ Liệu\nS3 (Bucket Mô Hình): Lưu trữ các mô hình ML (~1 GB) và xử lý ~60,000 yêu cầu GET mỗi tháng. Chi phí ≈ $0.05/tháng. S3 (Bucket Dữ Liệu Bão Gần Đây): Lưu trữ dữ liệu bão gần đây (~1 GB) với ~60,000 yêu cầu GET và 30 yêu cầu PUT mỗi tháng. Chi phí ≈ $0.27/tháng. Tổng cho Lưu Trữ \u0026amp; Truyền Dữ Liệu: ≈ $0.32/tháng\nF. Di chuyển lên AWS\nDùng AWS CodePipeline và CodeBuild cho 10 phút chỉnh sửa mỗi tháng ≈ $0.90/month. Tổng Chi Phí Hàng Tháng Ước Tính\nFrontend \u0026amp; CDN: $7.4 Backend (API + ML): $4.54 Tự động hóa (Crawler + Secrets): $2.0 Giám sát \u0026amp; Ghi log: $0.57 Lưu trữ \u0026amp; Truyền dữ liệu: $0.32 Phí di chuyển kỹ thuật : $0.90 TỔNG CỘNG ≈ $15.73/tháng\n7. Đánh Giá Rủi Ro Các Rủi Ro Chính\nSự cố Mạng: Mức độ ảnh hưởng trung bình, khả năng xảy ra trung bình. Nguồn Dữ liệu Không Khả Dụng: Mức độ ảnh hưởng trung bình, khả năng xảy ra thấp. Lỗi Mô Hình ML: Mức độ ảnh hưởng cao, khả năng xảy ra thấp. Vượt Quá Chi Phí: Mức độ ảnh hưởng trung bình, khả năng xảy ra thấp. Chiến Lược Giảm Thiểu\nMạng: Lưu vào bộ nhớ đệm (cache) dữ liệu bão gần đây trong S3 để cho phép hiển thị frontend trong thời gian xảy ra sự cố. Nguồn Dữ liệu: Lưu trữ dữ liệu bão lịch sử để dự phòng. Mô Hình ML: Xác thực và kiểm tra mô hình thường xuyên. Chi Phí: Giám sát mức sử dụng AWS và thiết lập cảnh báo ngân sách. Kế Hoạch Dự Phòng\nChuyển sang cập nhật thủ công nếu API bên ngoài thất bại. Khôi phục (rollback) về mô hình ML trước đó bằng cách sử dụng tính năng versioning của S3 nếu mô hình mới thất bại. 8. Kết Quả Kỳ Vọng Cải Tiến Kỹ Thuật:\nDự đoán quỹ đạo bão thời gian thực với các đường đi được hiển thị hóa. Hệ thống không máy chủ có khả năng mở rộng, xử lý hàng nghìn yêu cầu/ngày. Giá Trị Lâu Dài:\nDữ liệu bão tập trung cho nghiên cứu và phân tích. Khung (framework) có thể tái sử dụng cho các tác vụ dự đoán không gian địa lý khác. Chi phí vận hành hàng tháng thấp (\u0026lt; $20/tháng). "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.2-data-preparation/","title":"Chuẩn Bị Dữ Liệu","tags":[],"description":"","content":"Thu Thập và Xử Lý Dữ Liệu Dữ liệu là một thành phần quan trọng trong dự án. Nó không chỉ cung cấp nguồn kiến thức cho mô hình machine learning mà còn được hiển thị trực tiếp cho người dùng cuối để theo dõi các cơn bão mới nhất tại khu vực Tây Thái Bình Dương. Vì dữ liệu có mục đích kép — huấn luyện mô hình và trực quan hóa theo thời gian thực — chúng em đã xem xét kỹ lưỡng nhiều nguồn data source đáng tin cậy và có thẩm quyền trước khi chọn một bộ dữ liệu đáp ứng đầy đủ các yêu cầu, đó là: Dữ liệu bão của NOAA.\nNOAA (National Oceanic and Atmospheric Administration) là cơ quan khoa học thuộc Bộ Thương mại Hoa Kỳ. NOAA cung cấp dữ liệu môi trường có độ chính xác cao phục vụ nghiên cứu, bao gồm quan sát thời tiết toàn cầu, ảnh vệ tinh và thông tin về các xoáy thuận nhiệt đới. Với nhiều thập kỷ đầu tư vào công nghệ tiên tiến như vệ tinh địa tĩnh, hệ thống radar và mạng lưới giám sát khí hậu, NOAA được xem là một trong những nguồn cung cấp dữ liệu bão đáng tin cậy nhất trên thế giới.\nTrong dự án này, chúng em sử dụng dữ liệu từ International Best Track Archive for Climate Stewardship (IBTrACS) — một dự án do NOAA khởi xướng và là bộ dữ liệu xoáy thuận nhiệt đới toàn diện nhất thế giới. IBTrACS tổng hợp dữ liệu đường đi của bão trong lịch sử từ nhiều cơ quan khí tượng (ví dụ: JTWC, JMA, CMA, NHC). Bằng cách hợp nhất các nguồn vào một định dạng thống nhất, IBTrACS cải thiện khả năng so sánh giữa các cơ quan và đảm bảo các nhà nghiên cứu trên toàn thế giới có quyền truy cập dữ liệu chất lượng cao nhất.\nPhiên bản mới nhất của bộ dữ liệu này chứa 226.153 dòng ghi nhận quan sát bão. Mỗi dòng bao gồm nhiều thuộc tính giá trị như:\nsid – mã cơn bão number – số thứ tự bão basin / subbasin – phân loại khu vực nature – loại bão (ví dụ: áp thấp, bão nhiệt đới, siêu bão) iso_time – thời gian lat / lon – tọa độ tâm bão … và nhiều thông số khí tượng học khác Tuy nhiên, đối với mô hình machine learning, chúng em chỉ tập trung vào bốn cột chính: sid, iso_time, lat, và lon. Đây là chuỗi thời gian cơ bản dùng để dự đoán quỹ đạo di chuyển của bão.\nBộ dữ liệu bao gồm các cơn bão từ 1870 đến 2025, được lọc chỉ giữ lại các cơn bão trong khu vực Tây Thái Bình Dương — phạm vi địa lý mà dự án hướng đến. Bộ dữ liệu gốc được công khai tại: https://data.humdata.org/dataset/vnm-ibtracs-tropical-storm-tracks#\nLàm sạch dữ liệu và Trích xuất đặc trưng dựa trên quy luật vật lý Một ưu điểm của IBTrACS là dữ liệu đã được bảo trì tốt và có tính nhất quán cao. Việc tiền xử lý chỉ yêu cầu các bước tối thiểu, chủ yếu là loại bỏ giá trị thiếu.\nSau khi làm sạch, chúng em áp dụng bước đầu tiên của machine learning dựa trên vật lý (physics-informed ML) — kỹ thuật đưa kiến thức vật lý trực tiếp vào pipeline dữ liệu. Từ tọa độ vĩ độ – kinh độ, nhóm tính thêm hai đặc trưng bằng công thức Haversine:\nKhoảng cách giữa hai điểm bão liên tiếp Góc phương vị (bearing) — hướng di chuyển Các đặc trưng này mang ý nghĩa vật lý: chúng phản ánh quy luật chuyển động thực tế, thay vì những biến đổi tùy ý. Nhờ đó, chúng tăng cường bối cảnh về quán tính và hướng di chuyển của bão, giúp mô hình học hiệu quả hơn và dự đoán chính xác hơn.\nHình 1 : Mô tả dữ liệu Dữ Liệu Hiển Thị Trên Nền Tảng Dữ liệu dùng để hiển thị trên nền tảng khác với dữ liệu dùng để huấn luyện, dù cả hai đều xuất phát từ NOAA. Dữ liệu huấn luyện là tĩnh, còn dữ liệu hiển thị phải cập nhật theo tình hình bão hiện tại.\nĐể xử lý yêu cầu này, nhóm đã triển khai một AWS Lambda chạy theo lịch, tự động lấy dữ liệu đường đi bão mới nhất vào cuối mỗi ngày. Điều này đảm bảo nền tảng luôn hiển thị thông tin mới, chính xác và kịp thời cho người dùng.\nDữ liệu hiển thị sau xử lý được lưu dưới dạng file JSON trong S3. Khi người dùng truy cập website:\nFrontend gửi yêu cầu tới API Gateway API Gateway kích hoạt Lambda tương ứng Lambda lấy file JSON từ S3 Dữ liệu được trả về cho người dùng để hiển thị trực quan Pipeline này đảm bảo khả năng cập nhật thời gian thực, serverless và tiết kiệm chi phí.\nBộ dữ liệu bão có thể truy cập tại: https://ncics.org/ibtracs/\nHình 2 : Web để crawl dữ liệu "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.3-event3/","title":"Reinventing DevSecOps with AWS Generative AI","tags":[],"description":"","content":"Bài thu hoạch “Reinventing DevSecOps with AWS Generative AI” Mục Đích Của Sự Kiện Chia sẽ về DevSecOps đã có những bước chuyển mình trong tự động hoá vận hành hệ thống bằng AI như thế nào. Cung cấp kiến thức chit tiết về quy trình DecSecOps Giải đáp thắc mắc các kỹ sư DevSecOps đang ứng dụng AI như thế nào để tái định hình chu trình và kiến tạo những thay đổi ? Danh Sách Diễn Giả Lê Thanh Đức - Cloud Delivery Manager, CMC Global Dư Quốc Thành - Technical Leader, CMC Global Văn Hoàng Kha - Cloud Engineer, AWS Community Builder Nội Dung Nổi Bật Giới thiệu tổng quan về Devsecops Framework Devsecops không chỉ là chu trình Devops thông thường. Tích hợp bảo mật cho nhiều part và cả vòng đời. Debsecops Lifecycle Vòng đời của Devsecops bao gồm bảy thành phần chính, bắt đầu từ lên kế hoạch cho đến triển khai vận hành. Chi tiết sẽ được nêu ở bên dưới: Dưới đây là nội dung tất cả các bước trong DEVSECOPS LIFECYCLE được viết theo định dạng bạn yêu cầu:\n1. PLAN - Lập kế hoạch:\nXác định yêu cầu \u0026amp; rủi ro bảo mật ngay từ đầu. Thống nhất mục tiêu giữa Dev-Sec-Ops. Tạo security roadmap gắn với mục tiêu dự án. 2. CODE - Viết mã:\nÁp dụng secure coding standard \u0026amp; code review. Dùng SAST để phát hiện lỗi sớm. Hình thành tư duy \u0026ldquo;security-first\u0026rdquo; cho developer. 3. BUILD - Xây dựng:\nTự động kiểm tra bảo mật trong CI/CD pipeline. Thực hiện dependency \u0026amp; binary scan. Đảm bảo build an toàn và nhất quán. 4. TEST - Kiểm thử:\nChạy vulnerability scan, DAST, pen test. Xác thực ứng dụng đáp ứng yêu cầu bảo mật. Cập nhật test theo lỗ hổng mới phát sinh. 5. DEPLOY - Triển khai:\nKiểm tra config \u0026amp; IaC trước khi deploy. Tự động giám sát cấu hình runtime. Giảm lỗi thủ công, đảm bảo deploy an toàn. 6. OPERATE - Vận hành:\nTự động vá lỗi \u0026amp; cập nhật bảo mật liên tục. Có incident response và theo dõi hiệu năng. Duy trì ổn định và an toàn sau release. 7. MONITOR - Giám sát:\nTheo dõi liên tục hoạt động \u0026amp; mối đe dọa. Dùng real-time analytics \u0026amp; alerting tools. Phát hiện sớm, phản ứng nhanh với rủi ro. Giới thiệu các công cụ cho DEVSECOPS TOOLCHAIN Pre-commit \u0026amp; Code Quality :\nSonarQube, Codacy, Semgrep (SAST), Gitleaks – kiểm tra code \u0026amp; secrets trước khi commit. Dependency \u0026amp; SBOM Scanning :\nSyft, Grype, Dependency-Track – quản lý package \u0026amp; lỗ hổng thư viện. IaC \u0026amp; Policy-as-Code :\nCheckov, TFsec – quét Terraform/Kubernetes config. OPA Gatekeeper, Kyverno – enforce policy \u0026amp; compliance tự động. SAST / DAST \u0026amp; Security Tests\nTrivy, Checkmarx, Semgrep, Codacy – phát hiện lỗ hổng ở code \u0026amp; runtime. CI/CD Integration\nJenkins, GitHub Actions, Gitlab CI, ArgoCD – tự động hoá build, test, deploy an toàn. Monitoring \u0026amp; Logging\nPrometheus, Grafana, Loki, Promtail – giám sát \u0026amp; quan sát hệ thống real-time. Alerting \u0026amp; Governance\nSlack webhook, Email alerts, AI anomaly detection – cảnh báo \u0026amp; phản ứng nhanh. Centralized risk report – báo cáo và phân tích rủi ro tập trung. Lợi ích của GENAI trong DevsecOps 1. Tự động hóa \u0026amp; tăng tốc quy trình DevSecOps\nCode review \u0026amp; Security scanning tự động Pipeline Generation IaC Generation 2. Tăng cường bảo mật chủ động\nThreat modeling bằng ngôn ngữ tự nhiên Policy-as-code generation Dynamic scanning augmentation 3. Tối ưu hóa quan sát và phản ứng sự cố\nIncident summary \u0026amp; Root cause analysis ChatOps Integration Anomaly Detection Những Gì Học Được Chiến Lược tích hợp AI vào quy trình làm việc AI giúp phát hiện sự cố và phân tích lỗ hổng tốt hơn Về phản ứng và khắc phục lỗi cũng tiết kiệm được nhiều thời gian Giúp giảm tải công việc bản thân phải làm nhưng vẫn giữ kết quả tốt Cho phép chu trình Devsecops học liên tục và cải thiện theo thời gian Ứng Dụng Amazon Q vào coding Sử dụng Amazon Q để hỗ trợ phần code. Cân nhắc kỹ lưỡng hơn có nên chấp thuận hành động tiếp theo của AI hay không Có thể sử dụng để tự tìm tài liệu từu nhiều nguồn và xem đề xuất Trải nghiệm trong sự kiện Tham gia workshop “Reinventing DevSecOps with AWS Generative AI” mang lại cho tôi nhiều góc nhìn thực tế về cách AI đang thay đổi toàn bộ quy trình DevSecOps — từ lập kế hoạch, viết mã, kiểm thử, đến vận hành và giám sát hệ thống. Dưới đây là những trải nghiệm đáng nhớ nhất:\nTrải nghiệm kỹ thuật thực tế Được nghe các chuyên gia trình bày chi tiết về DevSecOps Lifecycle với từng giai đoạn cụ thể, từ Plan – Code – Build – Test – Deploy – Operate – Monitor, giúp tôi hiểu rõ cách tích hợp bảo mật xuyên suốt toàn bộ quy trình phát triển phần mềm. Quan sát các ví dụ thực tế về CI/CD pipeline có tích hợp kiểm tra bảo mật tự động, giúp nhận thức được tầm quan trọng của việc phát hiện lỗ hổng sớm. Ứng dụng công cụ hiện đại Được hướng dẫn sử dụng Amazon Q trong quy trình DevSecOps — từ hỗ trợ viết mã an toàn, tạo IaC, đến gợi ý khắc phục lỗi tự động. Tìm hiểu về các công cụ trong DevSecOps toolchain như SonarQube, Checkov, Trivy, Prometheus, Grafana,\u0026hellip; và cách chúng phối hợp để xây dựng quy trình bảo mật end-to-end. Thấy rõ vai trò của AI trong việc tạo, kiểm thử, và triển khai mã một cách an toàn hơn, đặc biệt với policy-as-code và threat modeling bằng ngôn ngữ tự nhiên. Kết nối và trao đổi Có cơ hội thảo luận trực tiếp với các chuyên gia DevSecOps đến từ AWS và CMC Global, qua đó học hỏi được kinh nghiệm triển khai thực tế trong các dự án lớn. Trao đổi cùng cộng đồng kỹ sư về cách kết hợp AI vào DevSecOps pipeline, giúp tôi có thêm ý tưởng ứng dụng AI trong công việc hằng ngày. Bài học rút ra DevSecOps không chỉ là tự động hóa quy trình CI/CD, mà là tích hợp bảo mật như một phần cốt lõi của toàn bộ vòng đời phát triển phần mềm. Việc áp dụng AI và GenAI giúp tăng tốc phát hiện lỗ hổng, tự động hóa quy trình kiểm thử, và cải thiện khả năng phản ứng với sự cố. Amazon Q là công cụ tiềm năng giúp lập trình viên và kỹ sư bảo mật tối ưu quy trình phát triển, giảm khối lượng công việc thủ công, và nâng cao hiệu suất tổng thể. DevSecOps hiệu quả cần sự phối hợp chặt chẽ giữa con người – quy trình – công nghệ, với AI đóng vai trò là “trợ lý thông minh” hỗ trợ quyết định và hành động chính xác hơn. Một số hình ảnh khi tham gia sự kiện Hình 1 Hình 2 Hình 3 Tổng thể, sự kiện đã cho tôi biết thêm rất nhiều về Devsecops cũng như sự tiện dụng của AI khi được tích hợp vào quy trình phát triễn.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.3-week3/","title":"Worklog Tuần 3","tags":[],"description":"","content":"Mục tiêu tuần 3: Tìm hiểu các khái niệm về Amazon Lightsail. Nắm rõ các bước scaling cho EC2. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu ngọn nguồn và đặc điểm của data được chuẩn bị cho huấn luyện mô hình - Tiến hành đề xuất thuật toán da đạng hóa data để làm tăng độ phong phú pattern trong quá trình huấn luyện mô hình 22/09/2025 22/09/2025 3 - Tiến hành tìm hiểu về Amazon Lightsail Workshop và các thông tin liên quan Thực hành thao tác với các tính năng của dịch vụ 23/09/2025 23/09/2025 https://000045.awsstudygroup.com/ 4 - Khám phá các chức năng của Amazon Lightsail Container - Tạo các instance liên quan và thử nghiệm hoạt động 24/09/2025 24/09/2025 https://000046.awsstudygroup.com/ 5 - Học về các khái niệm của EC2 Auto Scaling : + Manual Scalling + Dynamic Scalling + Scheduled Scalling + Predictive Scalling 25/09/2025 25/09/2025 https://000006.awsstudygroup.com/ 6 - Dịch thuật cho technical blog với tựa đề \u0026lsquo;Introducing universal installers for AWS CLI v2 on macOS\u0026rsquo; 26/09/2025 26/09/2025 https://aws.amazon.com/blogs/devops/introducing-universal-installers-for-aws-cli-v2-on-macos/ Kết quả đạt được tuần 3: A – Amazon Lightsail Workshop\nTiến hành tìm hiểu về 3 applications trên lightsail:\nWordPress PrestaShop Akaunting Thực hiện triển khai database trên lightsail:\nTạo specify login credentials Chọn standard database plan với mức giá 15$ Thiết lập tên, thêm key-value tag và hoàn thiện tạo database Thử nghiệm tạo WordPress instance:\nChọn và triển khai wordpress server Thiết lập các ubuntu và networking fonfiguration Làm theo hướng dẫn để configure wordpress đã tạo và hoàn tất cài đặt WordPress Tạo thử Prestashop E-Commerce Instace:\nHiểu được sự tiện ích của Prestashop cho phép người dùng tạo online store và tích hợp với payment gateways mong muốn. Tạo xong instance Prestashop 5$ theo hướng dẫn Thiết lập các kết nối mạng và triển khai thành công Thực nghiệm với Akaunting instance:\nBiết các thông tin cơ bản về Akaunting là dành cho quản lý tài chính và tương tác với WordPress, PrestaShop. Tiến hành tạo một instance từ plan $5 Thiết lập các kết nối và hoàn tất triển khai. Thiết lập sercurity cho cả 3 instances vừa tạo, xem thêm về các gói lớn hơn của các instances và thêm Arlam.\nB – Amazon Lightsail Container\nHiểu được các khái niệm cơ bản về Lightsail Container dùng để chạy applications.\nThực hiện các bước chuẩn bị cần thiết\nTạo container service thành công\nTriển khai thành công Container từ Public Image\nThử nghiệm triển khai container từ local system:\nTạo Lightisail instance và thực thiện thiết lập AWS CLI theo hướng dẫn Cài đặt Docker trên Ubuntu và xây dựng container image Push container image đã tạo và tiến hành deploy. Dọn dẹp tài nguyên sau khi thực hành C – EC2 Auto Scaling\nTiến hành tìm hiểu về tính năng auto scaling của EC2 với các scaling strategies khác nhau:\nManual Scaling Dynamic Scaling Scheduled Scaling Predictive Scaling Thực hiện các bước chuẩn bị cần thiết:\nTạo VPC enviroment, EC2 instance và database instace với RDS Setup dữ liệu cho Databse, triển khai webserver Chuẩn bị data cho predictive scaling, tải lên cloudwatch và thực hiện xác thực. Tìm hiểu về Amazon Machine Image và Launch Templates:\nKhởi tạo AMI từ instace EC2 Tạo Launch Template Thực hiện các thiết lập cần thiết. Cài đặt Load Balancer:\nTìm hiểu về Elastic Load Balancing Tạo application của Load Balance Target Group Tiến hành tạo Load Balance từ EC2 Thử nghiệm và hoàn thiện khởi tạo Auto Scaling Group để quản lý các EC2 instances\nTiến hành test các scaling solutions:\nTest manual, scheduled, dynamic scaling Đọc hiểu các thông số từ predictive scaling solution "},{"uri":"https://giaphazzz.github.io/aws/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Ra mắt universal installers dành cho AWS CLI v2 trên macOS bởi Andrew Asseily | on 11 THÁNG 9 2025 | in Announcements, AWS CLI |\nAmazon Web Services (AWS) thông báo ra mắt universal macOS installers cho AWS Command Line Interface (AWS CLI) v2.\nCó gì mới ! Bắt đầu từ phiên bản phiên bản 2.30.0 của AWS CLI v2, các trình cài đặt AWS CLI sẽ hỗ trợ tệp nhị phân phổ quát (universal binary support) cho macOS, hoạt động trên cả chip Apple silicon và bộ xử lý Intel chỉ với một lần tải xuống. Điều này giúp loại bỏ nhu cầu sử dụng Rosetta, một compatibility layer cho phép các ứng dụng dựa trên Intel phải chạy trên máy Mac sử dụng chip Apple silicon.\nCập nhật các bản cài đặt AWS CLI hiện có Nếu bạn đang sử dụng AWS CLI v2 trên máy Mac với chip Apple silicon, chúng tôi khuyến nghị bạn nâng cấp lên phiên bản mới nhất để cài đặt các native binaries. Những thay đổi này sẽ chỉ ảnh hưởng đến các trình cài đặt AWS CLI chính thức—việc biên dịch AWS CLI từ nguồn sẽ được tiếp tục hỗ trợ cho kiến trúc hệ thống chủ (host architecture). Nếu có câu hỏi hoặc phản hồi, hãy liên hệ với chúng tôi ngay trên GitHub.\nAndrew Asseily\nAndrew hiện đang là Software Development Engineer tại AWS CLI team. Ngoài công việc, anh ta còn là người đam mê võ thuật Brazilian Jiu-Jitsu.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Blog 1 - Exploring Quantum Measurements, Observables and Operators: Practical insights with Amazon Braket Bài viết này khám phá nền tảng toán học và cách triển khai thực tế của các kỹ thuật đo lường lượng tử bằng Amazon Braket. Bạn sẽ tìm hiểu cách mà các biến đổi cơ sở (basis transformations), phép chiếu (projectors) và toán tử quan sát (observables) phối hợp với nhau để chuyển đổi thông tin pha lượng tử ẩn thành các kết quả có thể đo lường được — một khái niệm then chốt trong nhiều thuật toán lượng tử. Bài viết cũng bao gồm các ví dụ thực hành Python sử dụng Amazon Braket để mô phỏng phép đo trong các cơ sở tùy ý, trực quan hóa kết quả trên hình cầu Bloch, và kết nối giữa lý thuyết với các thí nghiệm phần cứng lượng tử thực tế.\nBlog 2 - Implement network connectivity patterns for Oracle Database@AWS Bài viết giải thích cách thiết kế và triển khai các mô hình kết nối mạng cho Oracle Database@AWS (ODB@AWS). Bạn sẽ học cách kết nối hạ tầng Oracle Exadata chạy trên AWS với các ứng dụng, môi trường on-premises, và kiến trúc multi-VPC thông qua AWS Transit Gateway và AWS Cloud WAN. Bài viết mô tả chi tiết nhiều kiến trúc dựa trên định tuyến IP, bao gồm VPC peering trực tiếp, khả năng mở rộng trong một vùng (single-Region), và kết nối toàn cầu đa vùng (multi-Region). Ngoài ra, nội dung còn đề cập đến cấu hình DNS, các yếu tố bảo mật, và thực hành tốt nhất khi tích hợp ODB@AWS vào các hệ thống mạng phức tạp trên AWS trong khi vẫn đảm bảo hiệu năng, bảo mật và tính linh hoạt.\nBlog 3 - Introducing universal installers for AWS CLI v2 on macOS Bài viết đã công bố việc phát hành bộ cài đặt universal cho macOS của AWS Command Line Interface (AWS CLI) v2, bắt đầu từ phiên bản 2.30.0. Với bản cập nhật này, một bộ cài duy nhất có thể chạy tự nhiên trên cả Apple silicon và Intel, loại bỏ nhu cầu sử dụng Rosetta translation và giúp việc cài đặt trên các thiết bị macOS trở nên đơn giản, thống nhất và hiệu quả hơn.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.3-ml-model/","title":"Mô Hình Học Máy","tags":[],"description":"","content":"HUẤN LUYỆN MÔ HÌNH Mục sau đây trình bày về quá trình phát triển mô hình dự đoán được thiết kế để dự đoán vị trí địa lý tiếp theo của một cơn bão, dựa trên dữ liệu quan sát từ quỹ đạo di chuyển trước đó. Nói cách đơn giản, nhóm sử dụng chuỗi các giá trị vĩ độ và kinh độ trong quá khứ để dự đoán vĩ độ và kinh độ tại bước thời gian kế tiếp.\nTrích Xuất Đặc Trưng Sau khi hoàn tất bước tiền xử lý dữ liệu, nhóm tiến hành chia bộ dữ liệu thành 70% để huấn luyện, 10% để kiểm định, và 20% để kiểm tra. Việc chia này được thực hiện theo mã định danh cơn bão (storm ID), đảm bảo không có cơn bão nào xuất hiện đồng thời trong cả tập huấn luyện và tập kiểm định/kiểm tra. Điều này giúp ngăn rò rỉ dữ liệu và đảm bảo độ tin cậy của quá trình đánh giá.\nTrong quá trình huấn luyện mô hình, mỗi mẫu đầu vào bao gồm chuỗi 4 bước thời gian liên tiếp, trong đó mỗi bước cách nhau 3 giờ. Như vậy, một chuỗi đầu vào tương ứng với quãng di chuyển 9 giờ của cơn bão.\nFigure 1 : Dataset Distribution Áp dụng Kỹ thuật Stepwise Temporal Fading Augmentation (STFA) Để tăng độ đa dạng của dữ liệu huấn luyện, nhóm áp dụng phương pháp tự đề xuất — Stepwise Temporal Fading Augmentation (STFA) — lên 50% tập huấn luyện, được lựa chọn dựa trên từng storm ID riêng biệt. Các chuỗi gốc của những cơn bão này sẽ được thay thế bằng chuỗi đã được tăng cường, đảm bảo kích thước tập huấn luyện cuối cùng vẫn giữ nguyên (xấp xỉ 100% kích thước ban đầu).\nNhư đã đề cập trong phần đề xuất mô hình, STFA thay đổi các điểm cũ hơn trong chuỗi, trong khi giữ các quan sát mới nhất không đổi. Với mỗi chuỗi 4 bước:\n2 bước mới nhất được giữ nguyên 2 bước cũ hơn được nhân với hệ số giảm dần: [0.98, 0.99] Mặc dù những giá trị này có vẻ nhỏ, nhưng vĩ độ và kinh độ cực kỳ nhạy cảm. Một thay đổi nhỏ — ví dụ từ 6.7 lên 6.8 — có thể tương ứng với hàng chục kilomet dịch chuyển ngoài thực tế. Do đó, mức điều chỉnh nhỏ như vậy là hợp lý và phù hợp với quy luật vật lý, giúp dữ liệu tăng cường vẫn mang tính chân thực.\nVí dụ STFA trên một chuỗi 4 bước thời gian Row Original (lat, lon) Augmented (lat, lon) Operation 1 [-6.8, 107.5] [-6.66, 105.35] nhân với 0.98 2 [-7.0, 107.1] [-6.93, 106.03] nhân với 0.99 3 [-7.3, 106.7] [-7.3, 106.7] giữ nguyên 4 [-7.5, 106.4] [-7.5, 106.4] giữ nguyên Quy trình trên làm giảm giá trị của các quan sát cũ, đồng thời giữ nguyên các bước mới. Việc tăng cường này giúp mô hình có thêm biến thiên có kiểm soát, cải thiện khả năng tổng quát hóa trong dự báo quỹ đạo.\nTrước đó, nhóm đã sử dụng machine learning dựa trên quy luật vật lý để tính khoảng cách và góc phương vị bằng công thức Haversine. Sau khi STFA được áp dụng, các giá trị này sẽ được tính lại dựa trên tọa độ đã tăng cường để đảm bảo các đặc trưng vật lý vẫn chính xác và nhất quán.\nFigure 2 : Comparison of Augmentation Techniques on Storm Trajectories Thiết lập Mô hình 1. Hàm Loss dựa trên quy luật vật lý Việc ứng dụng công thức Haversine không chỉ dừng lại ở bước trích xuất đặc trưng. Ngoài việc tạo ra các giá trị khoảng cách và hướng, nhóm còn tích hợp Công thức Haversine như một hàm loss tùy chỉnh, sử dụng cùng với các hàm loss truyền thống như MSE, RMSE và MAPE.\nCông thức Haversine đo khoảng cách địa lý thực giữa hai điểm, nên đây là metric tự nhiên để đánh giá sai số dự đoán vị trí bão. Khoảng cách Haversine càng lớn nghĩa là dự đoán càng sai; ngược lại, giá trị gần 0 km cho thấy mô hình hoạt động tốt.\nVí dụ:\nDự đoán: [-6.72, 107.1] Giá trị thật: [-6.8, 107.5] Haversine loss: 45.06 km Giá trị 45.06 km phản ánh chính xác sai số vị trí ngoài thực tế, giúp việc giải thích mô hình dễ dàng và ý nghĩa hơn.\n2. Kiến trúc mô hình Các bài toán mô hình hóa chuỗi thường được xử lý bằng RNN, LSTM hoặc GRU, nhưng các nghiên cứu gần đây cho thấy mô hình dựa trên tích chập (CNN) có thể vượt trội hơn trong nhiều tác vụ time-series.\nDo đó, nhóm sử dụng kiến trúc CNN — cụ thể là Temporal Convolutional Network (TCN).\nTCN sử dụng tích chập giãn (dilated convolution), giúp mô hình có receptive field rộng mà không cần dùng mạng hồi quy.\nTCN kết hợp được cả:\nkhả năng học phụ thuộc dài hạn tốc độ huấn luyện nhanh gradient ổn định Nên rất phù hợp cho bài toán dự báo quỹ đạo bão.\n3. Các siêu tham số mô hình Input: 4 đặc trưng (lat, lon, distance, bearing) Hidden units: 1024 Số lớp TCN: 2 Learning rate: 1e-4 Epochs: 80 Optimizer: Adam Early stopping: patience = 6 4. Hàm Loss tổng hợp Loss chính của mô hình được kết hợp từ:\nMSE của lat/lon MSE của distance/bearing Haversine loss (dựa trên vật lý) Trong đó:\nλ_aux = 0.5 λ_hav = 0.3 Cách thiết kế này giúp mô hình:\ngiảm sai số tọa độ tôn trọng quy luật dịch chuyển vật lý tránh overfit vào một loại đặc trưng cụ thể Figure 3 : Training Process Evaluation Đánh giá mô hình Sau khi mô hình hoàn tất quá trình huấn luyện và dừng sớm (early stopping), nhóm tiến hành đánh giá trên tập kiểm tra để xác định khả năng tổng quát hóa và mức độ sẵn sàng triển khai thực tế.\nKết quả đánh giá:\nTotal Loss: 74.3849 MSE: 0.0832 RMSE: 0.2772 MAPE: 0.60% Haversine: 30.75 km Sai số vị trí trung bình khoảng 30 km — mức hoàn toàn chấp nhận được đối với hệ thống có quy mô hàng trăm đến hàng nghìn kilomet như bão nhiệt đới. MSE nhỏ (0.08) cho thấy khả năng dự đoán tốt và ổn định.\nKết quả này cũng chứng minh rằng các mô hình convolution có thể hoạt động xuất sắc trong bài toán mô hình hóa chuỗi, không chỉ trong xử lý ảnh.\nSau khi xác thực mô hình, bước tiếp theo là tải mô hình lên Amazon S3 và sử dụng AWS Lambda để thực thi mô hình khi người dùng gửi yêu cầu dự đoán.\nFigure 4 : Evaluation Metrics "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.4-event4/","title":"AWS Cloud Mastery Series #1","tags":[],"description":"","content":"Bài Thu Hoạch “AI/ML/GenAI on AWS Workshop” Mục Tiêu Của Sự Kiện Giới thiệu tổng quan về hệ sinh thái AI/ML của AWS Trình bày về Generative AI với Amazon Bedrock Khám phá các ứng dụng thực tế của Prompt Engineering và RAG Minh họa cách các dịch vụ AI tích hợp vào sản phẩm chạy trên nền tảng đám mây Giới thiệu AgentCore – nền tảng xây dựng AI agent quy mô lớn, sẵn sàng cho môi trường production Diễn Giả Lam Tuấn Kiệt – Senior DevOps Engineer, FPT Software Đặng Hoàng Hiếu Nghi – AI Engineer, Reonova Cloud Đinh Lê Hoàng Anh – Cloud Engineer Trainee, FCJ Nội Dung Nổi Bật Chuyển Đổi Từ Traditonal ML Sang Foundation Models Traditional ML models\nGiải quyết từng nhiệm vụ cụ thể Phụ thuộc vào dữ liệu đã được gắn nhãn Khả năng tổng quát kém Generative AI (Foundation Models)\nHuấn luyện trên lượng lớn dữ liệu không gắn nhãn Học theo phương pháp tự giám sát Có thể thực hiện nhiều tác vụ chỉ thông qua prompt Bedrock hỗ trợ nhiều nhà cung cấp mô hình lớn: OpenAI, DeepSeek, Anthropic Claude, Meta Llama, Amazon Titan Kiến Thức Cốt Lõi Về Prompt Engineering Prompt là gì? Tập hợp hướng dẫn để điều khiển kết quả của mô hình.\nCác kỹ thuật chính\nZero-shot prompting: Chỉ cung cấp yêu cầu → kết quả nhanh nhưng đôi khi sai Few-shot prompting: Đưa ví dụ mẫu để định hình phong cách trả lời Chain-of-Thought prompting: Hướng dẫn mô hình suy luận từng bước → đầu ra chi tiết và chất lượng cao Retrieval-Augmented Generation (RAG) Tăng độ chính xác bằng cách bổ sung kiến thức bên ngoài có liên quan Quy trình:\nNgười dùng đưa ra prompt Hệ thống tìm tài liệu liên quan Ghép nội dung vào ngữ cảnh Mô hình tạo ra câu trả lời dựa trên thông tin đã bổ sung Embeddings\nChuyển văn bản → vector mang ý nghĩa ngữ nghĩa Giúp phân cụm các khái niệm tương tự Titan Text Embeddings hỗ trợ hơn 100 ngôn ngữ RAG giúp giảm hallucination và tạo câu trả lời dựa trên dữ liệu thực tế.\nTổng Quan Dịch Vụ AI Trên AWS Các API AI sẵn sàng dùng:\nRekognition – Phát hiện đối tượng trong ảnh/video Translate – Dịch và nhận dạng ngôn ngữ Textract – Trích xuất văn bản và bố cục tài liệu Transcribe – Chuyển giọng nói thành văn bản, nhận dạng người nói Polly – Chuyển văn bản thành giọng nói Comprehend – NLP, phân tích cảm xúc Kendra – Tìm kiếm thông minh cho doanh nghiệp Lookout Family – Phát hiện bất thường: chỉ số, thiết bị, hình ảnh Personalize – Cá nhân hóa Pipecat – Framework phát triển pipeline AI agent Amazon Bedrock AgentCore Nền tảng giúp đơn giản hóa việc xây dựng và triển khai AI agents:\nTự động hóa những phần phức tạp trong production GenAI, bao gồm:\nScaling Context memory Identity \u0026amp; access control Tích hợp công cụ và API Điều phối workflow Quan sát hệ thống \u0026amp; logging Các thành phần chính\nRuntime – Thực thi tác vụ nhiều bước Memory – Lưu trữ tương tác trước đó Identity – Định nghĩa quyền truy cập Gateway – Truy cập tập trung các dịch vụ \u0026amp; công cụ Code Interpreter – Môi trường chạy code an toàn Browser tool – Truy xuất thông tin từ web Observability – Log, metric, debugging Những Điều Rút Ra Được Tư Duy Phát Triển AI \u0026amp; Cloud Doanh nghiệp đang chuyển từ mô hình ML truyền thống sang sản phẩm cloud-native tích hợp AI Cần xây dựng dự án thực tế, không chỉ là bài tập trên trường Foundation Model + dịch vụ đám mây = phát triển sản phẩm nhanh hơn, tối ưu chi phí Kiến Thức Kỹ Thuật Hiểu được tác động của prompt engineering đến chất lượng kết quả RAG nâng cao độ chính xác và bổ sung tri thức có cấu trúc Embeddings giúp tìm kiếm ngữ nghĩa và phân cụm mạnh mẽ Dịch vụ AI của AWS bao phủ end-to-end: giọng nói, văn bản, hình ảnh, phát hiện bất thường Phát Triển Agent AgentCore giúp đơn giản hóa các workflow vốn đòi hỏi nhiều DevOps Hữu ích trong việc xây dựng: Chatbots Automation agents Research assistants Ứng dụng chuyên biệt Ứng Dụng Vào Công Việc Xây dựng prototype sản phẩm thực để đưa vào CV Dùng RAG cho các hệ thống AI theo domain Tích hợp API AI của AWS để tăng tốc độ phát triển tính năng Triển khai Bedrock Agents cho tác vụ nhiều bước Khai thác embeddings cho semantic search/phân loại Luyện tập prompt engineering để tối ưu đầu ra mô hình Trải Nghiệm Tại Sự Kiện Tham gia workshop “AI/ML/GenAI on AWS” mang lại rất nhiều kiến thức thực tiễn về phát triển AI hiện đại trên đám mây AWS.\nKiến Thức Từ Các Diễn Giả Diễn giả từ FPT, Reonova Cloud và AWS chia sẻ cách doanh nghiệp triển khai AI tối ưu chi phí. Hiểu rõ cách AI được ứng dụng trong vision, text, speech và automation. Thực Hành Kiến Thức GenAI Nắm rõ sự khác biệt giữa Foundation Models và ML truyền thống Hiểu các kiểu prompting và lý do chúng quan trọng Xem ví dụ thực tế về pipeline RAG giúp tăng độ chính xác Trải Nghiệm Công Cụ AWS Hiểu vai trò của Rekognition, Textract, Transcribe, Translate, Comprehend Khám phá cách Bedrock AgentCore đơn giản hóa việc xây dựng ứng dụng GenAI quy mô lớn Bài Học Rút Ra AI + Cloud giúp đẩy nhanh việc phát triển sản phẩm thực tế Prompt engineering và RAG là nền tảng cho GenAI doanh nghiệp AgentCore là bước tiến tiếp theo cho kiến trúc AI hiện đại Một Số Hình Ảnh Trong Sự Kiện Hình 1 Hình 2 Hình 3 Tổng quan, workshop mang lại góc nhìn chiến lược và kiến thức kỹ thuật thực tiễn, giúp củng cố nền tảng quan trọng cho việc phát triển AI/ML trên AWS.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.4-week4/","title":"Worklog Tuần 4","tags":[],"description":"","content":"Mục tiêu tuần 4: Nắm vững kiến thức về các khái niệm sơ bộ của cloud\nTìm hiểu AWS Cloudwatch, Cloudfront, CLI, …\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu về AWS CloudWatch và các khái niệm liên quan 29/09/2025 29/09/2025 https://000008.awsstudygroup.com/ 3 - Làm quen với việc sử dụng AWS Command LineInterface, thử nghiệm thao tác với các dịch vụ + S3 Bucket + SNS + IAM + VPC + \u0026hellip; 30/09/2025 30/09/2025 https://000011.awsstudygroup.com/ 4 - Tham khảo các thông tin về Cloudfront và cách sử dụng 1/10/2025 1/10/2025 https://000094.awsstudygroup.com/ 5 - Tham khảo về dịch vụ Amazon DynamoDB và các tính năng của nó + Core components + Primary Keys + Secondary Index + Các quy tắc đặt tên và query data 2/10/2025 2/10/2025 https://000060.awsstudygroup.com/ 6 - Chuẩn hóa và xử lý hoàn tất dữ liệu cho project - Nghiên cứu mô hình Temporal Convolutional Network sẽ được sử dụng trong quá trình huấn luyện 3/10/2025 3/10/2025 Kết quả đạt được tuần 4: A – AWS CLOUDWATCH\nBiết được AWS CloudWatch là dịch vụ theo dõi và quản lí dữ liệu, định hướng hành động cho tài nguyên AWS.\nLàm việc với các Metrics, xem Logs từ các applications và tạo Alarms từ Metrics nhận được.\nThực hiện các bước chuẩn bị để làm việc với cloudwatch:\nTạo stack trong CloudFormation Thiết lập cơ bản cho stack Hoàn tất tạo dựng và deployment *Thao tác với mục xem metrics của cloudwatch: * Xem thử metric của EC2 * Phân tích cpu utilization * Chỉnh sửa chart visualiaztion\nTìm hiểu về search, math experessions và dynamic labels cùng thực hành thử nghiệm\nXem thông tin chi tiết về cloudwatch logs:\nXem blods của EC2 instance Thực hành tạo thử log Tạo metric filter để thu thập và chuyển hóa data sang cloudwatch metrics Khám phá các tính năng của Cloudwatch Alarms và Cloudwatch Dashboards\nB – Làm quen với AWS Command Line Interface (CLI)\nHiểu được AWS CLI là open-source tool cho phép ngường dùng tương tác với các dịch vụ của aws trong command-line shell.\nTải AWS CLI về máy và thực hiện các bước chuẩn bị để thực hành thao tác\nThao tác với Amazon S3 qua AWS CLI:\nTạo S3 Bukcet Xem list các bucket và object Xóa object và bucket Tiến hành thử nghiệm với dịch vụ SNS và IAM qua CLI:\nTạo thử SNS topic Tạo IAM group, user, .. Kiểm tra thông tin trong group, thêm/xóa access key Dùng CLI thao tác với VPC:\nTạo VPC và các componets Tạo thử internet gateway *Tham khảo qua các lỗi (Troubleshooting) trong quá trình thao tác với AWS CLI\nC – CLOUFRONT\nTiến hành tìm hiểu về CloudFront với S3 Bucket Origin\nTạo S3 Bucket để chuẩn bị cho các bước sau\nTải file index.html lên S3 Bucket vừa tạo\nThực hiện thiết lập các thông số cho Amazon CloudFront\nThử nghiệm xóa CloudFront khỏi S3 sau khi dùng.\nD – AMAZON DYNAMODB\nHiểu được Amazon DynamoDB là dịch vụ NoSQL Database hỗ trợ các performance nhanh và dễ đoán.\nTìm hiểu vài tính chất của DynamoDB: *Core components *Các key *Secondary Index *Quy tắc đặt tên và những loại dữ liệu *Tham khảo thêm về tính consistency và đọc/viết capacity mode\nThực hiện các bước chuẩn bị cần thiết:\nTạo acess key, table, đọc-viết và update dữ liệu Tạo global scondary index và query với nó Tiến hành thực hành với AWS SDK :\nThiết lập trước AWS CLI Tạo table, đọc-viết-update-xóa data. Query và scan dữ liệu, xóa bảng sau khi dùng. "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/","title":"Các events đã tham gia","tags":[],"description":"","content":"Xuyên suốt quá trình thực tập, việc tham gia events không chỉ là những trải nghiệm đáng nhớ đối mà còn là buổi chia sẽ rất nhiều kiến thức bổ ích. May mắn thay, em đã được tham gia 8 buổi events, tất cả đều vô cùng hay ho và thú vị.\nEvent 1 Tên sự kiện: Vietnam Cloud Day 2025 : Ho Chi Minh City Connect Edition for Builders\nThời gian: 09:00 ngày 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò trong sự kiện: Người tham dự\nCác hoạt động chính: Chia sẽ về quá trình chuyển giao công nghệ 4.0 và sự hữu ích của AI trong phát triễn công nghệ\nBài học: Áp dụng AI-DLC vào chiến lược phát triển dự án giúp tăng cao hiệu suất làm việc. Nên sử dụng Gen AI cho các hoạt động nghiên cứu và học hỏi kiến thức mới.\nEvent 2 Tên sự kiện: Data Science on AWS\nThời gian: 09:30 ngày 16/10/2025\nĐịa điểm: Hall A, tầng 5, đại học FPT, khu công nghệ cao\nVai trò trong sự kiện: Người tham dự\nCác hoạt động chính: Giới thiệu các dịch vụ chuyên dụng của AWS dành cho lĩnh vực AI và giải thích các khái niệm về học máy.\nBài học: Việc áp dụng các dịch vụ AWS cho xây dựng và triển khai mô hình ML hiện nay là không thể thiếu. Không chỉ tiết kiệm thời gian mà còn mang lại hiệu suất cao với độ chính xác tốt.\nEvent 3 Tên sự kiện: Reinventing DevSecOps with AWS Generative AI\nThời gian: 19:30 ngày 16/10/2025\nĐịa điểm: Online trên Teams Meeting\nVai trò trong sự kiện: Người tham dự\nCác hoạt động chính: Chia sẽ về DevSecOps đã có những bước chuyển mình trong tự động hoá vận hành hệ thống bằng AI như thế nào.\nBài học: DevSecOps không chỉ là tự động hóa quy trình CI/CD, mà là tích hợp bảo mật như một phần cốt lõi của toàn bộ vòng đời phát triển phần mềm. Việc áp dụng AI và GenAI giúp tăng tốc phát hiện lỗ hổng, tự động hóa quy trình kiểm thử, và cải thiện khả năng phản ứng với sự cố.\nEvent 4 Tên sự kiện: AWS Cloud Mastery Series #1 - AI/ML/GenAI on AWS Workshop\nNgày \u0026amp; Giờ: 8:30, ngày 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Giới thiệu các ứng dụng thực tiễn của AI và prompt engineering cho công việc. Khám phá một số dịch vụ machine learning trên AWS hỗ trợ nhiều tác vụ khác nhau, bao gồm nhận diện hình ảnh, chuyển văn bản thành giọng nói, tìm kiếm, cá nhân hóa, \u0026hellip;\nBài học rút ra: AI và prompt engineering không chỉ là công cụ tự động hóa mà còn là giải pháp giúp nâng cao năng suất và khả năng ra quyết định trong công việc và các tác vụ cá nhân. Tận dụng những dịch vụ ML của AWS — như nhận diện hình ảnh, chuyển văn bản thành giọng nói, tìm kiếm và cá nhân hóa — cho thấy AI có thể đơn giản hóa các tác vụ lặp đi lặp lại, cung cấp thông tin nhanh hơn và cải thiện trải nghiệm người dùng. Việc tích hợp các dịch vụ này một cách hợp lý vào quy trình làm việc đảm bảo hiệu quả, đồng thời duy trì kiểm soát và độ tin cậy.\nEvent 5 Tên sự kiện: AWS Cloud Mastery Series #2 - DevOps on AWS\nNgày \u0026amp; Giờ: 8:30, ngày 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Học hỏi về các nguyên tắc DevOps, xây dựng pipeline CI/CD tự động, khám phá Infrastructure as Code (IaC) với CloudFormation và CDK, so sánh các dịch vụ container của AWS (ECS, EKS, App Runner), và tìm hiểu các thực hành quan sát hệ thống với CloudWatch.\nBài học rút ra: DevOps hiệu quả không chỉ là triển khai tự động hóa trong pipeline CI/CD mà còn là thúc đẩy sự hợp tác giữa đội ngũ phát triển và vận hành, tích hợp phản hồi liên tục, và sử dụng IaC để xây dựng hạ tầng lặp lại và đáng tin cậy. Sử dụng các dịch vụ AWS để container hóa ứng dụng và nâng cao khả năng quan sát giúp triển khai nhanh hơn, giảm lỗi con người, và tạo ra hệ thống có thể mở rộng, bền vững.\nEvent 6 Tên sự kiện: AWS Edge Services Workshop\nNgày \u0026amp; Giờ: 9:00, ngày 19/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Khám phá các khả năng edge của CloudFront, bao gồm các tính năng bảo mật (TLS, mutual TLS, origin cloaking), kỹ thuật tối ưu chi phí, chiến lược caching, triển khai edge logic với CloudFront Functions/Lambda@Edge, và các best practices để đảm bảo tính khả dụng cao, hiệu năng tối ưu và độ tin cậy.\nBài học rút ra: Triển khai dịch vụ edge không chỉ đơn thuần là triển khai CDN; nó yêu cầu tích hợp các chiến lược bảo mật, caching và failover để tối ưu hiệu suất và giảm tải cho origin. Tận dụng các tính năng nâng cao của CloudFront và tuân thủ các thực hành tốt nhất giúp cung cấp nội dung toàn cầu với hiệu quả chi phí, độ bền cao, hiệu suất tối ưu, đồng thời duy trì khả năng quan sát toàn diện.\nEvent 7 Tên sự kiện: Master 3 — Security (AWS Well-Architected Security Pillar)\nNgày \u0026amp; Giờ: 9:00, ngày 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, phường Sài Gòn, thành phố Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Khám phá các nguyên tắc cốt lõi của AWS Well-Architected Security Pillar, bao gồm IAM (danh tính \u0026amp; phân quyền), chiến lược giám sát \u0026amp; phát hiện liên tục, tự động hóa phản ứng sự cố, bảo mật mạng nhiều lớp, và quản trị đa tài khoản. Tìm hiểu cách sử dụng các dịch vụ bảo mật quan trọng như IAM Access Analyzer, GuardDuty, Security Hub, EventBridge và CloudTrail để xây dựng môi trường AWS an toàn, ổn định và hiệu quả.\nBài học rút ra: Bảo mật không chỉ cần setup một lần mà nó là một quá trình theo dõi và điều chỉnh liên tục. Việc áp dụng nguyên tắc least privilege, xác thực mạnh, giám sát đa lớp, tự động hóa cảnh báo và phản ứng sự cố là điều thiết yếu. Kết hợp GuardDuty, Security Hub, EventBridge và IAM giúp tăng khả năng phát hiện, giảm rủi ro và đảm bảo hoạt động nhất quán trên nhiều tài khoản/vùng. Thiết kế bảo mật theo hướng “defense-in-depth” giúp gia tăng độ tin cậy, khả dụng và khả năng quan sát cho toàn bộ hệ thống cloud.\nSự kiện 8 Tên sự kiện: CloudThinker – Xây dựng Agentic AI \u0026amp; Tối ưu hóa Ngữ cảnh với Amazon Bedrock\nThời gian: 9:00, ngày 05 tháng 12 năm 2025\nĐịa điểm: Tầng 26, Tòa nhà Bitexco, 02 đường Hải Triều, phường Sài Gòn, TP. Hồ Chí Minh\nVai trò: Người tham dự\nHoạt động chính: Tham gia buổi chia sẻ kiến thức do CloudThinker và AWS tổ chức, tập trung vào cách thiết kế và tối ưu hóa hệ thống Agentic AI bằng Amazon Bedrock.\nBài học rút ra: Sự kiện nhấn mạnh rằng DevSecOps đã phát triển vượt xa tự động hóa CI/CD truyền thống. Hiện nay, việc tích hợp bảo mật vào mọi giai đoạn của vòng đời phát triển phần mềm là điều bắt buộc—và AI đóng vai trò quan trọng.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.4-frontback-end/5.4.1-frontend-architecture/","title":"Kiến Trúc Frontend","tags":[],"description":"","content":"Kiến trúc Frontend – Ứng dụng Web Dự báo Bão Tổng quan Dưới đây là tài liệu chi tiết về quá trình phát triển front-end của nhóm: Một ứng dụng web xây dựng bằng React và TypeScript dùng để theo dõi và dự đoán quỹ đạo bão\nKiến trúc dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ TRÌNH DUYỆT NGƯỜI DÙNG │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ CloudFront CDN │ │ - Distribution: d3lj47ilp0fgxy.cloudfront.net │ │ - SSL/TLS: HTTPS │ │ - Cache: Tài nguyên tĩnh + dữ liệu JSON │ │ - Truy cập Origin: OAI/OAC (bảo mật) │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ S3 Bucket (Riêng tư) │ │ - Bucket: storm-frontend-hosting-duc-2025 │ │ - Static Website Hosting: TẮT │ │ - Quyền truy cập: Chỉ CloudFront được phép qua REST API │ │ - Nội dung: HTML, CSS, JS, hình ảnh, recent_storms.json │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ Các hàm Lambda │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #1: Dự báo bão │ │ │ │ - URL: vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ │ │ - Phương thức: POST /predict │ │ │ │ - Xác thực: KHÔNG (công khai) │ │ │ │ - Container: ECR (Docker) │ │ │ │ - Mô hình: LSTM + TCN │ │ │ └─────────────────────────────────────────────────────┘ │ │ ┌─────────────────────────────────────────────────────┐ │ │ │ Lambda #2: Thu thập dữ liệu bão (mới) │ │ │ │ - Kích hoạt: EventBridge (hàng tuần) │ │ │ │ - Chức năng: Thu thập dữ liệu IBTrACS │ │ │ │ - Đầu ra: recent_storms.json → S3 │ │ │ └─────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ EventBridge │ │ - Rule: storm-data-crawler-weekly-trigger │ │ - Lịch chạy: Mỗi Chủ nhật 00:00 UTC (07:00 giờ Việt Nam) │ │ - Đích: Lambda #2 (Thu thập dữ liệu bão) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục Frontend frontend/ ├── src/ │ ├── components/ # Các component React │ │ ├── ui/ # Component từ shadcn/ui (button, card, input, ...) │ │ ├── storm/ # Component chuyên cho nghiệp vụ bão │ │ ├── timeline/ # Điều khiển timeline │ │ ├── wind/ # Trực quan hóa gió │ │ ├── StormPredictionForm.tsx # Form nhập tọa độ bão │ │ ├── WeatherMap.tsx # Bản đồ Leaflet chính │ │ ├── StormTracker.tsx # Danh sách bão │ │ ├── StormInfo.tsx # Thông tin chi tiết bão │ │ ├── StormAnimation.tsx # Marker hoạt ảnh │ │ ├── WeatherOverlay.tsx # Lớp phủ Nhiệt độ/Gió │ │ ├── WeatherLayerControl.tsx # Lớp Satellite/Radar │ │ ├── WeatherLayerControlPanel.tsx # UI bảng điều khiển lớp dữ liệu │ │ ├── WeatherValueTooltip.tsx # Tooltip khi rê chuột │ │ ├── WindyLayer.tsx # Tích hợp Windy.com │ │ ├── ProvinceLayer.tsx # Lớp ranh giới tỉnh/thành Việt Nam │ │ ├── OptimizedTemperatureLayer.tsx │ │ ├── TemperatureHeatMapLayer.tsx │ │ ├── ThemeToggle.tsx # Chế độ Sáng/Tối │ │ ├── PreferencesModal.tsx # Tùy chọn người dùng │ │ ├── RightSidebar.tsx # Panel bên phải │ │ └── WeeklyForecast.tsx # Dự báo 7 ngày │ │ │ ├── pages/ │ │ ├── Index.tsx # Trang chính │ │ └── NotFound.tsx # Trang 404 │ │ │ ├── lib/ # Logic nghiệp vụ \u0026amp; tiện ích │ │ ├── api/ # Client gọi API │ │ ├── __tests__/ # Unit test │ │ ├── stormData.ts # Kiểu dữ liệu \u0026amp; interface │ │ ├── stormAnimations.ts # Logic hoạt ảnh │ │ ├── stormIntensityChanges.ts │ │ ├── stormPerformance.ts │ │ ├── stormValidation.ts │ │ ├── windData.ts │ │ ├── windStrengthCalculations.ts │ │ ├── windyStatePersistence.ts │ │ ├── windyUrlState.ts │ │ ├── mapUtils.ts # Tiện ích hỗ trợ bản đồ │ │ ├── openWeatherMapClient.ts │ │ ├── dataWorker.ts # Web Worker │ │ ├── utils.ts │ │ └── colorInterpolation.ts │ │ │ ├── hooks/ # Custom React hooks │ │ ├── use-toast.ts │ │ ├── use-theme.tsx │ │ ├── use-mobile.tsx │ │ ├── useTimelineState.ts │ │ ├── useWindyStateSync.ts │ │ └── useSimplifiedTooltip.ts │ │ │ ├── contexts/ # React Context │ │ └── WindyStateContext.tsx │ │ │ ├── api/ │ │ └── weatherApi.ts # Các hàm gọi API │ │ │ ├── utils/ │ │ └── colorInterpolation.ts │ │ │ ├── styles/ │ │ └── accessibility.css # Style tuân thủ WCAG │ │ │ ├── test/ # Bộ test │ │ ├── accessibility.test.ts │ │ ├── accessibility-audit.test.ts │ │ ├── wcag-compliance.test.ts │ │ ├── performance.test.ts │ │ ├── cross-browser.test.ts │ │ └── setup.ts │ │ │ ├── assets/ # Ảnh, icon │ ├── App.tsx │ ├── main.tsx │ └── index.css │ ├── public/ # Tài nguyên tĩnh ├── dist/ # Output sau khi build (npm run build) ├── .env.production # Cấu hình môi trường production ├── .env.example ├── package.json ├── vite.config.ts ├── vitest.config.ts # Cấu hình test ├── tailwind.config.ts ├── tsconfig.json └── components.json # Cấu hình shadcn/ui Biến môi trường .env.production # OpenWeather API VITE_OPENWEATHER_API_KEY=8ff7f009d2bd420c86845c6bcf6de4a9 # CloudFront URL - Dùng để lấy dữ liệu bão VITE_CLOUDFRONT_URL=https://d3lj47ilp0fgxy.cloudfront.net # Lambda Function URL - API dự đoán bão VITE_PREDICTION_API_URL=https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Quy trình Build \u0026amp; Deploy 1. Build bản Production cd frontend npm run build Đầu ra: thư mục dist/ bao gồm:\nindex.html assets/index-[hash].js assets/index-[hash].css 2. Upload lên S3 aws s3 sync dist/ s3://storm-frontend-hosting-duc-2025/ --delete Important Notes:\nS3 bucket ở chế độ riêng tư (không public) CloudFront dùng REST API endpoint, không dùng website endpoint Origin: storm-frontend-hosting-duc-2025.s3.ap-southeast-1.amazonaws.com 3. Invalidate cache của CloudFront aws cloudfront create-invalidation \\ --distribution-id E1234567890ABC \\ --paths \u0026#34;/*\u0026#34; Luồng dữ liệu A. Tải dữ liệu bão (khi khởi động ứng dụng) Trình duyệt → CloudFront → S3 ↓ GET /recent_storms.json ↓ Parse JSON → Hiển thị lên bản đồ File: src/pages/Index.tsx (dòng ~40)\nconst CLOUDFRONT_URL = import.meta.env.VITE_CLOUDFRONT_URL; const FETCH_URL = `${CLOUDFRONT_URL}/recent_storms.json?t=${Date.now()}`; B. Dự báo bão (khi người dùng thao tác) Người dùng điền form → Nhấn \u0026#34;Run Prediction\u0026#34; ↓ POST /predict tới Lambda Function URL ↓ { \u0026#34;history\u0026#34;: [{lat, lng}, ...], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } ↓ Lambda xử lý → Trả về dự báo ↓ Hiển thị đường đi dự đoán lên bản đồ File: src/components/StormPredictionForm.tsx (dòng ~80)\nconst API_URL = `${import.meta.env.VITE_PREDICTION_API_URL}/predict`; const response = await fetch(API_URL, { method: \u0026#34;POST\u0026#34;, headers: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34; }, body: JSON.stringify({ history, storm_name }) }); Các thành phần chính 1. Thành phần cốt lõi StormPredictionForm File: src/components/StormPredictionForm.tsx\nTính năng:\nForm nhập tọa độ bão (tối thiểu 9 điểm) Kiểm tra dữ liệu đầu vào (lat/lng hợp lệ) Gọi Lambda API để dự báo Hiển thị kết quả lên bản đồ Danh sách vị trí có thể cuộn, hỗ trợ thêm/xóa điểm thuộc tính truyền:\ninterface StormPredictionFormProps { onPredictionResult: (result: PredictionResult) =\u0026gt; void; setIsLoading: (isLoading: boolean) =\u0026gt; void; } WeatherMap File: src/components/WeatherMap.tsx\nTính năng:\nHiển thị bản đồ Leaflet Vẽ quỹ đạo bão (lịch sử + dự báo) Vẽ đường dự đoán (màu tím, nét đứt) Lớp phủ thời tiết (nhiệt độ, gió, radar) Hiển thị nhiều cơn bão cùng lúc Tự động zoom tới cơn bão đang được chọn Dùng các pane tùy chỉnh để quản lý thứ tự lớp (z-index) Props:\ninterface WeatherMapProps { storms: Storm[]; selectedStorm?: Storm; customPrediction?: PredictionResult | null; mapFocusBounds?: LatLngBounds | null; onMapFocusComplete?: () =\u0026gt; void; } Mục cần chụp màn hình:\nWeb UI → Bản đồ có quỹ đạo bão (xanh/đỏ) Web UI → Đường dự đoán tùy chỉnh (màu tím, nét đứt) Web UI → Lớp phủ thời tiết (nhiệt độ/gió) Index (Trang chính) File: src/pages/Index.tsx\nTính năng:\nBố cục chính với header/footer Quản lý state (storms, selectedStorm, customPrediction) Sidebar có tab (Current Storms / Predict Storm) Đồng bộ trạng thái timeline Xử lý loading và lỗi Skip link hỗ trợ truy cập (accessibility) 2. Các component về bão StormTracker File: src/components/StormTracker.tsx\nDanh sách các cơn bão hiện tại Lọc theo trạng thái (active/developing/dissipated) Bấm để chọn cơn bão StormInfo File: src/components/StormInfo.tsx\nThông tin chi tiết về bão Tốc độ gió, áp suất, phân loại Dữ liệu lịch sử Timeline dự báo StormAnimation File: src/components/StormAnimation.tsx\nMarker động cho các vị trí của bão Hiệu ứng nhấp nháy/pulsing Màu sắc theo cấp độ bão 3. Các component lớp thời tiết WeatherOverlay File: src/components/WeatherOverlay.tsx\nLớp phủ heatmap nhiệt độ Trực quan hóa tốc độ gió Dữ liệu thời gian thực từ OpenWeather API Rê chuột để xem giá trị WeatherLayerControl File: src/components/WeatherLayerControl.tsx\nLớp ảnh vệ tinh (satellite) Lớp radar Lớp nhiệt độ Quản lý các tile layer WeatherLayerControlPanel File: src/components/WeatherLayerControlPanel.tsx\nĐiều khiển UI cho các lớp thời tiết Thanh chỉnh độ trong suốt (opacity) Nút bật/tắt layer Bật/tắt animation cho nhiệt độ OptimizedTemperatureLayer \u0026amp; TemperatureHeatMapLayer Files: src/components/OptimizedTemperatureLayer.tsx, TemperatureHeatMapLayer.tsx\nRender nhiệt độ tối ưu hiệu năng Nội suy màu (color interpolation) Heatmap dạng lưới (grid-based) 4. Các component về gió WindyLayer File: src/components/WindyLayer.tsx\nTích hợp Windy.com bằng iframe Lớp phủ animation gió Đồng bộ trạng thái với bản đồ chính Context: src/contexts/WindyStateContext.tsx\nState toàn cục cho lớp Windy Lưu trạng thái vào URL Đồng bộ giữa các component 5. Component nâng cấp bản đồ ProvinceLayer File: src/components/ProvinceLayer.tsx\nRanh giới tỉnh/thành Việt Nam Render GeoJSON Nhãn tên tỉnh/thành WeatherValueTooltip File: src/components/WeatherValueTooltip.tsx\nTooltip hiển thị giá trị thời tiết khi rê chuột Nhiệt độ, tốc độ gió, áp suất Tooltip định vị theo vị trí con trỏ 6. Các component UI ThemeToggle File: src/components/ThemeToggle.tsx\nChuyển chế độ Sáng/Tối Lưu lại tùy chọn người dùng Tự nhận theme theo hệ thống PreferencesModal File: src/components/PreferencesModal.tsx\nThiết lập tùy chọn người dùng Tùy chọn bản đồ Tùy chọn hiển thị RightSidebar File: src/components/RightSidebar.tsx\nPanel thông tin bổ sung Sidebar có thể thu gọn WeeklyForecast File: src/components/WeeklyForecast.tsx\nDự báo thời tiết 7 ngày Xu hướng nhiệt độ Icon thời tiết 7. Các component timeline Thư mục: src/components/timeline/\nĐiều khiển timeline cho hoạt ảnh bão Chức năng Play/Pause Kéo để tua thời gian (scrubbing) Điều chỉnh tốc độ Kiểu dữ liệu PredictionResult File: src/lib/stormData.ts\nexport interface PredictionResult { storm_id: string; storm_name: string; prediction_time: string; totalDistance: number; // km actualDistance: number; // km lifespan: number; // giờ forecastHours: number; // giờ forecast: StormPoint[]; // Các điểm vị trí dự đoán path?: StormPoint[]; // Hỗ trợ tương thích (legacy) } StormPoint export interface StormPoint { timestamp: number; // Unix timestamp (ms) lat: number; lng: number; windSpeed: number; // km/h pressure: number; // hPa category: string; // \u0026#34;Typhoon\u0026#34;, \u0026#34;Super Typhoon\u0026#34;, ... } `md\nQuyền IAM/AWS cần thiết S3 Bucket Policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PublicReadGetObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34; } ] } CloudFront Origin Access Origin: S3 bucket Origin Access: Public (hoặc OAI nếu dùng) Kiểm thử Local Development npm run dev # Mở http://localhost:5173 Kiểm thử bản build production npm run build npm run preview # Mở http://localhost:4173 Các lỗi thường gặp 1. Lỗi CORS khi gọi Lambda Đặc điểm: lỗi Access-Control-Allow-Origin\nCách xử lý: Lambda cần trả về header CORS:\nreturn { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } 2. CloudFront bị cache cũ Đặc điểm: Code mới không hiển thị\nCách xử lý: Invalidate cache\naws cloudfront create-invalidation --distribution-id E... --paths \u0026#34;/*\u0026#34; 3. Biến môi trường không được load Triệu chứng: undefined khi truy cập import.meta.env.VITE_*\nCách xử lý:\nĐảm bảo có file .env.production Build lại: npm run build Biến phải bắt đầu bằng VITE_ Checklist triển khai Cập nhật .env.production với đúng URL npm run build chạy thành công Upload dist/ lên S3 Invalidate CloudFront cache Test trên URL production Kiểm tra Lambda API hoạt động Kiểm tra dữ liệu bão tải được Test form dự đoán với 9+ điểm tọa độ API Endpoints 1. Lấy dữ liệu bão GET https://d3lj47ilp0fgxy.cloudfront.net/recent_storms.json Phản hồi: mảng các object Storm\n2. Dự đoán đường đi bão POST https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict Body: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Response: { \u0026#34;storm_id\u0026#34;: \u0026#34;unknown\u0026#34;, \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;totalDistance\u0026#34;: 500.5, \u0026#34;lifespan\u0026#34;: 72, \u0026#34;forecast\u0026#34;: [...] } Tối ưu hiệu năng 1. Tối ưu mã nguồn Code Splitting: Vite tự động tách chunk theo routes Tree Shaking: Loại bỏ code không dùng Minification: Build production tự nén JS/CSS Lazy Loading: Component được tải khi cần 2. Tối ưu dữ liệu Web Workers: Tính toán nặng chạy trong worker (dataWorker.ts) Memoization: Dùng React.memo cho component tốn tài nguyên Debouncing: Debounce cho handler input Caching: Lưu cache tùy chọn bằng LocalStorage 3. Tối ưu render Virtual Scrolling: Danh sách lớn dùng virtual scrolling Optimized Layers: OptimizedTemperatureLayer tối ưu hiệu năng Canvas Rendering: Heatmap render bằng canvas thay vì DOM Pane Management: Tạo Leaflet pane riêng để tối ưu z-index 4. Tối ưu mạng CDN Caching: CloudFront cache tài nguyên tĩnh Image Optimization: WebP, lazy loading API Caching: Cache dữ liệu bão kèm timestamp Compression: Nén Gzip/Brotli 5. Tối ưu cho khả năng truy cập (Accessibility) Skip Links: Phím tắt điều hướng bằng bàn phím ARIA Labels: Dùng nhãn ARIA và HTML ngữ nghĩa đúng Focus Management: Quản lý focus, đảm bảo thứ tự tab hợp lý Screen Reader: Tối ưu để hoạt động tốt với trình đọc màn hình Thư viện \u0026amp; tiện ích Business Logic (lib/) Quản lý bão stormData.ts: Kiểu dữ liệu, interface, định nghĩa Storm/StormPoint stormAnimations.ts: Logic animation cho marker bão stormIntensityChanges.ts: Tính toán thay đổi cường độ bão stormPerformance.ts: Tối ưu hiệu năng render stormValidation.ts: Kiểm tra/validate dữ liệu bão Hệ thống gió windData.ts: Cấu trúc dữ liệu gió windStrengthCalculations.ts: Tính toán cường độ gió windyStatePersistence.ts: Lưu trạng thái lớp Windy windyUrlState.ts: Quản lý trạng thái theo URL cho Windy Bản đồ \u0026amp; thời tiết mapUtils.ts: Tiện ích bản đồ (center, zoom, tính bounds) openWeatherMapClient.ts: Client gọi OpenWeather API colorInterpolation.ts: Tính toán gradient/nội suy màu Hiệu năng dataWorker.ts: Web Worker cho tác vụ tính toán nặng utils.ts: Tiện ích dùng chung Custom Hooks (hooks/) use-toast.ts: Hệ thống thông báo toast use-theme.tsx: Quản lý theme sáng/tối use-mobile.tsx: Nhận diện thiết bị mobile useTimelineState.ts: Đồng bộ trạng thái timeline useWindyStateSync.ts: Đồng bộ trạng thái lớp Windy useSimplifiedTooltip.ts: Logic tooltip rút gọn Context (contexts/) WindyStateContext.tsx: State toàn cục cho tích hợp lớp Windy Testing (test/) accessibility.test.ts: Kiểm thử accessibility accessibility-audit.test.ts: Audit theo WCAG wcag-compliance.test.ts: Kiểm thử tuân thủ WCAG 2.1 performance.test.ts: Benchmark hiệu năng cross-browser.test.ts: Kiểm thử tương thích đa trình duyệt setup.ts: Thiết lập môi trường test Dependencies Core React 18 TypeScript Vite (công cụ build) Vitest (framework test) UI Framework Tailwind CSS shadcn/ui (thư viện component) Lucide Icons Radix UI (primitives) Map \u0026amp; Visualization Leaflet React-Leaflet Hỗ trợ GeoJSON API \u0026amp; Data Fetch API (native) OpenWeather API AWS Lambda Function URL Quản lý state React Context API State theo URL (query params) Lưu trạng thái bằng LocalStorage Hiệu năng Web Workers Code splitting (Vite) Lazy loading Ảnh chụp tài liệu CloudFront Phân phối (Distribution) Hình 1 Cài đặt Origin (Origin Settings) Hình 1 Invalidations Hình 2 storm-frontend-hosting-duc-2025 Hình 3 Phân quyền (Permissions) Hình 4 storm-ai-models-2025 Hình 5 storm-data-store-2025 Hình 6 Trang chính (Main Page) Hình 7 Tính năng theo dõi bão (Storm Tracking Features) Hình 8 Chi tiết cơn bão (Storm Details) Hình 9 Tính năng dự đoán (Predict Feature) Hình 10 Hình 11 Hình 12 "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/","title":"Kiến trúc Lambda","tags":[],"description":"","content":"Kiến trúc Lambda - Dịch vụ AI Dự báo Bão Tổng quan Hàm Lambda là một thành phần quan trọng trong kiến trúc serverless. Chúng đặc biệt hữu ích nhờ chi phí vận hành thấp và khả năng triển khai dễ dàng—những yếu tố rất phù hợp với nền tảng dự đoán bão của nhóm.\nPhần này trình bày chi tiết cách chúng tôi thiết kế và xây dựng kiến trúc Lambda.\nCác hàm Lambda của chúng em chạy mô hình PyTorch để dự đoán quỹ đạo bão và được triển khai thông qua Docker container image.\nKiến trúc các dịch vụ AWS ┌─────────────────────────────────────────────────────────────┐ │ Frontend (Trình duyệt) │ └────────────────────────┬────────────────────────────────────┘ │ POST /predict ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function URL (Công khai) │ │ URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi... │ │ Auth: NONE (không xác thực) │ │ Method: POST │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ Lambda Function │ │ Tên: storm-prediction │ │ Runtime: Python 3.10 (Container) │ │ Bộ nhớ: 3008 MB │ │ Timeout: 120 giây │ │ Kiến trúc: x86_64 │ └────────────────────────┬────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────┐ │ ECR Repository │ │ Account: 339570693867 │ │ Region: ap-southeast-1 │ │ Repo: storm-prediction │ │ Image: latest │ │ Size: ~2 GB │ └────────────────────────┬────────────────────────────────────┘ ┌─────────────────────────────────────────────────────────────┐ │ S3 Buckets │ │ 1. storm-frontend-hosting-duc-2025 │ │ - models/lstm_totald_256_4.pt (tùy chọn) │ │ - predictions/[storm_id]_[timestamp].json │ │ │ │ 2. storm-ai-models (khuyến nghị) │ │ - models/lstm_totald_256_4.pt │ │ - models/tcn_model.pth (backup) │ └─────────────────────────────────────────────────────────────┘ Cấu trúc thư mục storm_prediction/ storm_prediction/ ├── app.py # Lambda handler (mã chính) ├── Dockerfile # Định nghĩa container ├── requirements.txt # Thư viện Python phụ thuộc ├── cropping_storm_7304_2l.pth # Mô hình TCN (đóng kèm trong image) │ ├── DEPLOY_NOW.md # Hướng dẫn deploy nhanh ├── DEPLOY_CONSOLE_STEP_BY_STEP.md # Hướng dẫn AWS Console từng bước ├── LAMBDA_DEPLOYMENT_GUIDE.md # Hướng dẫn triển khai chi tiết ├── AWS_CONSOLE_DEPLOYMENT_GUIDE.md ├── FIX_ECR_PUSH_ERROR.md # Tài liệu xử lý lỗi ECR ├── FIX_UNICODE_ERROR.md # Sửa lỗi UnicodeDecodeError ├── FIX_UNICODE_ERROR_SOLUTION.md # Chi tiết giải pháp └── REBUILD_AND_DEPLOY.sh # Script tự động build \u0026amp; deploy Cấu trúc Docker Image Dockerfile FROM public.ecr.aws/lambda/python:3.10 # Cài đặt dependencies COPY requirements.txt . RUN pip3 install -r requirements.txt \\ --target \u0026#34;${LAMBDA_TASK_ROOT}\u0026#34; \\ --extra-index-url https://download.pytorch.org/whl/cpu # Copy Lambda handler COPY app.py ${LAMBDA_TASK_ROOT} # Copy mô hình TCN vào thư mục con (tránh nhầm file .pth) RUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ # Đặt handler CMD [ \u0026#34;app.handler\u0026#34; ] Các lớp (Image Layers) Layer 1: AWS Lambda Python 3.10 base (~500 MB) Layer 2: PyTorch CPU + dependencies (~1.2 GB) Layer 3: app.py + mô hình TCN (~300 MB) ───────────────────────────────────────────── Tổng dung lượng: ~2 GB Các mô hình AI 1. Mô hình TCN (Dự đoán quỹ đạo) File: cropping_storm_7304_2l.pth\nVị trí: Bên trong Docker image tại /var/task/models/\nDung lượng: ~300 MB\nMục đích: Dự đoán bước tiếp theo (lat, lng) của quỹ đạo bão\nKiến trúc:\nclass StormTCN(nn.Module): def __init__(self, input_dim=4, hidden_units=1024, num_layers=2): self.tcn = TCN(...) self.head_latlon = nn.Linear(hidden_units, 2) # Dự đoán lat, lng self.head_aux = nn.Linear(hidden_units, 2) # Dự đoán đặc trưng phụ Input: [batch, sequence, 4] - (lat, lng, distance, bearing)\nOutput:\npred_latlon: (lat, lng) kế tiếp pred_aux: đặc trưng phụ 2. Mô hình LSTM (Dự đoán tổng quãng đường) File: lstm_totald_256_4.pt\nVị trí: S3 bucket (tải về ở lần chạy đầu tiên)\nDung lượng: ~50 MB\nMục đích: Dự đoán tổng quãng đường bão sẽ di chuyển\nKiến trúc:\nclass StormLSTM(nn.Module): def __init__(self, input_size=4, hidden_size=256, num_layers=2): self.lstm = nn.LSTM(...) self.fc = nn.Sequential( nn.Linear(hidden_size, hidden_size // 2), nn.ReLU(), nn.Linear(hidden_size // 2, 1) # Dự đoán tổng quãng đường ) Input: Tổng hợp theo ngày [batch, days, 4] - (day, daily_dist, avg_speed, motion_type)\nOutput: Tổng quãng đường (km)\nLuồng xử lý request 1. Nhận request POST /predict Content-Type: application/json { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... // Tối thiểu 9 điểm ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34;, \u0026#34;storm_id\u0026#34;: \u0026#34;TEST001\u0026#34; // Tùy chọn } 2. Tải mô hình (chỉ lần gọi đầu tiên) def load_models(): global LSTM_MODEL, TCN_MODEL # Tải LSTM từ S3 (nếu có) if not os.path.exists(\u0026#39;/tmp/lstm_model.pt\u0026#39;): s3_client.download_file( MODEL_BUCKET, \u0026#39;models/lstm_totald_256_4.pt\u0026#39;, \u0026#39;/tmp/lstm_model.pt\u0026#39; ) LSTM_MODEL = StormLSTM(...) LSTM_MODEL.load_state_dict(torch.load(\u0026#39;/tmp/lstm_model.pt\u0026#39;)) # Tải TCN từ local (đã có sẵn trong image) TCN_MODEL = StormTCN(...) TCN_MODEL.load_state_dict( torch.load(\u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;) ) 4. Dự đoán tổng quãng đường (LSTM) def predict_total_distance(record_tensor): if LSTM_MODEL is None: # Dự phòng (fallback): avg_distance * 24 bước return fallback_distance # Gom theo ngày (9 điểm/ngày) # Chạy dự đoán bằng LSTM with torch.no_grad(): pred = LSTM_MODEL(summary_tensor, lengths) return pred.item() # km 5. Dự đoán đường đi (TCN) def predict_storm_path(record_tensor, total_distance, history): seq = record_tensor.clone() gone_distance = 0 predicted_points = [] while gone_distance \u0026lt; total_distance: # Dự đoán vị trí tiếp theo pred_latlon, pred_aux = TCN_MODEL(seq) new_lat = pred_latlon[0, -1, 0].item() new_lng = pred_latlon[0, -1, 1].item() # Tính khoảng cách \u0026amp; hướng di chuyển step_distance = haversine(last_lat, last_lng, new_lat, new_lng) # Ước lượng tốc độ gió (giảm dần theo thời gian) estimated_wind = max(avg_wind * (0.98 ** step), 30) predicted_points.append({ \u0026#39;lat\u0026#39;: new_lat, \u0026#39;lng\u0026#39;: new_lng, \u0026#39;timestamp\u0026#39;: base_timestamp + (step * 3 * 3600 * 1000), \u0026#39;windSpeed\u0026#39;: estimated_wind, \u0026#39;pressure\u0026#39;: 980.0, \u0026#39;category\u0026#39;: calculate_category(estimated_wind) }) # Cập nhật chuỗi (sliding window) seq = torch.cat([seq[:, 1:, :], next_point.unsqueeze(1)], dim=1) gone_distance += step_distance step += 1 return predicted_points 6. Trả về response result = { \u0026#39;storm_id\u0026#39;: storm_id, \u0026#39;storm_name\u0026#39;: storm_name, \u0026#39;prediction_time\u0026#39;: datetime.now().isoformat(), \u0026#39;totalDistance\u0026#39;: 500.5, \u0026#39;actualDistance\u0026#39;: 520.3, \u0026#39;lifespan\u0026#39;: 72, \u0026#39;forecastHours\u0026#39;: 72, \u0026#39;forecast\u0026#39;: [ { \u0026#39;lat\u0026#39;: 15.1, \u0026#39;lng\u0026#39;: 106.99, \u0026#39;timestamp\u0026#39;: 1765015351626, \u0026#39;windSpeed\u0026#39;: 65, \u0026#39;pressure\u0026#39;: 980, \u0026#39;category\u0026#39;: \u0026#39;Typhoon\u0026#39; }, ... ] } return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } Quy trình Build \u0026amp; Deploy Bước 1: Build Docker Image cd storm_prediction docker build \\ --provenance=false \\ --platform linux/amd64 \\ -t storm-prediction-model . Giải thích flags:\n--provenance=false: Giảm kích thước image (không kèm metadata build) --platform linux/amd64: Lambda chỉ hỗ trợ x86_64 -t storm-prediction-model: Tên tag của image Bước 2: Tag để push lên ECR docker tag storm-prediction-model:latest \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Đăng nhập ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push image lên ECR docker push \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Thời gian: ~5–10 phút (upload ~2GB)\nBước 5: Cập nhật Lambda Function Trên AWS Console:\nLambda → storm-prediction Tab Image → Deploy new image Chọn image latest Nhấn Save Cấu hình Lambda Thiết lập Function Name: storm-prediction Runtime: Container image Architecture: x86_64 Memory: 3008 MB Timeout: 120 seconds Ephemeral storage: 512 MB Biến môi trường MODEL_BUCKET=storm-frontend-hosting-duc-2025 DATA_BUCKET=storm-frontend-hosting-duc-2025 Function URL URL: https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws Auth type: NONE CORS: Enabled - Allow origins: * - Allow methods: POST, OPTIONS - Allow headers: Content-Type Quyền IAM Role { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::storm-frontend-hosting-duc-2025/*\u0026#34;, \u0026#34;arn:aws:s3:::storm-ai-models/*\u0026#34; ] } ] } Giám sát \u0026amp; Logs CloudWatch Logs Log Group: /aws/lambda/storm-prediction\nCác log quan trọng:\nLoading LSTM model... Downloaded LSTM from S3 LSTM loaded successfully Loading TCN model... Checking: /var/task/models/cropping_storm_7304_2l.pth Found TCN at /var/task/models/cropping_storm_7304_2l.pth TCN loaded successfully Processing: Test Storm (TEST001) Input points: 9 Predicted total distance: 500.50 km Generated 24 predictions (72 hours) Saved to S3: predictions/TEST001_1733486400.json Metrics CloudWatch Metrics:\nInvocations Duration (trung bình ~5–10 giây) Errors Throttles Memory used (~500–800 MB) Lỗi thường gặp \u0026amp; cách xử lý 1. UnicodeDecodeError: \u0026lsquo;utf-8\u0026rsquo; codec can\u0026rsquo;t decode byte 0x80 Triệu chứng:\nUnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64 Nguyên nhân: file model .pth ở thư mục gốc bị Lambda hiểu nhầm như file cấu hình Python\nCách xử lý: chuyển model vào thư mục con\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. 502 Bad Gateway Triệu chứng: Frontend nhận lỗi 502\nNguyên nhân có thể:\nLambda timeout (quá 120s) Lambda crash (hết bộ nhớ) Load model thất bại Cách xử lý:\nKiểm tra CloudWatch Logs Tăng memory nếu cần Tăng timeout nếu cần 3. LSTM Fallback Đặc điểm: log có \u0026quot; Using fallback distance\u0026quot;\nNguyên nhân: chưa có model LSTM trên S3\nCách xử lý: upload lstm_totald_256_4.pt lên S3\naws s3 cp lstm_totald_256_4.pt \\ s3://storm-frontend-hosting-duc-2025/models/ 4. ECR Push 403 Forbidden Đặc điểm: 403 Forbidden khi push image\nNguyên nhân có thể:\nHết hạn đăng nhập ECR Sai account ID Repo chưa tồn tại Cách xử lý:\n# Đăng nhập lại aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ 339570693867.dkr.ecr.ap-southeast-1.amazonaws.com # Tạo repository nếu cần aws ecr create-repository \\ --repository-name storm-prediction \\ --region ap-southeast-1 Kiểm thử Test local (nếu có thể) # Chạy local python app.py # Test event test_event = { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, ... ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } result = handler(test_event, None) print(result) Test trực tiếp trên Lambda Trên AWS Console:\nLambda → tab Test Tạo test event: { \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 120.0}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 120.1}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 120.2}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 120.3}, {\u0026#34;lat\u0026#34;: 15.4, \u0026#34;lng\u0026#34;: 120.4}, {\u0026#34;lat\u0026#34;: 15.5, \u0026#34;lng\u0026#34;: 120.5}, {\u0026#34;lat\u0026#34;: 15.6, \u0026#34;lng\u0026#34;: 120.6}, {\u0026#34;lat\u0026#34;: 15.7, \u0026#34;lng\u0026#34;: 120.7}, {\u0026#34;lat\u0026#34;: 15.8, \u0026#34;lng\u0026#34;: 120.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; } Nhấn Test Kiểm tra response Test bằng cURL bash curl -X POST \\ \u0026quot;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026quot; \\ -H \u0026quot;Content-Type: application/json\u0026quot; \\ -d '{ \u0026quot;history\u0026quot;: [ {\u0026quot;lat\u0026quot;: 15.0, \u0026quot;lng\u0026quot;: 120.0}, {\u0026quot;lat\u0026quot;: 15.1, \u0026quot;lng\u0026quot;: 120.1}, {\u0026quot;lat\u0026quot;: 15.2, \u0026quot;lng\u0026quot;: 120.2}, {\u0026quot;lat\u0026quot;: 15.3, \u0026quot;lng\u0026quot;: 120.3}, {\u0026quot;lat\u0026quot;: 15.4, \u0026quot;lng\u0026quot;: 120.4}, {\u0026quot;lat\u0026quot;: 15.5, \u0026quot;lng\u0026quot;: 120.5}, {\u0026quot;lat\u0026quot;: 15.6, \u0026quot;lng\u0026quot;: 120.6}, {\u0026quot;lat\u0026quot;: 15.7, \u0026quot;lng\u0026quot;: 120.7}, {\u0026quot;lat\u0026quot;: 15.8, \u0026quot;lng\u0026quot;: 120.8} ], \u0026quot;storm_name\u0026quot;: \u0026quot;Test Storm\u0026quot; }' Checklist triển khai File model cropping_storm_7304_2l.pth tồn tại (Tùy chọn) Upload model LSTM lên S3 Build Docker image thành công Tag image đúng account ID (339570693867) Login ECR thành công Push image lên ECR Update Lambda function với image mới Kiểm tra cấu hình Lambda (memory, timeout) Test Lambda với test event Test qua Function URL bằng cURL Test từ frontend Kiểm tra CloudWatch Logs Xác nhận kết quả dự đoán hiển thị trên bản đồ Ảnh chụp Hình 1 Cấu hình (Configuration) Hình 2 Biến môi trường (Environment Variables) Hình 3 ECR Kho lưu trữ (Repository) Hình 4 Hình 5 "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.2-fix-unicode-error-solution/","title":"Sửa lỗi Unicode","tags":[],"description":"","content":"Giải quyết lỗi UnicodeDecodeError trong Lambda Đây là một lỗi quan trọng mà nhóm gặp phải trong quá trình xây dựng nền tảng và tích hợp model nên dành riêng một mục để nói về nó. Chi tiết xe ở bên dưới.\nVấn đề UnicodeDecodeError: \u0026#39;utf-8\u0026#39; codec can\u0026#39;t decode byte 0x80 in position 64: invalid start byte Nguyên nhân Model PyTorch có extension .pth (binary file) Python runtime cũng sử dụng .pth files cho path configuration (text files) Khi đặt model .pth trực tiếp trong LAMBDA_TASK_ROOT, Python cố đọc nó như text → lỗi Giải pháp đã áp dụng 1. Sửa Dockerfile Di chuyển model vào thư mục con models/:\nRUN mkdir -p ${LAMBDA_TASK_ROOT}/models COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/models/ 2. Sửa app.py Update đường dẫn tìm model:\npossible_paths = [ \u0026#39;/var/task/models/cropping_storm_7304_2l.pth\u0026#39;, \u0026#39;models/cropping_storm_7304_2l.pth\u0026#39;, tcn_path ] Các bước rebuild và deploy Bước 1: Build Docker image cd storm_prediction docker build --provenance=false --platform linux/amd64 -t storm-prediction-model . Lưu ý: --provenance=false giúp giảm kích thước image để push lên ECR\nBước 2: Tag image docker tag storm-prediction-model:latest 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 3: Login ECR aws ecr get-login-password --region ap-southeast-1 | docker login --username AWS --password-stdin 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com Bước 4: Push to ECR docker push 211125445874.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction:latest Bước 5: Update Lambda Vào AWS Console → Lambda → storm-prediction Click tab Image Click Deploy new image Chọn image mới nhất Click Save Bước 6: Test curl -X POST \u0026#34;https://vill3povlzqxdyxm7ubldizobu0kdgbi.lambda-url.ap-southeast-1.on.aws/predict\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;history\u0026#34;: [ {\u0026#34;lat\u0026#34;: 14.5, \u0026#34;lng\u0026#34;: 121.0}, {\u0026#34;lat\u0026#34;: 14.6, \u0026#34;lng\u0026#34;: 121.1}, {\u0026#34;lat\u0026#34;: 14.7, \u0026#34;lng\u0026#34;: 121.2}, {\u0026#34;lat\u0026#34;: 14.8, \u0026#34;lng\u0026#34;: 121.3}, {\u0026#34;lat\u0026#34;: 14.9, \u0026#34;lng\u0026#34;: 121.4}, {\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 121.5}, {\u0026#34;lat\u0026#34;: 15.1, \u0026#34;lng\u0026#34;: 121.6}, {\u0026#34;lat\u0026#34;: 15.2, \u0026#34;lng\u0026#34;: 121.7}, {\u0026#34;lat\u0026#34;: 15.3, \u0026#34;lng\u0026#34;: 121.8} ], \u0026#34;storm_name\u0026#34;: \u0026#34;Test Storm\u0026#34; }\u0026#39; Kiểm tra logs sau khi deploy aws logs tail /aws/lambda/storm-prediction --region ap-southeast-1 --follow Tóm tắt Trước: Model .pth ở root → Python nhầm là config file → UnicodeDecodeError Sau: Model .pth ở models/ → Python bỏ qua → Lambda hoạt động "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.1-ai-model-integration/","title":"Tích Hợp AI","tags":[],"description":"","content":"Tiến hành tích hợp AI Model từ Lambda Tổng quan Dưới đây xin trình bày về cách mà nhóm đã tích hợp mô hình AI dự đoán bão từ lambda để dùng theo từng bước.\nCác file đang dùng Mock Data 1. WeatherOverlay.tsx (QUAN TRỌNG) Vị trí: frontend/src/components/WeatherOverlay.tsx Mock data: Temperature và Wind overlay data Function: generateWeatherData() Cần sửa: Thay thế bằng API call đến Lambda 2. WeeklyForecast.tsx Vị trí: frontend/src/components/WeeklyForecast.tsx Mock data: mockForecast array Cần sửa: Fetch từ backend API 3. windData.ts Vị trí: frontend/src/lib/windData.ts Mock data: mockWindData Cần sửa: Fetch từ OpenWeatherMap hoặc Lambda 4. WindFieldManager.ts Vị trí: frontend/src/components/wind/WindFieldManager.ts Mock data: Fallback khi không có API key Đã OK: Có logic fetch từ OpenWeatherMap, chỉ cần config API key Cách tích hợp AI Model từ Lambda Bước 1: Thêm API endpoint cho Storm Prediction Trong file frontend/src/api/weatherApi.ts, thêm:\nexport interface StormPrediction { stormId: string; name: string; nameVi: string; currentPosition: { lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }; historicalTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; }\u0026gt;; forecastTrack: Array\u0026lt;{ lat: number; lng: number; timestamp: number; windSpeed: number; pressure: number; category: string; confidence?: number; // Độ tin cậy từ AI model }\u0026gt;; } export const weatherApi = { // ... existing methods ... // Lấy dự đoán bão từ Lambda AI model getStormPredictions: async (): Promise\u0026lt;StormPrediction[]\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction[]\u0026gt;(\u0026#39;/storms/predictions\u0026#39;); return response.data; }, // Lấy chi tiết một cơn bão cụ thể getStormById: async (stormId: string): Promise\u0026lt;StormPrediction\u0026gt; =\u0026gt; { const response = await api.get\u0026lt;StormPrediction\u0026gt;(`/storms/${stormId}`); return response.data; }, }; Bước 2: Cập nhật Backend để gọi Lambda Trong backend C# (backend/Controllers/WeatherController.cs), thêm endpoint:\n[HttpGet(\u0026#34;storms/predictions\u0026#34;)] public async Task\u0026lt;IActionResult\u0026gt; GetStormPredictions() { try { // Gọi Lambda function var lambdaClient = new AmazonLambdaClient(); var request = new InvokeRequest { FunctionName = \u0026#34;storm-prediction-function\u0026#34;, InvocationType = InvocationType.RequestResponse, Payload = \u0026#34;{}\u0026#34; // Hoặc parameters nếu cần }; var response = await lambdaClient.InvokeAsync(request); using var reader = new StreamReader(response.Payload); var result = await reader.ReadToEndAsync(); return Ok(JsonSerializer.Deserialize\u0026lt;List\u0026lt;StormPrediction\u0026gt;\u0026gt;(result)); } catch (Exception ex) { return StatusCode(500, new { error = ex.Message }); } } Bước 3: Cập nhật Frontend để dùng API thật Trong frontend/src/pages/Index.tsx hoặc nơi fetch storm data:\nimport { weatherApi } from \u0026#39;../api/weatherApi\u0026#39;; import { useQuery } from \u0026#39;@tanstack/react-query\u0026#39;; // Thay vì dùng mock data const { data: storms, isLoading } = useQuery({ queryKey: [\u0026#39;storms\u0026#39;], queryFn: () =\u0026gt; weatherApi.getStormPredictions(), refetchInterval: 5 * 60 * 1000, // Refresh mỗi 5 phút }); Bước 4: Cấu hình Environment Variables Frontend (.env.production):\nVITE_API_BASE_URL=https://your-backend-api.com/api/weather Backend (appsettings.json):\n{ \u0026#34;AWS\u0026#34;: { \u0026#34;Region\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, \u0026#34;LambdaFunctionName\u0026#34;: \u0026#34;storm-prediction-function\u0026#34; } } Checklist Deploy Deploy AI model lên Lambda Test Lambda function với sample input Thêm API endpoint trong backend C# Test backend endpoint Cập nhật weatherApi.ts với endpoints mới Thay thế mock data bằng API calls Test frontend với data thật Cập nhật .env.production với URL production Build và deploy frontend Monitor logs và errors Files không cần sửa (chỉ là examples) Các file này chỉ là demo/example, không ảnh hưởng production:\n*.example.tsx */__tests__/* */GUIDE.md "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.4-frontback-end/5.4.2-lambda-architecture/5.4.2.3-lambda-deployment/","title":"Triển Khai Lamda","tags":[],"description":"","content":"Các bước Deploy PyTorch Model dự đoán bão lên AWS Lambda Việc triển khai Lambda là một phần quan trọng trong quy trình phát triển website của nhóm. Mục sau đây sẽ giải thích các bước chúng em đã thực hiện để hoàn thành quy trình này.\nChuẩn bị Code 1.1. Sửa app.py\nimport json import torch import numpy as np from typing import List, Dict # Load model khi Lambda khởi động (reuse across invocations) MODEL_PATH = \u0026#34;model.pth\u0026#34; device = torch.device(\u0026#34;cpu\u0026#34;) # Lambda không có GPU model = None def load_model(): global model if model is None: print(f\u0026#34;Loading model from {MODEL_PATH}...\u0026#34;) model = torch.load(MODEL_PATH, map_location=device) model.eval() print(\u0026#34;Model loaded successfully!\u0026#34;) return model def prepare_features(history: List[Dict]) -\u0026gt; torch.Tensor: \u0026#34;\u0026#34;\u0026#34; Chuyển đổi history thành tensor cho model history: [{\u0026#34;lat\u0026#34;: 15.0, \u0026#34;lng\u0026#34;: 107.0}, ...] \u0026#34;\u0026#34;\u0026#34; # TODO: Implement feature engineering theo model của bạn lats = [p[\u0026#34;lat\u0026#34;] for p in history] lngs = [p[\u0026#34;lng\u0026#34;] for p in history] # Ví dụ: normalize và reshape features = np.array([lats + lngs]) # Shape: (1, 18) return torch.tensor(features, dtype=torch.float32) def format_predictions(predictions: torch.Tensor, storm_name: str) -\u0026gt; Dict: \u0026#34;\u0026#34;\u0026#34; Format output theo cấu trúc frontend cần \u0026#34;\u0026#34;\u0026#34; # TODO: Implement theo output của model pred_array = predictions.detach().cpu().numpy()[0] # Giả sử model predict 10 điểm tiếp theo (lat, lng) forecast = [] base_timestamp = int(time.time() * 1000) for i in range(0, len(pred_array), 2): if i + 1 \u0026lt; len(pred_array): forecast.append({ \u0026#34;lat\u0026#34;: float(pred_array[i]), \u0026#34;lng\u0026#34;: float(pred_array[i + 1]), \u0026#34;timestamp\u0026#34;: base_timestamp + (i // 2) * 3600000, # +1 hour each \u0026#34;windSpeed\u0026#34;: 120.0, # TODO: Predict từ model \u0026#34;pressure\u0026#34;: 980.0, # TODO: Predict từ model \u0026#34;category\u0026#34;: \u0026#34;Category 3\u0026#34;, # TODO: Classify từ windSpeed \u0026#34;confidence\u0026#34;: 0.85 }) return { \u0026#34;storm_name\u0026#34;: storm_name, \u0026#34;forecast\u0026#34;: forecast } def handler(event, context): \u0026#34;\u0026#34;\u0026#34; Lambda handler function \u0026#34;\u0026#34;\u0026#34; try: # Parse input body = json.loads(event.get(\u0026#39;body\u0026#39;, \u0026#39;{}\u0026#39;)) history = body.get(\u0026#39;history\u0026#39;, []) storm_name = body.get(\u0026#39;storm_name\u0026#39;, \u0026#39;Unknown Storm\u0026#39;) # Validate input if len(history) \u0026lt; 9: return { \u0026#39;statusCode\u0026#39;: 400, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: f\u0026#39;Need at least 9 positions, got {len(history)}\u0026#39; }) } # Load model model = load_model() # Prepare features X = prepare_features(history) # Predict with torch.no_grad(): predictions = model(X) # Format output result = format_predictions(predictions, storm_name) return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps(result) } except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return { \u0026#39;statusCode\u0026#39;: 500, \u0026#39;headers\u0026#39;: { \u0026#39;Content-Type\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;Access-Control-Allow-Origin\u0026#39;: \u0026#39;*\u0026#39; }, \u0026#39;body\u0026#39;: json.dumps({ \u0026#39;error\u0026#39;: str(e) }) } 1.2. Sửa Dockerfile\nFROM public.ecr.aws/lambda/python:3.11 # Copy requirements và install COPY requirements.txt ${LAMBDA_TASK_ROOT} RUN pip install --no-cache-dir -r requirements.txt # Copy model (đổi tên thành model.pth) COPY cropping_storm_7304_2l.pth ${LAMBDA_TASK_ROOT}/model.pth # Copy code COPY app.py ${LAMBDA_TASK_ROOT} # Set handler CMD [\u0026#34;app.handler\u0026#34;] 1.3. Kiểm tra requirements.txt\ntorch==2.1.0 numpy==1.24.3 Bước 2: Build Docker Image cd storm_prediction # Build image docker build -t storm-prediction-model . # Test local (optional) docker run -p 9000:8080 storm-prediction-model # Test với curl curl -X POST \u0026#34;http://localhost:9000/2015-03-31/functions/function/invocations\u0026#34; \\ -d \u0026#39;{ \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;history\\\u0026#34;: [{\\\u0026#34;lat\\\u0026#34;: 15.0, \\\u0026#34;lng\\\u0026#34;: 107.0}, {\\\u0026#34;lat\\\u0026#34;: 15.1, \\\u0026#34;lng\\\u0026#34;: 107.1}, {\\\u0026#34;lat\\\u0026#34;: 15.2, \\\u0026#34;lng\\\u0026#34;: 107.2}, {\\\u0026#34;lat\\\u0026#34;: 15.3, \\\u0026#34;lng\\\u0026#34;: 107.3}, {\\\u0026#34;lat\\\u0026#34;: 15.4, \\\u0026#34;lng\\\u0026#34;: 107.4}, {\\\u0026#34;lat\\\u0026#34;: 15.5, \\\u0026#34;lng\\\u0026#34;: 107.5}, {\\\u0026#34;lat\\\u0026#34;: 15.6, \\\u0026#34;lng\\\u0026#34;: 107.6}, {\\\u0026#34;lat\\\u0026#34;: 15.7, \\\u0026#34;lng\\\u0026#34;: 107.7}, {\\\u0026#34;lat\\\u0026#34;: 15.8, \\\u0026#34;lng\\\u0026#34;: 107.8}], \\\u0026#34;storm_name\\\u0026#34;: \\\u0026#34;Test Storm\\\u0026#34;}\u0026#34; }\u0026#39; Bước 3: Upload lên AWS ECR # 1. Tạo ECR repository aws ecr create-repository \\ --repository-name storm-prediction-model \\ --region ap-southeast-1 # 2. Đăng nhập Docker vào ECR aws ecr get-login-password --region ap-southeast-1 | \\ docker login --username AWS --password-stdin \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com # 3. Tag image docker tag storm-prediction-model:latest \\ \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest # 4. Push image docker push \u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest Lưu ý: Thay \u0026lt;account-id\u0026gt; bằng AWS Account ID của bạn.\nBước 4: Tạo Lambda Function 4.1. Tạo Lambda từ Console\nVào AWS Lambda Console Click \u0026ldquo;Create function\u0026rdquo; Chọn \u0026ldquo;Container image\u0026rdquo; Function name: storm-prediction Container image URI: Chọn image vừa push lên ECR Architecture: x86_64 Click \u0026ldquo;Create function\u0026rdquo; 4.2. Cấu hình Lambda\n# Hoặc dùng AWS CLI aws lambda create-function \\ --function-name storm-prediction \\ --package-type Image \\ --code ImageUri=\u0026lt;account-id\u0026gt;.dkr.ecr.ap-southeast-1.amazonaws.com/storm-prediction-model:latest \\ --role arn:aws:iam::\u0026lt;account-id\u0026gt;:role/lambda-execution-role \\ --timeout 60 \\ --memory-size 3008 \\ --region ap-southeast-1 Cấu hình quan trọng:\nMemory: 3008 MB (PyTorch model cần nhiều RAM) Timeout: 60 seconds (model inference có thể mất 10-30s) Ephemeral storage: 512 MB (default, tăng nếu cần) 4.3. Tạo IAM Role\nLambda cần role với permissions:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:logs:*:*:*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ecr:GetDownloadUrlForLayer\u0026#34;, \u0026#34;ecr:BatchGetImage\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Bước 5: Tạo API Gateway # 1. Tạo REST API aws apigateway create-rest-api \\ --name storm-prediction-api \\ --region ap-southeast-1 # 2. Lấy API ID và Root Resource ID API_ID=\u0026lt;your-api-id\u0026gt; ROOT_ID=\u0026lt;your-root-resource-id\u0026gt; # 3. Tạo resource /predict aws apigateway create-resource \\ --rest-api-id $API_ID \\ --parent-id $ROOT_ID \\ --path-part predict # 4. Tạo POST method RESOURCE_ID=\u0026lt;predict-resource-id\u0026gt; aws apigateway put-method \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --authorization-type NONE # 5. Integrate với Lambda aws apigateway put-integration \\ --rest-api-id $API_ID \\ --resource-id $RESOURCE_ID \\ --http-method POST \\ --type AWS_PROXY \\ --integration-http-method POST \\ --uri arn:aws:apigateway:ap-southeast-1:lambda:path/2015-03-31/functions/arn:aws:lambda:ap-southeast-1:\u0026lt;account-id\u0026gt;:function:storm-prediction/invocations # 6. Deploy API aws apigateway create-deployment \\ --rest-api-id $API_ID \\ --stage-name prod API URL: https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod/predict\nBước 6: Cập nhật Frontend 6.1. Cập nhật .env.production\nVITE_PREDICTION_API_URL=https://\u0026lt;api-id\u0026gt;.execute-api.ap-southeast-1.amazonaws.com/prod 6.2. Build và deploy frontend\ncd frontend npm run build # Deploy dist/ lên S3/CloudFront Tối ưu hóa 1. Giảm Cold Start Provisioned Concurrency:\naws lambda put-provisioned-concurrency-config \\ --function-name storm-prediction \\ --provisioned-concurrent-executions 1 \\ --qualifier $LATEST 2. Giảm kích thước Image Dùng PyTorch CPU-only:\n# requirements.txt torch==2.1.0+cpu --extra-index-url https://download.pytorch.org/whl/cpu numpy==1.24.3 Multi-stage build:\n# Stage 1: Build FROM python:3.11-slim as builder COPY requirements.txt . RUN pip install --target /packages -r requirements.txt # Stage 2: Runtime FROM public.ecr.aws/lambda/python:3.11 COPY --from=builder /packages ${LAMBDA_RUNTIME_DIR} COPY model.pth ${LAMBDA_TASK_ROOT}/ COPY app.py ${LAMBDA_TASK_ROOT}/ CMD [\u0026#34;app.handler\u0026#34;] 3. Cache Model trong /tmp import os MODEL_PATH = \u0026#34;/tmp/model.pth\u0026#34; if os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;) else \u0026#34;model.pth\u0026#34; def load_model(): global model if model is None: # Copy to /tmp for faster access if not os.path.exists(\u0026#34;/tmp/model.pth\u0026#34;): import shutil shutil.copy(\u0026#34;model.pth\u0026#34;, \u0026#34;/tmp/model.pth\u0026#34;) model = torch.load(\u0026#34;/tmp/model.pth\u0026#34;, map_location=device) model.eval() return model Monitoring CloudWatch Logs # Xem logs aws logs tail /aws/lambda/storm-prediction --follow CloudWatch Metrics Invocations: Số lần gọi Duration: Thời gian chạy Errors: Số lỗi Throttles: Số lần bị throttle Alerts # Tạo alarm cho errors aws cloudwatch put-metric-alarm \\ --alarm-name storm-prediction-errors \\ --alarm-description \u0026#34;Alert when Lambda has errors\u0026#34; \\ --metric-name Errors \\ --namespace AWS/Lambda \\ --statistic Sum \\ --period 300 \\ --threshold 5 \\ --comparison-operator GreaterThanThreshold \\ --dimensions Name=FunctionName,Value=storm-prediction Troubleshooting Lỗi: \u0026ldquo;Task timed out after 3.00 seconds\u0026rdquo; Giải pháp: Tăng timeout lên 60s\nLỗi: \u0026ldquo;Runtime exited with error: signal: killed\u0026rdquo; Giải pháp: Tăng memory lên 3008 MB\nLỗi: \u0026ldquo;No module named \u0026rsquo;torch'\u0026rdquo; Giải pháp: Kiểm tra requirements.txt và rebuild image\nLỗi: Model không load được Giải pháp: Kiểm tra tên file model trong Dockerfile và app.py\nChi phí ước tính Lambda:\nFree tier: 1M requests/month, 400,000 GB-seconds Sau đó: $0.20 per 1M requests + $0.0000166667 per GB-second Ví dụ: 10,000 requests/month, mỗi request 10s, 3GB RAM\nCompute: 10,000 × 10s × 3GB × $0.0000166667 = $5/month Requests: 10,000 × $0.20/1M = $0.002/month Total: ~$5/month API Gateway:\n$3.50 per million requests 10,000 requests = $0.035/month ECR:\n$0.10 per GB/month storage Image ~2GB = $0.20/month Total ước tính: ~$5.25/month cho 10,000 predictions\nChecklist cuối cùng Sửa tên file model trong app.py hoặc Dockerfile Test Docker image locally Push image lên ECR Tạo Lambda function với memory 3008MB, timeout 60s Tạo API Gateway và integrate với Lambda Test API với Postman/curl Cập nhật VITE_PREDICTION_API_URL trong frontend Build và deploy frontend Test form prediction trên web Setup CloudWatch alerts Monitor logs và performance "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.5-event5/","title":"AWS Cloud Mastery Series #2","tags":[],"description":"","content":"Bài thu hoạch “Devops on aws” Mục đích của sự kiện Giới thiệu các nguyên tắc DevOps và tư duy văn hóa đằng sau mô hình phát triển phần mềm hiện đại Trình diễn cách xây dựng pipeline CI/CD tự động trên AWS Hướng dẫn triển khai Infrastructure as Code (IaC) So sánh các dịch vụ container của AWS để triển khai ứng dụng hiện đại Trình bày các thực tiễn tốt nhất về khả năng quan sát và giám sát hệ thống Danh sách diễn giả Bao Huynh – AWS Community Builder Thinh Nguyen – AWS Community Builder Vi Tran – AWS Community Builder Nội dung nổi bật Hiểu về tư duy devops Kết hợp giữa phát triển và vận hành → Tăng tốc độ release Tự động hóa giảm, thao tác thủ công và tăng tính nhất quán Vòng phản hồi liên tục → Hệ thống ổn định và đáng tin cậy hơn Ci/cd pipeline trên aws Pipeline tự động hoàn toàn gồm bốn giai đoạn:\nsource control: CodeCommit quản lý và phiên bản hóa code build \u0026amp; test: CodeBuild biên dịch, kiểm thử và đóng gói ứng dụng deployment: CodeDeploy triển khai rolling, canary và blue/green orchestration: CodePipeline kết nối tất cả các bước thành workflow liên tục Infrastructure as code (iac) Chuyển từ thiết lập thủ công sang môi trường tự động, có kiểm soát version.\naws cloudformation\nTemplate YAML/JSON khai báo Resources, parameters, conditions, outputs Drift detection đảm bảo trạng thái môi trường nhất quán aws cdk (cloud development kit)\nĐịnh nghĩa hạ tầng bằng TypeScript, Python, Java, v.v. L1/L2/L3 constructs cho mẫu reusable CLI synthesize, diff và deploy stack Containers trên aws Tổng quan Docker và lựa chọn compute cho container:\namazon ecr: registry bảo mật, hỗ trợ quét lỗ hổng amazon ecs: điều phối AWS-native, chạy trên EC2 hoặc Fargate amazon eks: Kubernetes được quản lý cho workloads chuẩn aws app runner: triển khai container đơn giản, ít vận hành Observability và monitoring Xây dựng khả năng quan sát hệ thống hiện đại:\namazon cloudwatch Metrics, logs, alarms, dashboards aws x-ray Tracing phân tán để xác định bottleneck và microservice chậm Tập trung vào cảnh báo hành động được, dashboards có ý nghĩa, và theo dõi chủ động.\nNhững Gì Học Được Thực hành devops Tự động hóa → tốc độ + độ tin cậy Đồng bộ văn hóa giữa dev và ops Sử dụng DORA để cải thiện Kết hợp phản hồi ở mọi giai đoạn phát triển Infrastructure as code Giảm cấu hình thủ công trong production CloudFormation cho workflow khai báo AWS-native CDK cho định nghĩa hạ tầng linh hoạt, lập trình được Xem hạ tầng như phần mềm: test, version, automate Triển khai ứng dụng Pipeline CI/CD giảm lỗi con người Chọn chiến lược deploy theo rủi ro (rolling, canary, blue/green) Tích hợp kiểm thử tự động ở mọi bước Chiến lược container Container mang tính di động, nhất quán, kiến trúc modular ECS → mô hình vận hành đơn giản EKS → linh hoạt với Kubernetes App Runner → triển khai ít vận hành ECR là nền tảng quản lý image Tăng cường kỹ năng của bản thân Kết hợp metrics, logs, traces cho cái nhìn 360° Dashboards CloudWatch + maps dịch vụ X-Ray để khắc phục sự cố Xây dựng cảnh báo chủ động, không phản ứng khi sự cố xảy ra Ứng dụng vào công việc Tự động hóa CI/CD với CodePipeline, CodeBuild, CodeDeploy để tối ưu release Áp dụng IaC với CloudFormation hoặc CDK thay thế thiết lập thủ công, đảm bảo nhất quán Container hóa dịch vụ và chọn ECS, EKS hoặc App Runner dựa trên workload Nâng cao khả năng quan sát với CloudWatch metrics, logs, alarms và dashboards tùy chỉnh Kích hoạt distributed tracing bằng AWS X-Ray để khắc phục sự cố microservice Sử dụng DORA để đo hiệu suất và cải thiện DevOps Trải nghiệm trong event Tham gia workshop “Cloud mastery series #2 – devops on aws” mang lại cả hướng chiến lược và kiến thức thực tiễn để triển khai DevOps quy mô lớn.\nHọc hỏi từ các diễn giả có chuyên môn Diễn giả giải thích rõ CI/CD, container, IaC, monitoring Các case study thực tế minh họa DevOps hoạt động trong môi trường production Trải nghiệm kỹ thuật thực tế Quan sát pipeline chạy từ commit → build → deploy Hiểu CloudFormation và CDK giúp enforce hạ tầng lặp lại Làm rõ trade-offs giữa ECS, EKS và App Runner cho orchestration container Ứng dụng công cụ hiện đại IaC giúp nhất quán và giảm drift CloudWatch và X-Ray là nền tảng cho vận hành chuẩn hóa Kết nối và thảo luận Cơ hội kết nối chuyên gia và đồng nghiệp Thảo luận nhấn mạnh văn hóa, tự động hóa và cải tiến đo lường được Bài học rút ra Tự động hóa là nhân tố cải thiện chính Observability cần thiết cho sự ổn định Chọn compute/container phù hợp giảm gánh nặng vận hành Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tổng kết, workshop đã cung cấp kiến thức toàn diện và thực tiễn về DevOps, CI/CD, IaC, orchestration container và monitoring.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.5-week5/","title":"Worklog Tuần 5","tags":[],"description":"","content":"Mục tiêu tuần 5: Tìm hiểu về các mục trong module \u0026ldquo;Migrate to AWS\u0026rdquo; Hiểu các tối ưu chi phí với AWS Lambda Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tiếp tục tìm hiểu cho dự án, vẽ sơ đồ kiến trúc sơ bộ 6/10/2025 6/10/2025 3 - Thực hành VM Import/Export + Thử triển khai máy chủ ứng dụng + Upload và import VM lên AWS 7/10/2025 7/10/2025 https://000014.awsstudygroup.com/ 4 - Thực hành Database Schema Conversion \u0026amp; Migration + Cấu hình DMS và SCT + Thực hiện chuyển đổi schema và di chuyển dữ liệu 8/10/2025 8/10/2025 https://000015.awsstudygroup.com/ 5 - Thực hành AWS Elastic Disaster Recovery Workshop + Cấu hình DRS + Cài đặt agent và kiểm tra quá trình failover 9/10/2025 9/10/2025 https://000016.awsstudygroup.com/ 6 - Thực hành Optimizing EC2 Costs with Lambda + Tạo hàm Lambda start/stop instance + Kết nối Slack để nhận thông báo 10/10/2025 10/10/2025 https://000017.awsstudygroup.com/ Kết quả đạt được tuần 5: A - Tìm hiểu về VM Import/Export\nHiểu quy trình VM Import/Export trên AWS, bao gồm cả hướng di chuyển hai chiều giữa môi trường on-premises và AWS Cloud.\nTriển khai thành công máy ảo Ubuntu trong môi trường VMWare Workstation:\nTạo mới máy ảo, cài hệ điều hành Ubuntu. Cấu hình người dùng, dung lượng đĩa và dịch vụ OpenSSH Server để truy cập từ xa. Thực hiện xuất máy ảo từ on-premises:\nDùng chức năng Export to OVF để tạo file .vmdk phục vụ cho quá trình nhập lên AWS. Tạo và cấu hình S3 bucket để lưu trữ file máy ảo:\nĐặt tên bucket duy nhất, chọn region phù hợp. Cho phép public access và tải file .vmdk lên S3. Tạo IAM Role “vmimport” và gán chính sách cần thiết để dịch vụ VM Import/Export có thể:\nTruy cập S3 bucket chứa file máy ảo. Thực hiện lệnh import-image trên AWS CLI để chuyển đổi máy ảo thành AMI. Triển khai EC2 Instance từ AMI:\nTruy cập EC2 Console, chọn AMI vừa import. Tạo key pair, khởi tạo instance và SSH kết nối kiểm tra. Thực hành quy trình xuất ngược (Export) từ AWS:\nTạo S3 bucket mới và cấu hình ACL cho phép quyền ghi/đọc. Sử dụng AWS CLI để export từ Instance hoặc AMI ra định dạng .vhd / .vmdk. Lưu file vào S3 và triển khai lại máy ảo trên hệ thống on-premise. Nắm vững luồng thao tác hai chiều:\nImport: On-premises → S3 → AMI → EC2 Export: EC2 / AMI → S3 → On-premises Hoàn tất các bước kết nối CLI, xác minh AMI, kiểm tra tiến trình import/export và quản lý tài nguyên trên AWS Cloud.\nB - Xem qua Database Schema Conversion \u0026amp; Migration\nHiểu cách chuẩn bị môi trường AWS cho quá trình di trú cơ sở dữ liệu, bao gồm tạo key pair, cấu hình EC2 instance và thiết lập kết nối.\nNắm được cách lựa chọn và cấu hình các nguồn cơ sở dữ liệu khác nhau như Oracle và SQL Server cho AWS DMS.\nThực hành chuyển đổi schema bằng công cụ AWS Schema Conversion Tool (SCT) và hiểu cách chỉnh sửa mã thủ tục (procedural code) khi cần.\nTìm hiểu cách thiết lập quá trình di trú dữ liệu bằng AWS Database Migration Service (DMS), bao gồm tạo replication instance, endpoint và migration task.\nBiết cách giám sát hoạt động di trú thông qua CloudWatch metrics, task logs và event notifications.\nHiểu cơ chế hoạt động của DMS Serverless và cách nó tự động mở rộng quy mô khi tải tăng.\nThực hành xử lý các sự cố thường gặp trong quá trình di trú như lỗi bộ nhớ hoặc lỗi bảng trong DMS task.\nHoàn thành các bước dọn dẹp môi trường sau khi di trú, bao gồm xóa migration task, replication instance và IAM roles.\nC - AWS Elastic Disaster Recovery Workshop\nHiểu tổng quan về AWS Elastic Disaster Recovery (AWS DRS), bao gồm mục đích, cách hoạt động và lợi ích trong việc giảm thiểu downtime và mất mát dữ liệu.\nNắm được cách chuẩn bị hạ tầng cho môi trường mô phỏng on-premises để thực hành DRS, bao gồm cấu hình các subnet, DNS, và máy chủ Bastion.\nThực hành kết nối đến Bastion Host thông qua RDP hoặc SSH, sử dụng thông tin đăng nhập được cung cấp.\nCấu hình các thiết lập mặc định của DRS trong AWS Management Console, bao gồm lựa chọn subnet, loại instance và nhóm bảo mật.\nTạo và cấu hình IAM User dành cho DRS Agent với quyền truy cập, đồng thời lưu thông tin Access Key phục vụ cho quá trình cài đặt.\nThực hành cài đặt DRS Agent trên các máy chủ nguồn (web và database) thông qua Bastion Host, thiết lập vùng AWS, Access Key, Secret Key và chọn ổ đĩa cần sao chép.\nTheo dõi quá trình đồng bộ dữ liệu (initial sync) và xác minh trạng thái của DRS source servers là “Ready for recovery” và “Healthy”.\nThực hiện quy trình Failover, bao gồm khởi tạo recovery job, chọn dữ liệu gần nhất và kiểm tra quá trình phục hồi trên giao diện DRS cũng như EC2.\nHiểu cách kiểm tra log, theo dõi lịch sử job và xác nhận các instance đã được khởi chạy thành công trong môi trường AWS.\nHoàn thành việc làm quen với quy trình khôi phục hệ thống trong trường hợp thảm họa và đảm bảo tính sẵn sàng của hệ thống.\nD - Optimizing EC2 Costs with Lambda\nHiểu mục tiêu và nguyên lý của việc tối ưu chi phí EC2 bằng AWS Lambda, bao gồm tự động bật/tắt máy chủ và sử dụng Savings Plan cho các trường hợp hoạt động liên tục.\nThực hành tạo hạ tầng ban đầu bao gồm VPC, Security Group và EC2 instance phục vụ cho bài lab.\nCấu hình Slack Incoming Webhooks để nhận thông báo trạng thái hoạt động của instance trực tiếp trên kênh Slack.\nTạo Tag cho instance trong giao diện EC2 (key: environment_auto, value: true) để Lambda có thể nhận diện và thao tác chính xác.\nTạo IAM Role cho Lambda Function, gán quyền AmazonEC2FullAccess và CloudWatchFullAccess, đảm bảo Lambda có thể quản lý EC2 và ghi log theo dõi hoạt động.\nThực hành tạo hai hàm Lambda:\nstop instance – tự động dừng EC2 khi không cần thiết. start instance – tự động khởi động EC2 khi cần hoạt động. Kiểm tra kết quả hoạt động bằng cách chạy thử các hàm Lambda trong giao diện AWS Management Console:\nKhi chạy hàm start instance, EC2 được khởi động và Slack hiển thị thông báo “Starting instance”. Khi chạy hàm stop instance, EC2 chuyển sang trạng thái “Stopped” và Slack hiển thị thông báo “Stopping instance”. Hoàn thành toàn bộ quy trình kiểm thử và xác nhận Lambda hoạt động chính xác, giúp tối ưu chi phí vận hành hệ thống EC2.\nThực hiện bước dọn dẹp tài nguyên sau khi kiểm thử.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"NỀN TẢNG THEO DÕI VÀ DỰ ĐOÁN BÃO Tổng Quan Bão là một trong những thảm họa thiên nhiên nguy hiểm nhất, có thể gây thiệt hại nghiêm trọng đến cơ sở hạ tầng và đe dọa tính mạng con người. Việc phát hiện sớm và đưa ra cảnh báo kịp thời là vô cùng quan trọng để người dân trong khu vực bị ảnh hưởng có đủ thời gian chuẩn bị và sơ tán an toàn.\nĐể đáp ứng nhu cầu này, dự án của chúng tôi hướng đến việc xây dựng một nền tảng trực tuyến cho phép người dùng truy cập miễn phí vào thông tin về những cơn bão mới nhất ở khu vực Tây Thái Bình Dương, sử dụng dữ liệu từ NOAA (Cơ quan Quản lý Khí quyển và Đại dương Quốc gia Hoa Kỳ) — một nguồn dữ liệu đáng tin cậy. Bên cạnh đó, sinh viên, nhà khí tượng hoặc bất kỳ ai quan tâm đến động lực học của bão đều có thể tương tác với hệ thống bằng cách cung cấp quỹ đạo đầu vào của riêng họ và nhận về dự đoán được tạo bởi mô hình học máy của chúng tôi.\nWorkshop này trình bày toàn bộ quy trình xây dựng mô hình dự báo bão, bao gồm nhiều kỹ thuật chuỗi thời gian mới — Stepwise Temporal Fading và Plausible Geodesic-Aware Augmentation — cùng với phần giải thích chi tiết từng bước về cách chúng tôi xây dựng và triển khai nền tảng từ con số 0.\nVới sự hỗ trợ của các dịch vụ AWS như Amazon S3, AWS Lambda, API Gateway và CloudFront, chúng tôi xây dựng một kiến trúc hoàn toàn serverless. Giải pháp này mang lại sự đơn giản, khả năng mở rộng linh hoạt và hiệu quả chi phí dài hạn, đồng thời đảm bảo hiệu suất ổn định và phản hồi nhanh.\nKiến trúc Nền tảng Nền tảng cuối cùng cung cấp hai chức năng cốt lõi:\nXem Thông Tin Bão Người dùng có thể khám phá thông tin mới nhất về các cơn bão ở Tây Thái Bình Dương, bao gồm quỹ đạo lịch sử, tốc độ gió, nhiệt độ và các thông số liên quan khác.\nDự Đoán Quỹ Đạo Bão Người dùng có thể nhập quỹ đạo một phần của cơn bão và nhận về dự đoán quãng đường tiếp theo được tạo bởi mô hình đã huấn luyện.\nNội dung Tổng quan về workshop Chuẩn bị dữ liệu Kiến tạo mô hình ML Kiến trúc Front\u0026amp;Back-end API "},{"uri":"https://giaphazzz.github.io/aws/vi/5-workshop/5.5-platform-api/","title":"Nền tảng API","tags":[],"description":"","content":"MÔ TẢ CHI TIẾT BACK-END API 1. Giới thiệu Weather Backend API là một dịch vụ RESTful cung cấp thông tin thời tiết bằng cách tích hợp với OpenWeatherMap API. Backend hoạt động như lớp trung gian giữa ứng dụng frontend và các nguồn dữ liệu thời tiết bên ngoài.\nHình 1 2. Kiến trúc hệ thống Kiến trúc ┌─────────────────────────────────────────────────────────────┐ │ Ứng dụng Frontend │ │ (React, Mobile, Web Clients) │ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API ▼ ┌─────────────────────────────────────────────────────────────┐ │ Weather Backend API │ │ (.NET 9.0 - ASP.NET Core) │ ├─────────────────────────────────────────────────────────────┤ │ ┌────────────────┐ ┌────────────────┐ ┌────────────────┐ │ │ Bộ điều khiển │ │ Dịch vụ │ │ Program.cs │ │ │ │ │ │ │ - Khởi động app│ │ │ - WeatherCtrl │ │ - WeatherSvc │ │ - Ghi log │ │ │ - ForecastCtrl │ │ - Lớp cache │ │ - Thiết lập DI │ │ └────────────────┘ └────────────────┘ └────────────────┘ └─────────────────────────────────────────────────────────────┘ │ │ HTTPS / REST API (Bên ngoài) ▼ ┌─────────────────────────────────────────────────────────────┐ │ Dịch vụ thời tiết bên ngoài │ ├─────────────────────────────────────────────────────────────┤ │ • OpenWeatherMap API │ │ • Redis Caching Layer │ │ • Giới hạn tốc độ \u0026amp; Giám sát │ └─────────────────────────────────────────────────────────────┘ 3. Tính năng cốt lõi Mô tả: Lấy dữ liệu thời tiết hiện tại của bất kỳ thành phố nào trên thế giới.\nTính năng:\nTìm kiếm theo tên thành phố (ví dụ: \u0026ldquo;Hà Nội\u0026rdquo;, \u0026ldquo;TP Hồ Chí Minh\u0026rdquo;) Tùy chọn mã quốc gia để xác định vị trí chính xác Hỗ trợ nhiều hệ thống đơn vị (metric, imperial, standard) Hỗ trợ đa ngôn ngữ cho phần mô tả thời tiết Phản hồi được lưu cache để tăng hiệu suất Tham số API:\ncityName (bắt buộc): Tên thành phố countryCode (tùy chọn): Mã quốc gia ISO 3166 units (tùy chọn): metric, imperial, standard language (tùy chọn): en, vi, fr, \u0026hellip; Ví dụ phản hồi:\nResponse body Download { \u0026#34;localDate\u0026#34;: \u0026#34;2025-12-06 19:57:02\u0026#34;, \u0026#34;city\u0026#34;: \u0026#34;Hà Nội\u0026#34;, \u0026#34;coord\u0026#34;: { \u0026#34;lon\u0026#34;: 105.8412, \u0026#34;lat\u0026#34;: 21.0245 }, \u0026#34;weather\u0026#34;: [ { \u0026#34;id\u0026#34;: 804, \u0026#34;main\u0026#34;: \u0026#34;Clouds\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;mây đen u ám\u0026#34;, \u0026#34;icon\u0026#34;: \u0026#34;04n\u0026#34; } ], \u0026#34;main\u0026#34;: { \u0026#34;temp\u0026#34;: 22, \u0026#34;feels_like\u0026#34;: 22.11, \u0026#34;temp_min\u0026#34;: 22, \u0026#34;temp_max\u0026#34;: 22, \u0026#34;pressure\u0026#34;: 1018, \u0026#34;humidity\u0026#34;: 71, \u0026#34;sea_level\u0026#34;: 1018, \u0026#34;grnd_level\u0026#34;: 1017 }, \u0026#34;wind\u0026#34;: { \u0026#34;speed\u0026#34;: 4.14, \u0026#34;deg\u0026#34;: 136, \u0026#34;gust\u0026#34;: 6.84 }, \u0026#34;sys\u0026#34;: { \u0026#34;type\u0026#34;: 1, \u0026#34;id\u0026#34;: 9308, \u0026#34;country\u0026#34;: \u0026#34;VN\u0026#34;, \u0026#34;sunrise\u0026#34;: 1764976827, \u0026#34;sunset\u0026#34;: 1765016103 } } Hình 2 4. Công nghệ sử dụng Backend Framework .NET 9.0 – Runtime .NET mới nhất ASP.NET Core – Framework xây dựng Web API C# 12 – Ngôn ngữ lập trình chính Tích hợp API HttpClientFactory – Quản lý sử dụng HTTP client Polly – Chính sách thử lại \u0026amp; xử lý lỗi tạm thời Newtonsoft.Json / System.Text.Json – Tuần tự hóa JSON Cache \u0026amp; Hiệu năng MemoryCache – Cache trong bộ nhớ Redis (tùy chọn) – Cache phân tán ResponseCompression – Nén Gzip / Brotli Công cụ phát triển Visual Studio 2022 / VS Code - IDE / Trình soạn thảo mã Swagger / OpenAPI – Tài liệu API Git – Kiểm soát phiên bản Docker – Container hóa 5. Cấu trúc dự án WeatherBackend/ │ ├── WeatherBackend.csproj # Tập tin dự án ├── Program.cs # Điểm vào ứng dụng ├── WeatherBackend.http # Tập tin kiểm tra yêu cầu HTTP │ ├── appsettings.json # Cài đặt cấu hình │ ├── Controllers/ # Bộ điều khiển API │ └── WeatherController.cs # Điểm cuối thời tiết chính │ ├── Services/ # Dịch vụ logic nghiệp vụ │ └── WeatherService/ # Hợp đồng \u0026amp; triển khai dịch vụ 6. API Endpoints Base URL https://localhost:7042/swagger/index.html 6.1 GET /api/weather/current Mô tả:\nLấy dữ liệu thời tiết hiện tại theo tên thành phố.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather?city=hanoi\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather?city=hanoi 6.2 GET /api/weather/forecast Mô tả: Lấy dự báo thời tiết 5 ngày cho một thành phố được chọn.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/forecast?city=hochiminh\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/forecast?city=hochiminh 6.3 GET /api/weather/coordinates Mô tả: Lấy thông tin thời tiết bằng vĩ độ và kinh độ.\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/by-coord?lat=21.0245\u0026amp;lon=105.8412 6.4 GET /api/weather/location Mô tả: Lấy thông tin thời tiết theo vị trí của người dùng (yêu cầu thiết bị người dùng gửi tọa độ).\nVí dụ CURL:\ncurl -X GET \\ \u0026#34;https://localhost:7042/api/Weather/global\u0026#34; \\ -H \u0026#34;accept: */*\u0026#34; URL yêu cầu:\nhttps://localhost:7042/api/Weather/global Hình 3 Cập nhập lần cuối: 2025-12-09\nPhiên bản: 1.0.0\nBảo trì bởi: SKYNET\n"},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.6-event6/","title":"AWS Edge Services Wokrshop","tags":[],"description":"","content":"Bài Thu Hoạch “AWS Edge Services Workshop - Amazon CloudFront As Your Foundation” Mục Đích Của Sự Kiện Hiểu cách Amazon CloudFront nâng cao bảo mật, hiệu suất và tối ưu chi phí Học các best practices về edge caching, phân phối nội dung và bảo vệ origin Khám phá khả năng của CloudFront cho nội dung tĩnh, động và quy mô lớn Nhận kiến thức thực tiễn về triển khai edge logic và chiến lược failover Danh Sách Diễn Giả Nguyễn Gia Hưng – Head of Solutions Architect, Edge Technical Field Community, Amazon Web Services Việt Nam Nội Dung Nổi Bật Gói giá ưu đãi mới Chi Phí CDN Khó Lường: Thanh toán dựa trên usage có thể dẫn đến hóa đơn cao khi traffic tăng hoặc bị tấn công Giải Pháp: Gói AWS Fixed-Price CDN + Security, giúp chi phí hàng tháng dự đoán được và giảm rủi ro tài chính Gói gồm: CloudFront, WAF, Shield AMR, Route 53, CloudWatch Logging, S3 storage credits Giá cố định hàng tháng bất kể usage Khả Năng Của CloudFront Bảo Mật Và Bảo Vệ\nHỗ Trợ HTTPS/TLS:\nGiảm kích thước key để tăng hiệu suất và giảm độ trễ Sử dụng TLS library (s2n) để xác thực đích đến Hỗ trợ TLS 1.3, chứng chỉ ECDSA, và tùy chọn sẵn sàng cho post-quantum Mutual TLS (2-way): Hỗ trợ xác thực client certificate, sắp triển khai trên CloudFront\nOrigin Cloaking:\nVPC Origin: ẩn origin khỏi internet, sử dụng ALB private Origin Access Control (OAC): signed requests cho S3, Lambda, MediaPackage, không cần API Gateway Custom Origins: giới hạn IP CloudFront, thêm header tùy chỉnh với secret định sẵn Access Control: Giới hạn theo địa lý, Signed URLs theo thời gian, đường dẫn URL và xác thực IP client\nTối Ưu Chi Phí\nTự động nén object (đến 10 GB, bỏ qua file đã nén) - cần bật chế độ nén AWS miễn phí transfer từ origin đến CloudFront Giảm tải origin: giảm chi phí CPU và load balancer Độ Tin Cậy Và Khả Năng Phục Hồi\nCaching với TTL và stale content delivery Built-in failover tới origin phụ còn khỏe Graceful failure: phục vụ nội dung cache hoặc trang lỗi tùy chỉnh Tăng Cường Hiệu Suất\nMulti-layer caching: Regional Edge Caches + Origin Shield Request collapsing để giảm duplicate requests Persistent connections đến origin để tránh TCP handshakes thừa Edge logic thực thi với CloudFront Functions hoặc Lambda@Edge Các Trường Hợp Sử Dụng Trường Hợp Sử Dụng:\nTài nguyên web tĩnh Phân phối toàn bộ website (hiệu suất toàn cầu, bảo mật, high availability) Tăng tốc API (reuse connection, giảm độ trễ) Streaming media và tải file lớn (resumable, edge caching) Best Practices:\nQuan sát toàn bộ: monitor trải nghiệm người dùng và đường đi request Caching tối đa: chuẩn hóa cache keys, chọn TTL phù hợp, cache lỗi để chống brute-force Chặn request không mong muốn: detect malicious pattern, implement rate limiting Offload business logic: di chuyển processing nhẹ lên edge, ví dụ CloudFront Functions Failover tự động: cấu hình Route 53 health check hoặc CloudFront origin group Những Gì Học Được CloudFront là nền tảng toàn diện cho bảo mật, hiệu suất và tối ưu chi phí tại edge Edge caching và logic giúp giảm tải origin và cải thiện tốc độ phản hồi Các tính năng bảo mật (TLS, mutual TLS, origin cloaking, signed URLs) bảo vệ nội dung ở edge Thực hành best practices đảm bảo high availability, caching tối ưu, và resilience Ứng Dụng Vào Công Việc Bật nén và multi-layer caching cho nội dung tĩnh và động Triển khai Signed URLs và OAC cho nội dung nhạy cảm Di chuyển business logic nhẹ lên CloudFront Functions để tăng tốc phản hồi Monitor metrics và logs tại edge để duy trì visibility và phát hiện traffic không mong muốn Cấu hình failover để đảm bảo high availability Trải Nghiệm Trong Sự Kiện Tham gia AWS Edge Services Workshop rất bổ ích, cung cấp cái nhìn sâu về bảo mật, hiệu suất và khả năng vận hành của CloudFront. Các trải nghiệm chính bao gồm:\nHọc Hỏi Từ Diễn Giả Chuyên Gia Hung Nguyen Gia chia sẻ kinh nghiệm thực tế và ví dụ thực tiễn về tối ưu edge Hiểu rõ tất cả tính năng của CloudFront để phân phối nội dung toàn cầu Trải Nghiệm Kỹ Thuật Thực Tế Học cách cấu hình origin cloaking và origin access control Khám phá chiến lược compression, caching, và persistent connections Hiểu cách edge logic giảm độ trễ và cải thiện scalability Ứng Dụng Best Practices Quan sát toàn bộ và chiến lược xử lý lỗi Cấu hình caching nâng cao để đạt hiệu quả tối đa Kỹ thuật chặn request độc hại và offload processing lên edge Một Số Hình Ảnh Khi Tham Gia Sự Kiện Hình 1 Hình 2 Hình 3 Tổng thể, workshop nhấn mạnh tầm quan trọng của bảo mật, hiệu suất và độ tin cậy tại edge, đồng thời cung cấp các chiến lược thực tế để triển khai CloudFront trong môi trường doanh nghiệp.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.6-week6/","title":"Worklog Tuần 6","tags":[],"description":"","content":"Mục tiêu tuần 6: Học hỏi thêm kiến thức về Grafam Tags và quản lý AWS system manager Thực hành với các bài lab của FJC Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tiến hành trainning model cho vấn đề dự đoán tọa độ tiếp theo, đánh giá, nhận xét các tích hợp mới vào mô hình 13/10/2025 13/102025 3 - Làm quen với Grafana và giám sát tài nguyên AWS bằng dashboard trực quan + Tìm hiểu khái niệm, chức năng và ứng dụng của Grafana trong giám sát hệ thống + Cài đặt và cấu hình Grafana trên EC2 instance + Kết nối Grafana với CloudWatch và tạo dashboard giám sát tài nguyên EC2 14/10/2025 14/10/2025 https://000029.awsstudygroup.com/ 4 - Tìm hiểu về Tags và Resource Groups trong AWS + Hiểu cơ chế key–value pair và vai trò của tagging trong tổ chức tài nguyên + Thực hành tạo, xóa, lọc tài nguyên theo tag qua AWS Console và CLI + Tạo Resource Group kiểu Tag-based với tiêu chí Key=BusinessUnit, Value=Marketing 15/10/2025 15/10/2025 https://000027.awsstudygroup.com/ 5 - Quản lý truy cập EC2 thông qua IAM và Resource Tags + Áp dụng nguyên tắc Least Privilege và tạo các IAM Policy điều kiện theo Region và Tag + Tạo nhóm quản trị (Admin Group), người dùng (Admin User) và role ec2-admin-team-alpha 16/10/2025 16/10/2025 https://000028.awsstudygroup.com/ 6 - Quản lý và tự động hóa nhiều máy chủ bằng AWS Systems Manager 17/10/2025 17/10/2025 https://000031.awsstudygroup.com/ Kết quả đạt được tuần 6: A - Làm quen với Grafana và giám sát tài nguyên AWS bằng dashboard trực quan\nTìm hiểu về công cụ Grafana:\nHiểu khái niệm, chức năng và ứng dụng của Grafana trong việc trực quan hóa dữ liệu và giám sát hệ thống. Nắm được các tính năng chính như visualize, dashboard động, alerting và tích hợp nhiều nguồn dữ liệu. Chuẩn bị môi trường AWS:\nTạo VPC, Subnet, Security Group, IAM User và IAM Role phục vụ cho việc cài đặt Grafana. Khởi tạo EC2 instance để cài đặt Grafana Server. Thực hành cài đặt Grafana trên EC2:\nKết nối đến instance qua PuTTY, thực hiện cập nhật hệ thống và thêm YUM repository. Cài đặt Grafana bằng lệnh sudo yum install grafana và khởi động dịch vụ bằng systemctl start grafana-server. Kiểm tra trạng thái hoạt động và thiết lập tự khởi động cùng hệ thống. Đăng nhập và cấu hình ban đầu Grafana:\nTruy cập giao diện qua địa chỉ :3000, đăng nhập bằng tài khoản mặc định admin/admin. Đặt lại mật khẩu mới và kiểm tra giao diện dashboard cơ bản. Kết nối Grafana với CloudWatch:\nCấu hình data source CloudWatch bằng Access Key và Secret Key của IAM User. Kiểm tra kết nối thành công và thực hiện truy vấn dữ liệu. Tạo dashboard giám sát tài nguyên:\nThêm panel hiển thị chỉ số CPUUtilization của EC2 instance. Lưu dashboard với tên Grafana-Monitoring và thực hiện chia sẻ qua liên kết. Thử nghiệm tính năng Explore để truy vấn và trực quan hóa dữ liệu theo thời gian thực. B - Tìm hiểu về Tags và Resource Groups trong AWS.\nHiểu khái niệm key–value pair của tag và vai trò của việc gắn thẻ trong quản lý tài nguyên, chi phí, phân quyền và tự động hóa.\nThực hành thao tác với Tag thông qua giao diện AWS Management Console:\nTạo EC2 instance kèm tag khi khởi tạo. Thêm, xóa và lọc tài nguyên theo tag. Làm quen với cách sử dụng AWS CLI để quản lý tag:\nGán tag cho tài nguyên EC2 sẵn có bằng lệnh create-tags. Tạo mới EC2 instance và EBS volume có sẵn tag qua run-instances và create-volume. Dùng describe-instances để xem thông tin tài nguyên đã được gắn thẻ. Tạo và quản lý Resource Group dựa trên tag:\nXây dựng nhóm tài nguyên kiểu Tag-based với tiêu chí Key=BusinessUnit, Value=Marketing. Kiểm tra danh sách tài nguyên trong group vừa tạo trên giao diện Resource Groups Console. Nắm được cách tổ chức, nhóm và truy xuất tài nguyên AWS hiệu quả bằng việc sử dụng tag và resource group.\nC - Tìm hiểu về cơ chế quản lý truy cập tài nguyên EC2 thông qua IAM và Resource Tags.\nHiểu rõ nguyên tắc Least Privilege trong IAM và cách áp dụng điều kiện trong IAM Policy để giới hạn quyền truy cập theo vùng và thẻ tài nguyên.\nThực hành tạo nhóm quản trị (Admin Group) và người dùng quản trị (Admin User) trong IAM Console.\nTạo các IAM Policy chuyên biệt cho quản lý EC2, bao gồm:\nec2-list-read: chỉ cho phép quyền đọc EC2 trong hai vùng us-east-1 và us-west-1 ec2-create-tags: cho phép gán thẻ khi tạo EC2 instance ec2-create-tags-existing: cho phép gán thẻ nếu thẻ có giá trị Key=Team, Value=Alpha ec2-run-instances: cho phép tạo EC2 instance khi đáp ứng điều kiện vùng và thẻ ec2-manage-instances: cho phép thao tác khởi động, dừng, xóa EC2 khi điều kiện thẻ và vùng được đáp ứng Tạo và gán IAM Role ec2-admin-team-alpha với các policy vừa tạo, đồng thời cấu hình Trust relationship để cho phép Assume Role.\nThực hành cơ chế Switch Role và xác minh quyền truy cập của người dùng theo từng chính sách IAM đã cấu hình.\nHiểu được cách kết hợp IAM và Resource Tags để kiểm soát truy cập theo nguyên tắc linh hoạt, bảo mật và có thể mở rộng cho mô hình quản trị phân tán.\nD - Tìm hiểu và thực hành quản lý nhiều máy chủ cùng lúc thông qua AWS Systems Manager.\nHiểu rõ chức năng của Systems Manager trong việc tập trung dữ liệu vận hành, tự động hóa quy trình và quản lý đồng bộ tài nguyên trên AWS.\nThực hành triển khai môi trường gồm 2 máy ảo Windows EC2:\nTạo VPC, subnet và cấu hình IAM Role cho phép Systems Manager truy cập và quản lý instance. Gán IAM Role vào từng instance để kết nối được với Systems Manager. Kiểm tra trạng thái Managed Nodes trong Fleet Manager, xác nhận 2 node (Windows-Lab-SSM-1 và Windows-Lab-SSM-2) hoạt động và có thể khởi tạo phiên terminal session thành công.\nSử dụng Patch Manager để quét và cài đặt bản vá cho hai Windows EC2 Instances:\nChọn chế độ “Scan and Install” để kiểm tra và cài đặt bản cập nhật. Cấu hình không khởi động lại instance sau khi vá. Theo dõi và xác minh kết quả cập nhật thành công. Thực hành Run Command trên nhiều máy chủ cùng lúc bằng AWS Systems Manager:\nChạy lệnh “AWS-RunPowerShellScript” để thực thi câu lệnh PowerShell từ xa. Chọn mục tiêu là 2 Windows EC2 Instances. Bật tùy chọn lưu kết quả đầu ra về S3 Bucket để kiểm tra log và lỗi. Hoàn tất quá trình kiểm tra đầu ra của từng instance, xác nhận lệnh được thực thi thành công và hệ thống phản hồi đúng với cấu hình.\nNắm vững quy trình quản lý tập trung và tự động hóa trên nhiều máy chủ, giúp tối ưu hóa bảo trì hệ thống, kiểm soát truy cập và giảm thiểu thao tác thủ công trong môi trường vận hành AWS.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Hành trình thực tập của em tại CÔNG TY TNHH AMAZON WEB SERVICES VIỆT NAM từ ngày 08/09/2025 đến ngày 24/12/2025 là một trải nghiệm quý giá. Với cơ hội được làm quen nhiều bạn bè đồng trang lứa, thực hành và sử dụng các dịch vụ tiện lợi của AWS cũng như mở rộng thêm kiến thức về điện toán đám mây, em đã vô cùng thích thú với những điều này. Đây không chỉ là kiến thức đơn thuần mà còn được thực hành thực tế trong môi trường làm việc chuyên nghiệp.\nĐặc biệt, em được tham gia vào dự án Online Platform for Hurricane Tracjectory của nhóm SKYNET. Dự án được ra đời với mục đích cung cấp nền tảng online cho người dùng Internet có thể truy cập và theo dõi các thông tin mới nhất về bão trong khu vực Tây Thái Bình Dương (West Pacific). Không những thế, nó còn có tính năng độc nhất cho họ được trải nghiệm mô hình dự đoán đường đi của bão chỉ với việc nhập vào một vài dữ liệu về điểm di chuyển của bão trong quá khứ. Chưa hết, dự án còn cho ra đời thuật toán Stepwise Temporal Fading Augmentation và Geodesic Beering … , cung cấp thêm lựa chọn đa dạng hóa dữ liệu cho quá trình huấn luyện mô hình với dữ liệu time-series. Tiêu biểu nhất là nó giải quyết được tính chất thiên vị (bias), quan trọng hóa giá trị theo chiều thời gian cho những ghi chép gần nhất nhằm tạo nên tính thực tế và chính xác cho các dự đoán. Điều mà tới hiện nay vẫn chưa thấy có nghiên cứu nào đề xuất cho kỹ thuật Augmentation và Time-series data.\nQua đó, em đã cải thiện được nhiều kỹ năng cho bản thân như:\nPhân tích và giải quyết bài toán Thu thập, xử lý thông tin từ các nguồn tin cậy Nghiên cứu, thử nghiệm tìm ra phương pháp mới kết hợp các kiến thức hiện có Tổ chức huấn luyện, áp dụng kĩ thuật mới cho mô hình Machine Learning Tích hợp các dịch vụ cloud services của AWS trong quá trình làm việc và triển khai online platformt thành sản phẩm hoạt động được. Nâng cao kỹ năng mềm Trở nên tự tin hơn để trình bày các để xuất và cải thiện việc giao tiếp, làm việc nhóm với nhiều người. Em đã luôn cố gắng hoàn thành task được giao và cảm thấy rất thích thú, hài lòng khi được làm việc với các kiến thức mới. Đặc biệt là khi lần đầu tiếp xúc và làm quen với các dịch vụ của AWS.\nĐể trình bày rõ hơn về cảm nhận của bản thân về quá trình thực tập, em xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây :\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ☐ ✅ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ✅ ☐ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ✅ ☐ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ✅ ☐ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ☐ ✅ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ☐ ✅ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ✅ ☐ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Cần cải thiện Khả năng học để có thể hiểu sâu và rõ cách ứng dụng dịch vụ AWS cũng như các best practice hơn Tư duy giải quyết vấn đề nhằm giúp cho quá trình từ lập kế hoạch đến hoàn thiện sản phẩm được suôn sẽ, dễ dàng hơn "},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.7-event7/","title":"AWS Cloud Mastery Series #3","tags":[],"description":"","content":"Summary Report: “Security - AWS Well-Architected Security Pillar” Mục Đích Của Sự Kiện Giới thiệu các nguyên tắc cốt lõi của AWS Well-Architected Security Pillar Tăng cường kiến thức nền tảng về indetity, giám sát và phản ứng khi gặp sự cố Thúc đẩy sự phát triển cộng đồng thông qua học tập, hợp tác và tạo nội dung Danh Sách Diễn Giả Lê Vũ Xuân An - FCJ Member Trần Đức Anh - FCJ Member Trần Đoàn Công Lý - FCJ Member Danh Hoàng Hiếu Nghi - FCJ Member Nội Dung Nổi Bật Tổng quan về AWS Cloud Club — Security Track Lộ trình badging có cấu trúc giúp ghi nhận tiến bộ và đóng góp của thành viên Core team là nền tảng của câu lạc bộ, hỗ trợ thành viên mới và dẫn dắt các sáng kiến Thành viên nhận badge khi tham gia workshop và có thể đổi lấy phần thưởng Thành viên đóng góp bằng cách tạo nội dung kỹ thuật và bài đăng mạng xã hội Điểm nhấn lớn trong năm là sự kiện Student Community Day Lợi ích cho thành viên bao gồm: *Nâng cao kỹ năng *Xây dựng cộng đồng *Nhận thêm cơ hội việc làm IAM (Identity \u0026amp; Access Management) Quản lý danh tính là nền tảng của mọi chiến lược bảo mật trên AWS Gán quyền dựa trên least privilege, chỉ cấp đúng những gì user/service cần Loại bỏ access key dài hạn; ưu tiên sử dụng IAM roles Bật MFA cho tất cả người dùng để tăng cường xác thực Sử dụng AWS Single Sign-On (IAM Identity Center) để quản lý truy cập đồng nhất Không phụ thuộc vào credit miễn phí để thử nghiệm; nên dùng AWS Organizations để quản lý tài khoản đúng cách Service Control Policies (SCPs) thiết lập guardrail cho nhiều tài khoản (tính năng cấp doanh nghiệp) Dùng Permission Boundaries để ngăn mở rộng quyền ngoài ý muốn Hạn chế tạo IAM user với thông tin đăng nhập dài hạn Hỗ trợ phương thức xác thực mạnh: TOTP và khóa cứng FIDO2 IAM Access Analyzer giúp phát hiện truy cập công khai hoặc cross-account không mong muốn Detection \u0026amp; Continuous Monitoring Triển khai quan sát đa lớp để hiểu điều gì đang xảy ra trong môi trường Dùng Amazon EventBridge để tự động gửi cảnh báo khi có hoạt động bất thường Áp dụng Detection-as-Code: quản lý rule và automation dưới dạng code để đảm bảo tính nhất quán Đảm bảo log từ CloudTrail, CloudWatch và VPC Flow Logs được tập trung để phân tích Amazon GuardDuty Giải quyết các mối quan tâm quan trọng của doanh nghiệp:\nKhông biết hệ thống có đang bị tấn công hay không Thời gian phản hồi chậm Rủi ro về tuân thủ Chi phí bất thường do hành vi độc hại GuardDuty sử dụng machine learning và threat intelligence để phát hiện hành vi đáng ngờ\nTích hợp hoàn chỉnh với EventBridge để tự động hóa quy trình\nTính năng nâng cao gồm S3 Protection, RDS Protection, và sơ đồ chuỗi tấn công\nCung cấp phát hiện thời gian thực, gợi ý khắc phục và định tuyến sự kiện đa tài khoản\nAWS Security Hub Quản lý nhiều dịch vụ AWS khiến việc theo dõi cảnh báo trở nên khó khăn Security Hub gom các alert từ mọi dịch vụ về một định dạng thống nhất Giúp duy trì tuân thủ theo tiêu chuẩn AWS và CIS Cung cấp hướng dẫn khắc phục từng bước Hỗ trợ quản lý nhiều tài khoản và nhiều vùng (region) Network Layer Security Chiến lược phòng thủ nhiều lớp bắt đầu từ thiết kế VPC an toàn Sử dụng Security Groups và Network ACLs để giới hạn lưu lượng mạng Giám sát hành vi mạng bằng VPC Flow Logs Thiết kế mạng tách biệt, tối thiểu quyền và tránh phơi bày ra public nếu không cần thiết Tích hợp AWS Network Firewall hoặc PrivateLink khi cần Incident Response Chuẩn bị các playbook phản ứng sự cố cho cô lập, điều tra, xử lý và phục hồi Tự động hóa bước phản ứng quan trọng bằng EventBridge, Lambda và Security Hub Thực hành tabletop để kiểm tra mức độ sẵn sàng Ghi lại quy trình escalations, thông tin liên lạc và đánh giá sau sự cố Những Gì Học Được Tư duy bảo mật Bảo mật là quá trình liên tục — danh tính, giám sát và phản ứng sự cố phải phát triển theo hệ thống Least privilege và xác thực mạnh là cốt lõi của bảo mật IAM Quản trị đa tài khoản và đa vùng đảm bảo sự nhất quán Thực hành kỹ thuật Dùng GuardDuty và Security Hub để có khả năng quan sát end-to-end Tự động cảnh báo và workflow bằng EventBridge Áp dụng Detection-as-Code để theo phiên bản và tái sử dụng Thiết kế bảo mật nhiều lớp và giới hạn truy cập không cần thiết Phát triển \u0026amp; Cộng đồng Thành viên phát triển cả kỹ năng kỹ thuật lẫn kỹ năng lãnh đạo Câu lạc bộ khuyến khích hợp tác, chia sẻ và tạo nội dung Hệ thống badge thúc đẩy động lực và giúp thể hiện chuyên môn cloud Trải nghiệm trong event Tham dự workshop Master 3 — Security mang lại cái nhìn toàn diện về thực hành bảo mật hiện đại trên AWS. Những trải nghiệm nổi bật:\nHọc từ chuyên gia Core team chia sẻ kinh nghiệm thực tế về IAM, công cụ giám sát và quản trị cloud Các ví dụ tình huống giúp củng cố best practice về IAM và bảo mật tổ chức Hiểu sâu qua trải nghiệm trực quan Thảo luận về permission boundaries, SCP và IAM roles giúp giải quyết khó khăn thường gặp Demo GuardDuty và Security Hub giúp hình dung rõ cách AWS phát hiện và phản hồi đe dọa Tự động hóa và khả năng quan sát Ví dụ EventBridge minh họa cách cảnh báo và workflow được tự động hóa Quan sát quá trình detection → remediation giúp nhấn mạnh tầm quan trọng của visibility trong kiến trúc bảo mật Bài học kinh nghiệm Identity là tuyến phòng thủ đầu tiên Giám sát liên tục (Continuous Monitorign) là điều thiết yếu Tự động hóa giảm rủi ro và thời gian phản hồi Quản trị trên nhiều tài khoản và vùng là cần thiết trong môi trường thực tế Một số hình ảnh khi tham gia sự kiện Hình 1 Hình 2 Hình 3 Tổng thể, sự kiện giúp tôi củng cố kiến thức về bảo mật cloud và nâng cao sự đánh giá đối với các best practice của AWS. Đồng thời, sự kiện cũng nhấn mạnh giá trị của cộng đồng học tập và hợp tác.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.7-week7/","title":"Worklog Tuần 7","tags":[],"description":"","content":"Mục tiêu tuần 7: Tiếp tục tìm hiểu về các dịch vụ của AWS Hiểu thêm các kiến thức về AWS Cloudformation và CDK Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đánh giá mô hình đã đạt được yêu cầu cho bussiness problem hay chưa. - Re-train lại model để nâng cao độ chính xác và đảm bảo các yêu cầu khác 20/10/2025 20/10/2025 3 - Làm quen với Amazon Systems Manager và cơ chế quản lý tập trung tài nguyên AWS. - Hiểu chức năng của Session Manager trong việc truy cập EC2 an toàn mà không cần SSH. - Thực hành tạo VPC, subnet, EC2, IAM Role và kết nối thành công qua Session Manager. 21/10/2025 21/10/2025 https://000014.awsstudygroup.com/ 4 - Tìm hiểu AWS CloudFormation và cơ chế triển khai hạ tầng dưới dạng code. - Hiểu cấu trúc CloudFormation Template và các Intrinsic Functions. - Thực hành tạo Stack, cấp quyền cho Cloud9 Role và phát hiện Drift. 22/10/2025 22/10/2025 https://000052.awsstudygroup.com/ 5 - Hiểu khái niệm AWS CDK và mối liên hệ với CloudFormation. - Cài đặt môi trường CDK và khởi tạo project qua Cloud9. - Thực hành tạo VPC, subnet, IAM Role, Security Group và triển khai EC2 qua CDK. 23/10/2025 23/10/2025 https://000037.awsstudygroup.com/ 6 - Mở rộng triển khai hạ tầng CDK với API Gateway, ECS, ELB và Lambda. - Thực hành tạo ECS Cluster, triển khai Nginx trên Fargate kèm Load Balancer. - Kết nối API Gateway và Lambda với S3 để phản hồi dữ liệu động. 24/10/2025 24/10/2025 https://000076.awsstudygroup.com/ Kết quả đạt được tuần 7: A - Work with Amazon System Manager - Session Manager\nLàm quen và thực hành với Amazon Systems Manager, nắm rõ cơ chế hoạt động và quản lý tập trung tài nguyên AWS.\nHiểu rõ chức năng của Session Manager trong việc truy cập và quản lý EC2 Instances an toàn mà không cần mở cổng SSH (port 22) hay sử dụng Bastion Host.\nThực hành tạo và cấu hình đầy đủ môi trường bao gồm:\nVPC, Public Subnet, Private Subnet, Security Group EC2 Instances (Linux \u0026amp; Windows) IAM Role cho phép EC2 tương tác với Systems Manager Kết nối thành công tới Public Instance qua Session Manager, xác nhận không phát sinh lưu lượng SSH mà chỉ dùng HTTPS, đảm bảo an toàn kết nối.\nCấu hình VPC Interface Endpoints (ssm, ssmmessages, ec2messages) để kết nối tới Private Instance mà không cần internet, tăng cường bảo mật mạng nội bộ.\nTriển khai và kiểm thử Session Logs:\nTạo S3 Bucket lưu trữ nhật ký phiên làm việc và lệnh thực thi. Tạo S3 Gateway Endpoint để truyền dữ liệu nội bộ. Kiểm tra, xác minh log lưu trữ thành công. Thực hành Port Forwarding qua AWS CLI:\nCấu hình chuyển tiếp cổng RDP từ máy cá nhân tới Windows Instance trong Private Subnet. Đăng nhập thành công bằng Remote Desktop thông qua cổng nội bộ. B - AWS CloudFormation\nHiểu rõ về AWS CloudFormation – dịch vụ cho phép mô tả và triển khai hạ tầng AWS bằng mã (Infrastructure as Code), giúp tự động hoá việc tạo và quản lý tài nguyên một cách an toàn và lặp lại được.\nBiết cách sử dụng CloudFormation Template để mô hình hoá hạ tầng thông qua các thành phần chính:\nAWSTemplateFormatVersion Description Parameters Resources Outputs Thực hành tạo và chỉnh sửa CloudFormation Template trên môi trường AWS Cloud9, một IDE dựa trên web hỗ trợ nhiều ngôn ngữ lập trình (Python, JavaScript, PHP,…).\nCài đặt và cấu hình các công cụ cần thiết trong Cloud9 Workspace bao gồm:\njq, gettext, bash-completion, moreutils cfn-lint (kiểm tra cú pháp CloudFormation) taskcat (kiểm thử template tự động) Hiểu và áp dụng được các Intrinsic Functions trong CloudFormation:\n!Ref – tham chiếu giá trị của tham số hoặc tài nguyên !Sub – chèn biến động vào chuỗi ký tự !GetAtt – lấy thuộc tính từ một tài nguyên đã tạo Tạo thành công các tài nguyên cơ bản bằng CloudFormation Template:\nSecurity Group mở port 80 cho HTTP IAM Role \u0026amp; Instance Profile cho phép EC2 giao tiếp với SSM và CloudWatch EC2 Instance tự động gán IAM Role và Network Interface Thực hành tạo CloudFormation Stack trực tiếp từ Cloud9 thông qua AWS CLI, đồng thời cấp quyền cần thiết cho Cloud9 Role (AmazonEC2FullAccess, IAMFullAccess) để thực thi lệnh tạo Stack.\nNắm được khái niệm Drift Detection – phát hiện sự khác biệt giữa trạng thái hạ tầng thực tế và cấu hình trong CloudFormation Template.\nLàm quen với các nội dung nâng cao: Custom Resources, Mapping, StackSet và Macro – giúp tự động hoá, mở rộng khả năng triển khai và quản lý hạ tầng phức tạp.\nC - CDK basic\nHiểu được khái niệm AWS CloudFormation và cách triển khai kiến trúc hạ tầng dưới dạng code (Infrastructure as Code).\nBiết được mối quan hệ giữa CloudFormation và AWS CDK, trong đó CDK là lớp trừu tượng giúp lập trình hạ tầng AWS bằng ngôn ngữ lập trình phổ biến như Python, TypeScript, JavaScript, Java, C#.\nCài đặt và khởi tạo môi trường làm việc với AWS CDK thông qua Cloud9 IDE.\nThực hành khởi tạo project CDK\nHiểu được cách thức CDK hoạt động thông qua quy trình:\nViết code hạ tầng bằng Python CDK chuyển đổi code sang CloudFormation Template (bằng cdk synth) Triển khai tài nguyên thực tế lên AWS qua cdk deploy Thực hành khởi tạo VPC và subnet công khai bằng CDK.\nTạo và gán IAM Role cho EC2 Instance, cấu hình Security Group.\nThực hành triển khai EC2 Instance trên VPC đã tạo bằng AWS CDK.\nThực hành triển khai hạ tầng qua cdk deploy và xác nhận kết quả triển khai trên AWS Management Console.\nTruy cập vào EC2 instance vừa tạo, kiểm tra hoạt động của Apache Web Server thông qua Public IP.\nHiểu được quy trình khép kín của CDK: định nghĩa – tổng hợp – kiểm tra – triển khai – xác thực.\nD - CDK Basic - 2\nHiểu được cách mở rộng việc triển khai hạ tầng AWS bằng CDK thông qua tích hợp nhiều dịch vụ như API Gateway, ECS, Elastic Load Balancer và Lambda.\nThực hành tạo ECS Cluster và triển khai ứng dụng mẫu Nginx trên Fargate kèm theo Application Load Balancer.\nCấu hình API Gateway để định tuyến yêu cầu đến dịch vụ ECS thông qua Load Balancer.\nTạo và cấu hình Lambda function truy cập vào S3 Bucket, đọc và liệt kê các đối tượng trong bucket.\nThực hành kết nối Lambda với API Gateway, kiểm tra phản hồi dữ liệu động từ S3.\nHiểu được cách quản lý môi trường Python ảo và cài đặt các gói phụ thuộc khi làm việc với CDK.\nNắm được khái niệm Nested Stack và cách chia nhỏ kiến trúc CDK thành các stack con nhằm tối ưu khả năng mở rộng và bảo trì.\nHoàn thành việc triển khai, kiểm tra hoạt động của toàn bộ kiến trúc CDK nâng cao trên AWS.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Nguyễn Gia Phát\nSố điện thoại: 09395100\nEmail: phat10102005@gmail.com\nTrường: Đại học FPT\nNgành: Công nghệ thông tin\nLớp: SE190236\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 12/08/2025 đến ngày 12/11/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://giaphazzz.github.io/aws/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc thân thiện và chuyên nghiệp, không gian ngồi rộng rãi và sạch sẽ. Có một điểm chê các bạn sinh viên nói chung đó là nhiều nhóm bạn tụm lại rồi bàn chuyện quá to, khiến cho bản thân em không tập trung vào công việc được. Ngoài ra thì em cũng mong AWS cho phép sử dụng pantry để lấy nước, do mang theo 1 chai nước mà lỡ uống hết trong giờ làm thì xuống tận tầng trệt ra bên ngoài mua, khá mất thời gian. Còn lại thì tất cả đều ổn hết, không có gì để bình luận thêm.\n2. Sự hỗ trợ của mentor / team admin\nMentor hỗ trợ cho sinh viên khá tốt. Tuy nhiên thì khi lập nhóm chat thì nên có hai nhóm, một nhóm để thông báo và một nhóm để trò chuyện thoải mái. Do đôi lúc có thông báo mà em không xem ngay thì bị tin nhắn của nhiều bạn khác nhắn vào (tán gẫu, hỏi ý kiến diagram, share khóa học, …) làm trôi đi mất. Em cũng cảm ơn các mentor đã hỗ trợ tụi em và còn đóng góp vào các workshop về dịch vụ AWS để tụi em hiểu rõ hơn.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nEm học AI, chuyên về thiết kế thuật toán, xử lý dữ liệu và huấn luyện mô hình. Mà đa số các dịch vụ của AWS đều có sẵn mô hình AL để làm việc (ví dụ như bedrock) rồi, chỉ cần gọi api về dùng thôi chứ không cần nhiều đến lĩnh vực này. Công việc chính cũng chủ yếu liên quan kiến trúc và dịch vụ chứ không chuyên về cải thiện tính năng hay độ chính xác/hiệu quả của model.\nTuy nhiên, mặc dù không giống với chuyên ngành nhưng em đã có được các kiến thức thực tiễn hay mà ở trường không có được. Chẳng hạn như bây giờ ta đã có mô hình và api của nó rồi thì làm sao tích hợp vào phần mềm và ứng dụng cho user dùng, đặc biệt là tích hợp kèm công nghệ cloud vào chung. Các kiến thức này rất quý giá và bổ ích, có thể sẽ hữu dụng trong tương lai khi em đi làm.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nCụ thể hơn về những gì em học được trong quá trình thực tập. Có thể kể đến một vài thứ sau như dùng sagemaker để chạy mô hình dự đoán đường đi của bão, tìm hiểu qua các dịch vụ dùng AI hỗ trợ khác, dùng lamda, s3, ec2, … Điều khá quan trọng là em biết rõ hơn về tính toán chi phí hoạt động cho nhóm khi sử dụng dịch vụ. Ban đều nhóm sử dụng rds, ec2, … khiến chi phí lên tận 58$ một tháng, nhưng khi nhận ra bài toán này có thể dùng serverless architect và chuyển sang dùng s3, lambda thay thế thì chi phí chỉ còn khoảng 18$. Đây có thể gọi là một achivement đáng để tự hào trong quá trình học tập và làm việc kỳ OJT này. Từ đó em nhận ra rằng công việc của IT không chỉ hoàn toàn là kỹ thuật mà còn bao gồm cả bài toán tiết kiệm chi phí cho doanh nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nNói về Company Culture thì mọi thứ khá lạc quan, tích cực. Công việc không quá dồn dập, có nhiều điều mới để học hỏi, bạn bè cùng nhóm làm dự án thì đều hòa đồng và cởi mở. Nhưng (chê sinh viên trường FPT lần hai) kỹ năng giao tiếp của một vài bạn còn kém, nhất là việc thụ động, ít đóng góp ý kiến cho việc phát triễn project. Tuy nhiên, tựu chung lại thì nhóm FCJ thì nhìn chung khá tốt, các bạn có hỗ trợ và chia sẽ những kinh nghiệm cho nhau.\n6. Chính sách / phúc lợi cho thực tập sinh\nViệc AWS cho sinh viên đăng ký chọn ngày phù hợp để lên văn phòng khá hợp lý. Giờ làm việc cũng ổn, từ 9 giờ sáng đến 5 giờ chiều theo tiêu chuẩn thông thường. Ngoài ra còn có các events và workshop cho sinh viên tham dự rất bổ ích và vui.\nMột số câu hỏi khác Gặp được trực tiếp bác Eric Yeo trong Game Days là một điều khiến mình khá ấn tượng. Nhưng thỏa mãn nhất là việc mình biết thêm về tính toán chi phí vận hành dự án sao cho tiết kiệm và hợp lí nhất.\nNhững điểm cần cải thiện thì đã được em đề cập phía trên. Hy vọng trong tương lai AWS sẽ cho các khóa sau được dùng pantry lấy nước lọc uống.\nĐối với sinh viên cùng trường học chuyên ngàng kỹ thuật phần mềm hoặc bảo mật thì tất nhiên mình sẽ đề xuất AWS là nơi thực tập. Với việc các hạ tầng cloud cũng như sự phổ biến của dịch vụ đám mây hiện nay thì đây là nơi rất tốt để có thêm kiến thức, mở rộng cơ hội nghề nghiệp hơn nữa.\nĐề xuất \u0026amp; mong muốn Một vài đề nghị cho các thực tập sinh cải thiện trong tương lai đó là các bạn nên nói chuyện nhỏ lại lúc lên văn phòng và hãy chủ động, cởi mở hơn trong công việc và cuộc sống.\nTất nhiên, FCJ có chữ J là một hành trình. Và hành trình này sẽ không kết thúc kể cả khi kỳ OJT kết thúc!\n"},{"uri":"https://giaphazzz.github.io/aws/vi/4-eventparticipated/4.8-event8/","title":"CLOUDTHINKER","tags":[],"description":"","content":"Bào thu hoạch: “BUILDING AGENTIC AI - Context Optimization with Amazon Bedrock” Mục tiêu Sự kiện Cung cấp cái nhìn có hệ thống về Agentic AI và sự chuyển dịch sang các hệ thống AI tự động Giới thiệu Amazon Bedrock AgentCore và hệ sinh thái agentic của AWS Trình bày thiết kế Agentic Workflow trong các ứng dụng thực tế trên AWS Giới thiệu CloudThinker Agentic Orchestration và các kỹ thuật tối ưu hóa ngữ cảnh Hướng dẫn thực hành xây dựng ứng dụng agentic bằng AWS Bedrock Tạo không gian kết nối với các chuyên gia trong ngành AI và điện toán đám mây Diễn giả Nguyễn Gia Hưng – Head of Solutions Architect, AWS Kiên Nguyễn – Solutions Architect, AWS Việt Phạm – Founder \u0026amp; CEO, Diaflow Thắng Tôn – Co-founder \u0026amp; COO, CloudThinker Henry Bùi – Head of Engineering, *CloudThinker Kha Van – Community Leader, AWS Những điểm nổi bật Sự phát triển của Agentic AI ML/AI truyền thống\nNhiệm vụ cố định, năng lực hạn chế Cần dữ liệu có cấu trúc và xử lý tiền đề phức tạp Khó mở rộng và kém linh hoạt Agentic AI hiện đại\nDựa trên Foundation Models và khả năng suy luận đa bước Tự động phân rã nhiệm vụ và sử dụng công cụ Có thể tích hợp API, thực thi workflow, truy xuất tri thức Linh hoạt và sẵn sàng sản xuất khi kết hợp với các dịch vụ AWS Thách thức khi triển khai Agentic AI vào sản xuất Hiệu năng – độ trễ, suy luận song song, tốc độ xử lý token Khả năng mở rộng – multi-agent, quản lý ngữ cảnh Bảo mật – quản trị dữ liệu, luồng định danh, quyền truy cập Governance – khả năng quan sát, nhật ký, phạm vi nhiệm vụ Bộ dịch vụ Agentic AI của AWS Amazon Bedrock AgentCore – identity, memory, runtime, tools, workflows Agent Gateway – tích hợp API và công cụ thống nhất Tự do lựa chọn mô hình – Anthropic, Meta Llama, Amazon Titan,\u0026hellip; Thiết kế hướng sản xuất – khả năng mở rộng, guardrails, quan sát Amazon Bedrock AgentCore (từ AWS) Runtime – Quản lý luồng thực thi đa bước Memory – Lưu trữ ngữ cảnh ngắn hạn và dài hạn Identity Flow – Kiểm soát quyền và các ranh giới bảo mật Agent Gateway – Kết nối công cụ, API, hệ thống nội bộ Code Interpreter – Môi trường chạy mã an toàn Browser Tool – Thu thập thông tin từ web Observability – Tracing, logs, metrics phục vụ quản trị \u0026amp; giám sát Xây dựng Agentic Workflow trên AWS (Use Case bởi Diaflow) Phối hợp nhiều agent Truy xuất ngữ cảnh và function calling Kết nối agent với các nguồn dữ liệu doanh nghiệp Điều phối logic doanh nghiệp qua Bedrock \u0026amp; công cụ của Diaflow Các mô hình triển khai thực tế cho startup và SME CloudThinker: Orchestration và Tối ưu hoá Ngữ cảnh Chiến lược điều phối giữa các agent Lọc và tối ưu hóa ngữ cảnh giúp giảm chi phí và tăng hiệu quả Thích nghi workflow theo thời gian thực Đánh giá độ tin cậy chain-of-thought Tích hợp CloudThinker vào Bedrock AgentCore CloudThinker Hack: Phiên thực hành Cài đặt Bedrock agents Xây dựng pipeline agentic cơ bản Tích hợp công cụ bên ngoài vào workflow Debug và tối ưu hành vi agent Triển khai một bản proof-of-concept hoàn chỉnh Những điểm rút ra quan trọng Tư duy Agentic AI AI đang dịch chuyển từ phản hồi → hành động Agent cần tích hợp memory, tools, orchestrator, và identity Foundation Models + Orchestration = Thế hệ ứng dụng AI mới AWS cung cấp môi trường sản xuất mạnh nhất cho Agentic AI Hiểu biết kỹ thuật Tầm quan trọng của tối ưu hóa ngữ cảnh Cách tools và identity flow ảnh hưởng đến độ tin cậy Vì sao AgentCore đơn giản hóa reasoning nhiều bước Giá trị thực tế của các mô hình điều phối Kết nối FM với API, logic doanh nghiệp, kho dữ liệu Kỹ năng phát triển thực hành Thiết kế workflow AI end-to-end Kết nối công cụ bên ngoài vào pipeline agent Quản lý tương tác multi-agent Hiểu rõ độ trễ, khả năng mở rộng, bảo mật Triển khai agent an toàn với guardrails \u0026amp; monitoring Ứng dụng vào công việc Người tham gia có thể áp dụng ngay:\nXây dựng assistant dựa trên agent, quy trình tự động hoặc copilots nội bộ Tích hợp mô hình Bedrock vào hệ thống doanh nghiệp Sử dụng AgentCore để tạo workflow nhiều bước có kiểm soát Tăng tốc prototyping mà không cần hạ tầng DevOps phức tạp Kết hợp diễn orchestration của CloudThinker để tối ưu hiệu năng Áp dụng mẫu thiết kế agentic cho startup hoặc dự án doanh nghiệp Trải nghiệm sự kiện Sự kiện “Agentic Build AI – Optimization with Amazon Bedrock” mang lại góc nhìn sâu sắc về phát triển AI hiện đại.\nKiến thức từ chuyên gia Diễn giả từ AWS, CloudThinker, Diaflow chia sẻ kinh nghiệm triển khai thực tế Hướng dẫn rõ ràng về mở rộng sản phẩm GenAI Ví dụ thực tiễn về tự động hóa agent trong doanh nghiệp Trải nghiệm thực hành Xây dựng pipeline agent hoàn chỉnh Hiểu cách memory, identity và tool phối hợp Thành thạo API và công cụ orchestration của Bedrock Cơ hội giao lưu Gặp gỡ kiến trúc sư AWS, kỹ sư, founder và cộng đồng Thảo luận về nghề nghiệp và phát triển AI cloud-native Bài học rút ra Agentic AI là bước tiếp theo sau chatbot và LLM Triển khai thực tế cần identity, scale và quan sát Bedrock + CloudThinker là con đường nhanh nhất đến sản xuất Dự án thực tế mang lại giá trị vượt xa lý thuyết Một số hình ảnh sự kiện Hình 1 Hình 2 Hình 3 Tóm lại, workshop “Agentic Build AI – Optimization with Amazon Bedrock” mang đến sự kết hợp mạnh mẽ giữa kiến thức chiến lược và trải nghiệm thực hành. Người tham gia nắm được kỹ năng triển khai agentic workflow, tối ưu ngữ cảnh, tích hợp công cụ, và xây dựng hệ thống AI có khả năng mở rộng và an toàn.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.8-week8/","title":"Worklog Tuần 8","tags":[],"description":"","content":"Mục tiêu tuần 8: Khám phá các kiến thức về Iac, Vpc flow logs, billing. Hoàn thiện phần thực hành được kèm theo trong các labs. Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Chạy so sánh kết quả của phương pháp STFA đề xuất với cac kỹ thuật khác - Tiến hành đo lường trên nhiều thang đo error metrics bao gồm cả custom error. 27/10/2025 27/10/2025 3 - Tìm hiểu khái niệm và lợi ích của Infrastructure as Code (IaC) trong quản lý hạ tầng tự động. - Phân biệt CloudFormation, CDK, Terraform, Pulumi. - Thực hành thiết lập Cloud9, tạo IAM Role và triển khai Lambda Function bằng CloudFormation. 28/10/2025 28/10/2025 https://000111.awsstudygroup.com/ 4 - Cấu hình và giám sát tài nguyên EC2 bằng Amazon CloudWatch. - Cài đặt CloudWatch Agent, thu thập metric CPU, bộ nhớ, mạng, ổ đĩa. - Áp dụng AWS EC2 Resource Optimization và Compute Optimizer để đề xuất tối ưu chi phí. 29/10/2025 29/10/2025 https://000014.awsstudygroup.com/ 5 - Tìm hiểu VPC Flow Logs và cơ chế giám sát lưu lượng IP trong VPC. - Triển khai hạ tầng giám sát mạng qua CloudFormation. - Phân tích log bằng CloudWatch Log Insights để phát hiện sự cố và tối ưu hiệu suất mạng. 30/10/2025 30/10/2025 https://000105.awsstudygroup.com/ 6 - Thực hành phân quyền truy cập Billing Console cho IAM User. - Tạo IAM Policy tùy chỉnh (BillingViewAccess) và gán cho user/group. - Kiểm tra quyền truy cập Billing Console và dọn dẹp tài nguyên sau thực hành. 31/10/2025 31/10/2025 https://000106.awsstudygroup.com/ Kết quả đạt được tuần 8: A - Infrastructure as Code\nHiểu được khái niệm và lợi ích của Infrastructure as Code (IaC) trong quản lý hạ tầng tự động bằng mã nguồn.\nPhân biệt các framework IaC phổ biến như CloudFormation, CDK, Terraform, Pulumi và hiểu sự khác biệt trong cách triển khai.\nNắm được vai trò của IaC trong DevOps và CI/CD, giúp tăng năng suất và đảm bảo tính nhất quán khi triển khai hạ tầng.\nThực hành thiết lập môi trường Cloud9, tạo IAM Role với quyền AdministratorAccess và gán vào EC2 Instance.\nThực hành sử dụng CloudFormation Template để triển khai Lambda Function và xác nhận kết quả tạo tài nguyên thành công.\nTriển khai mẫu VPC và EC2 bằng CloudFormation, hiểu rõ cấu trúc template gồm Parameters, Mappings, Resources, Outputs.\nKết nối EC2 Instance qua SSM, kiểm tra hoạt động thành công và xác nhận kết nối an toàn không cần mở cổng SSH.\nTìm hiểu mô hình triển khai kiến trúc ba tầng (Three-Tier Architecture) gồm Bastion Host, Web Tier, App Tier và Database Tier trên AWS CloudFormation.\nThực hành tạo Stack, kiểm tra truy cập giữa các tầng, và dọn dẹp tài nguyên sau khi hoàn tất triển khai.\nB - Right-sizing with EC2 Resource Optimization\nNắm vững quy trình thiết lập, cấu hình và giám sát tài nguyên EC2 bằng Amazon CloudWatch để theo dõi hiệu suất thực tế của máy ảo.\nTạo và gán thành công IAM Role cho EC2 nhằm kích hoạt CloudWatch Agent và thu thập đầy đủ các metric như CPU, bộ nhớ, mạng và ổ đĩa.\nCài đặt và cấu hình CloudWatch Agent để bổ sung các chỉ số tùy chỉnh giúp phân tích chính xác hơn.\nÁp dụng AWS EC2 Resource Optimization để xác định các máy chủ hoạt động kém hiệu quả và đề xuất biện pháp giảm chi phí hợp lý.\nHiểu và thực hành các nguyên tắc right-sizing EC2, kết hợp với chiến lược Saving Plans để tối ưu chi phí.\nSử dụng AWS Compute Optimizer để phân tích và nhận đề xuất tối ưu cho EC2, Auto Scaling Group, EBS, Lambda và Fargate dựa trên dữ liệu thực tế.\nNắm được điều kiện và giới hạn của Compute Optimizer khi áp dụng cho các loại tài nguyên khác nhau.\nC - Network Monitoring with VPC Flows Logs\nHiểu rõ cơ chế hoạt động của VPC Flow Logs và cách thu thập thông tin lưu lượng IP giữa các network interfaces trong VPC.\nTạo và triển khai hạ tầng giám sát mạng tự động bằng CloudFormation, bao gồm VPC, subnet, IAM Role và CloudWatch Log Group.\nKích hoạt VPC Flow Logs và cấu hình gửi dữ liệu đến Amazon CloudWatch Logs để theo dõi lưu lượng mạng thời gian thực.\nThực hành phân tích dữ liệu log bằng CloudWatch Log Insights, giúp phát hiện các vấn đề về bảo mật, cấu hình và hiệu suất mạng.\nHoàn thiện quy trình giám sát hạ tầng mạng và hiểu rõ cách áp dụng trong việc tối ưu, kiểm soát, và khắc phục sự cố trong môi trường AWS.\nD - Billing Console Delegation\nBiết đến quy trình phân quyền truy cập Billing Console trong AWS, giúp đảm bảo quản lý tài chính an toàn và tách biệt quyền giữa các tài khoản.\nThực hành kích hoạt quyền truy cập Billing cho IAM Users thông qua mục “IAM User and Role Access to Billing Information” bằng tài khoản root.\nTạo IAM Policy tùy chỉnh (BillingViewAccess) để giới hạn quyền truy cập chỉ trong phạm vi quản lý hóa đơn và chi phí.\nGán policy cho nhóm hoặc người dùng IAM, đảm bảo phân quyền chính xác và có kiểm soát.\nKiểm tra thành công quyền truy cập Billing Console bằng tài khoản IAM được cấp phép.\nHoàn tất việc xóa nhóm người dùng và policy, đảm bảo enviroment sạch sẽ sau khi thực hành.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.9-week9/","title":"Worklog Tuần 9","tags":[],"description":"","content":"Mục tiêu tuần 9: Tìm hiểu các module vể Security Làm quen với AWS single sign-on và security hub Các công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu và chuẩn bị tích hợp mô hình sau khi train với các dịch vụ của AWS 03/11/2025 03/11/2025 3 - Tìm hiểu AWS IAM Identity Center (AWS SSO) + Khái niệm, vai trò và lợi ích + Thiết lập và cấu hình cơ bản 04/11/2025 04/11/2025 https://000121.awsstudygroup.com/ 4 - Thực hành IAM Identity Center + Tạo và gán Permission Set + Cấu hình truy cập đa tài khoản qua portal + Thiết lập Time-based Access Control 05/11/2025 05/11/2025 https://000122.awsstudygroup.com/ 5 - Tìm hiểu IAM Permission Boundaries + Cơ chế hoạt động và mục đích + So sánh với Identity-based Policy 06/11/2025 06/11/2025 https://000123.awsstudygroup.com/ 6 - Access Control with IAM Policies \u0026amp; Conditions - Kích hoạt và cấu hình AWS Security Hub 07/11/2025 15/11/2025 https://000124.awsstudygroup.com/ Kết quả đạt được tuần 9: A - Identity Federation with AWS Single sign-on\nHiểu rõ khái niệm và vai trò của AWS IAM Identity Center (trước đây là AWS Single Sign-On) trong việc quản lý danh tính tập trung và kiểm soát truy cập cho nhiều tài khoản AWS.\nNắm được quy trình thiết lập IAM Identity Center để quản lý quyền truy cập theo nguyên tắc tối thiểu đặc quyền, gán quyền dựa trên nhóm người dùng và vai trò dự án.\nTriển khai thành công AWS Organization và tạo các Organizational Units (Security, Shared Services, Logging, Application) nhằm phân tách và quản lý tài nguyên hiệu quả.\nThực hành tạo và gán Permission Set cho người dùng, cấu hình truy cập đa tài khoản qua AWS IAM Identity Center.\nHiểu và áp dụng Time-based Access Control để giới hạn quyền truy cập theo khung thời gian định trước, phù hợp với vai trò kiểm toán hoặc dự án tạm thời.\nTạo, gán và kiểm tra nhóm người dùng (Groups) và người dùng (Users) trong IAM Identity Center; xác thực khả năng truy cập bằng portal URL và vai trò được chỉ định.\nThực hành truy cập AWS CLI thông qua IAM Identity Center bằng cơ chế xác thực tự động (OIDC), đảm bảo bảo mật và tuân thủ nguyên tắc Zero Trust.\nHiểu cách sử dụng Customer Managed Policies để tái sử dụng các chính sách tùy chỉnh giữa nhiều tài khoản AWS, giúp quản lý quyền linh hoạt và nhất quán.\nTriển khai và kiểm thử các API của Identity Store (IdentityStore API) để tự động hóa việc tạo, cập nhật và kiểm tra người dùng, nhóm, và quan hệ thành viên.\nHoàn thiện quy trình kiểm toán người dùng và nhóm bằng các lệnh CLI, đảm bảo quyền truy cập được cấp phát đúng phạm vi và đúng thời gian, duy trì tuân thủ bảo mật.\nB - Permission Managemnet with IAM Permisson Boundaries\nNắm được khái niệm và mục đích của IAM Permission Boundary trong việc giới hạn phạm vi tối đa quyền của người dùng hoặc nhóm người dùng.\nHiểu được cơ chế hoạt động của Permission Boundary — quyền hiệu lực là phần giao giữa chính sách người dùng (Identity-based Policy) và chính sách giới hạn (Permission Boundary).\nThực hành tạo Restriction Policy chỉ cho phép thao tác với dịch vụ EC2 trong vùng ap-southeast-1 (Singapore).\nTạo IAM user “ec2-admin” và gán quyền AmazonEC2FullAccess cùng Permission Boundary “ec2-admin-restrict-region”.\nKiểm tra và xác nhận người dùng “ec2-admin” chỉ có thể tạo và quản lý EC2 tại Singapore, không thể thao tác ở các vùng khác như Sydney.\nHiểu được lợi ích của Permission Boundary trong việc ngăn chặn privilege escalation và đơn giản hóa quản lý quyền trên quy mô lớn.\nThực hiện quy trình cleanup — xóa user và policy sau khi kiểm thử để đảm bảo môi trường sạch và an toàn.\nC - Access control with IAM Policies and Conditions\nHiểu và áp dụng nguyên tắc least privilege khi cấp quyền cho người dùng, đảm bảo chỉ truy cập đủ phạm vi cần thiết.\nNắm rõ khái niệm và quy trình Assume Role, cách IAM User lấy temporary credentials thông qua AWS STS.\nThực hành tạo IAM Group với quyền quản trị cho EC2 và RDS, giúp quản lý người dùng tập trung và an toàn hơn.\nTạo các IAM User có quyền khác nhau (EC2-admin-user, RDS-admin-user, Group-user, No-permission-user) để mô phỏng nhiều tình huống truy cập thực tế.\nCấu hình IAM Role có quyền Admin và thiết lập Trust Relationship cho phép các IAM User thực hiện Assume Role.\nThiết lập Condition trong IAM Role để giới hạn truy cập theo địa chỉ IP hoặc thời gian, nâng cao tính bảo mật và kiểm soát chi tiết quyền truy cập.\nXác minh thành công việc switch role của người dùng theo điều kiện đặt ra và dọn dẹp tài nguyên sau khi hoàn tất.\nD - AWS Security Hub\nHiểu được vai trò của AWS Security Hub trong việc tổng hợp, tổ chức và ưu tiên các cảnh báo bảo mật từ nhiều dịch vụ AWS như GuardDuty, Inspector và Macie.\nNắm được cơ chế hoạt động của Security Hub trong việc hiển thị rủi ro qua bảng điều khiển trực quan, giúp dễ dàng theo dõi tình trạng bảo mật và tuân thủ.\nBiết cách kích hoạt Security Hub trên AWS Management Console và lựa chọn các bộ tiêu chuẩn bảo mật như AWS Foundational Security Best Practices, CIS AWS Foundations Benchmark và PCI DSS.\nTheo dõi và đánh giá điểm Security Score của tài khoản AWS dựa trên từng bộ tiêu chuẩn, từ đó xác định các rủi ro và điểm yếu bảo mật cần khắc phục.\nHiểu mối quan hệ giữa Security Hub và AWS Config, biết cách bật AWS Config để ghi lại toàn bộ tài nguyên cần thiết cho việc đánh giá tuân thủ.\nThực hành loại bỏ các tiêu chí đánh giá không phù hợp, đồng thời quản lý việc kích hoạt hoặc vô hiệu hóa từng tiêu chuẩn bảo mật theo nhu cầu thực tế.\nHoàn thiện việc theo dõi, đánh giá và tối ưu mức độ an toàn của tài khoản AWS dựa trên các tiêu chuẩn bảo mật được áp dụng.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.10-week10/","title":"Worklog Tuần 10","tags":[],"description":"","content":"Mục tiêu tuần 10: Hiểu quy trình container hóa ứng dụng với Docker và triển khai trên AWS Cloud. Làm quen với ECS, CDK và CodePipeline để tự động hóa triển khai hạ tầng và ứng dụng. Các công việc cần triển khai trong tuần này Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu khái niệm container và Docker + Docker Engine, Dockerfile, Docker Image, Container 10/11/2025 10/11/2025 https://000201.awsstudygroup.com/ 3 - Tìm hiểu cách push/pull image lên Docker Hub và Amazon ECR - Cấu hình VPC, EC2, RDS để triển khai ứng dụng container hóa trên môi trường AWS 11/11/2025 11/11/2025 https://000202.awsstudygroup.com/ 4 - Tìm hiểu Amazon ECS và các launch type (Fargate, EC2) + Cấu hình ECS Cluster, Task Definition, Service + Triển khai frontend và backend trên ECS 12/11/2025 12/11/2025 https://000203.awsstudygroup.com/ 5 - Triển khai ECS bằng AWS CDK (IaC) + Tạo VPC, NAT Gateway, ECS Cluster bằng CDK + Xây dựng ECS Service và kết nối DynamoDB, API Gateway 13/11/2025 13/11/2025 https://000204.awsstudygroup.com/ 6 - Thiết lập CI/CD pipeline với CodePipeline, CodeBuild, CodeDeploy + Tạo repository và build pipeline từ GitHub hoặc CodeCommit + Tự động build và deploy ứng dụng lên ECS Fargate hoặc EC2 14/11/2025 15/11/2025 https://000205.awsstudygroup.com/ Bạn có muốn mình thêm phần “Kết quả đạt được tuần này” tương tự như các tuần trước (tổng hợp tóm tắt các nội dung chính đã hoàn thành) để khớp định dạng báo cáo tuần không?\nKết quả đạt được tuần 10: A - Containerization with Docker\nHiểu toàn bộ quy trình triển khai ứng dụng container hóa với Docker từ môi trường local đến AWS Cloud.\nCấu hình và vận hành thành công các dịch vụ AWS như VPC, EC2, RDS và ECR phục vụ cho triển khai ứng dụng.\nThực hành triển khai ứng dụng bằng Docker Image, so sánh hiệu quả giữa triển khai thủ công và Docker Compose.\nXây dựng và quản lý mạng lưới container giúp frontend, backend và cơ sở dữ liệu giao tiếp ổn định.\nĐẩy và quản lý image trên Docker Hub và Amazon ECR, phục vụ cho tái sử dụng và triển khai tự động.\nHiểu rõ vai trò của Nginx trong điều phối luồng truy cập và cân bằng tải giữa các container.\nTối ưu hóa quy trình phát triển và triển khai thông qua việc tách biệt môi trường phát triển và sản xuất.\nNâng cao kỹ năng xử lý sự cố và kiểm tra hoạt động ứng dụng trên môi trường đám mây.\nB - Container Orchestration with Amazon ECS\nNắm vững quy trình triển khai ứng dụng container hóa trên Amazon ECS với cả hai loại launch type: Fargate và EC2.\nTạo và cấu hình thành công ECS Cluster, Task Definition cho frontend và backend, giúp dịch vụ hoạt động ổn định và tách biệt rõ ràng.\nỨng dụng kiến thức về Service Discovery trong AWS Cloud Map để kết nối các container nội bộ thông qua DNS name.\nThiết lập thành công Application Load Balancer, Target Group và Listener, đảm bảo cân bằng tải và khả năng mở rộng cho ứng dụng.\nThực hành triển khai dịch vụ backend với mô hình Blue/Green Deployment, đảm bảo quá trình cập nhật không gián đoạn.\nThực hiện Rolling Deployment cho frontend, giúp cập nhật phiên bản liên tục mà không gây downtime.\nQuản lý và giám sát container thông qua ECS Console và CloudWatch Logs, hiểu rõ hoạt động của từng tác vụ trong cluster.\nKiểm thử và xác nhận ứng dụng hoạt động trơn tru trên ECS, từ giao diện frontend đến xử lý backend và kết nối cơ sở dữ liệu.\nTối ưu hóa quy trình CI/CD bằng việc tích hợp ECR, ECS và CodeDeploy, tạo nền tảng tự động hóa triển khai cho các dự án tương lai.\nC - Infrastructure as Code for ECS with CDK\nHiểu rõ quy trình triển khai ứng dụng Spring Boot trên AWS ECS Fargate bằng cách sử dụng AWS CDK.\nNắm được nguyên lý hạ tầng như Infrastructure as Code (IaC) và lợi ích khi sử dụng AWS CDK v2 để tự động hoá việc tạo tài nguyên.\nTạo và cấu hình thành công Amazon ECR Repository để lưu trữ Docker images.\nTriển khai VPC và NAT Gateway bằng AWS CDK, thiết lập môi trường mạng an toàn và cô lập cho ứng dụng.\nXây dựng ECS Cluster, định nghĩa Task và ECS Service cho microservice backend.\nTạo API Gateway để quản lý endpoint REST, kết nối trực tiếp với ECS Service.\nThiết kế và triển khai DynamoDB Table để lưu trữ dữ liệu sản phẩm, sử dụng SDK v2 cho Java.\nThực hiện logging ứng dụng qua CloudWatch Logs và cấu hình AWS X-Ray để theo dõi và phân tích luồng truy cập.\nNâng cao kỹ năng quản lý, cấu hình và triển khai hạ tầng AWS một cách tự động, đồng bộ và có thể tái sử dụng.\nD - CI/CD Pipeline with AWS CodePipeline\nHiểu rõ khái niệm và quy trình hoạt động của CI/CD (Continuous Integration/Continuous Deployment) trong triển khai ứng dụng container trên AWS ECS.\nThiết lập và cấu hình thành công pipeline CI/CD sử dụng GitLab, GitHub Actions và AWS CodeBuild kết hợp với ECR, ECS, và CodeDeploy.\nTự động hoá toàn bộ quy trình build, test, và deploy ứng dụng từ source code lên môi trường ECS Fargate.\nBiết cách tạo và quản lý GitLab Runner, định nghĩa pipeline thông qua file cấu hình .gitlab-ci.yml và .github/workflows.\nTích hợp thành công các dịch vụ AWS trong pipeline bao gồm CodeBuild, CodePipeline và CodeDeploy để triển khai ứng dụng liền mạch.\nSử dụng CloudWatch Container Insights để giám sát hoạt động của container, theo dõi CPU, memory, network, và trạng thái các ECS tasks.\nCấu hình FireLens trong ECS để thu thập và định tuyến log từ container đến Amazon S3, giúp dễ dàng phân tích và theo dõi hoạt động của ứng dụng.\nThực hành quản lý log, phát hiện sự cố và tối ưu hiệu năng ứng dụng thông qua CloudWatch và FireLens.\nHoàn thành quy trình dọn dẹp tài nguyên AWS (ECS, ECR, RDS, EC2, IAM, S3, VPC, NAT Gateway) để đảm bảo môi trường sạch và tối ưu chi phí.\nCủng cố kiến thức DevOps, đặc biệt trong việc triển khai CI/CD hiện đại trên môi trường cloud-native với AWS.\nE - Automated Deployments with AWS CodePipeline\nHiểu được quy trình triển khai ứng dụng lên EC2 thông qua chuỗi CI/CD tự động hóa với AWS CodePipeline.\nNắm được vai trò và cách phối hợp của các dịch vụ trong pipeline gồm CodeCommit, CodeBuild, CodeDeploy, và CodePipeline.\nTạo thành công S3 bucket để lưu trữ artifact của quá trình build và deploy.\nCài đặt và cấu hình CodeDeploy Agent trên EC2 thông qua Session Manager hoặc User Data.\nThực hành tạo repository trên CodeCommit (hoặc GitHub thay thế) và thực hiện quy trình clone, mirror, và migrate mã nguồn.\nThiết lập dự án build với AWS CodeBuild, cấu hình source từ GitHub, thiết lập môi trường Linux, và tạo artifact đầu ra lưu vào S3.\nTạo ứng dụng và Deployment Group trong AWS CodeDeploy, cấu hình loại triển khai In-place và nhóm EC2 theo tag để tự động triển khai.\nThực hiện triển khai ứng dụng Node.js thành công lên EC2 thông qua CodeDeploy, xác minh hoạt động qua DNS của instance.\nThiết lập CodePipeline hoàn chỉnh với các giai đoạn Source – Build – Deploy, giúp tự động hóa quy trình khi có thay đổi mã nguồn.\nKiểm thử pipeline bằng cách chỉnh sửa mã trong repository, commit thay đổi và quan sát pipeline tự động thực thi toàn bộ quá trình build và deploy.\nHiểu được quy trình CI/CD khép kín trên AWS: từ commit mã nguồn đến build, test, deploy và xác minh kết quả triển khai thực tế.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.11-week11/","title":"Worklog Tuần 11","tags":[],"description":"","content":"Mục tiêu tuần 11: Làm quen với các dịch vụ AWS serverless Trải nghiệm thực hành qua AWS SAM, Cognito, \u0026hellip; Các công việc cần triển khai trong tuần này: Dưới đây là phiên bản ngắn gọn, tập trung ý chính cho tuần từ thứ 2 đến thứ 6, dựa trên nội dung bạn cung cấp:\nThứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Tìm hiểu cách deploy ứng dụng Java SpringBoot Monolith TravelBuddy trên AWS 17/11/2025 17/11/2025 https://000050.awsstudygroup.com/ 3 - Tạo CloudFormation stack, Key Pair, RDS MySQL - Import project TravelBuddy vào Eclipse và chạy thử local 18/11/2025 18/11/2025 https://000052.awsstudygroup.com/ 4 - Tìm hiểu Lambda và serverless microservices - Tạo Lambda function Java, test cục bộ và upload lên AWS - Kết nối Lambda với S3 trigger 19/11/2025 19/11/2025 https://000078.awsstudygroup.com/ 5 - Triển khai Node.js Lambda function xử lý S3 và DynamoDB - Cấu hình với IAM role, memory, timeout, environment 20/11/2025 20/11/2025 https://000080.awsstudygroup.com/ 6 - Triển khai SAM project, tạo API Gateway và Lambda functions - Cấu hình front-end với REST API trên S3 - Tạo User Pool Cognito, authentication flow và kiểm tra đăng ký/đăng nhập 21/11/2025 21/11/2025 https://000081.awsstudygroup.com/ Kết quả đạt được tuần 11: A - Monolith to Microservices Migration\nTìm hiểu cách triển khai ứng dụng Java Springboot TravelBuddy trên AWS.\nSử dụng CloudFormation để provision và xác minh các tài nguyên AWS.\nDùng AWS Tools for Eclipse và Elastic Beanstalk CLI để deploy và cập nhật ứng dụng.\nSử dụng AWS SDK để query và thao tác tài nguyên AWS thông qua code.\nChuẩn bị môi trường trước khi deploy:\nTạo Key Pair để truy cập instance Tạo CloudFormation stack Kết nối tới Windows Instance Thiết lập cơ sở dữ liệu MySQL trên RDS Download project TravelBuddy Test project trên Eclipse IDE:\nImport dự án Maven vào Eclipse Cấu hình biến môi trường để kết nối RDS (JDBC_CONNECTION_STRING, JDBC_UID, JDBC_PWD) Tạo Tomcat server nội bộ để chạy ứng dụng Chạy thử ứng dụng và kiểm tra dữ liệu từ RDS Deploy ứng dụng lên Elastic Beanstalk:\nExport WAR file từ Eclipse Tạo Elastic Beanstalk Application và Environment Cấu hình môi trường: High availability, VPC, Load Balancer, Subnet, Security Groups, Instance type, EC2 Key Pair Thiết lập biến môi trường Elastic Beanstalk tương ứng với RDS Deploy WAR file và truy cập ứng dụng từ URL Elastic Beanstalk Cập nhật ứng dụng (Update Application):\nSửa nội dung trong index.jsp Build WAR file mới bằng Maven (mvn package) Sử dụng Elastic Beanstalk CLI (eb init + eb deploy) để cập nhật ứng dụng Xác nhận thay đổi hiển thị trên website Query API và thao tác AWS bằng Eclipse IDE:\nImport EC2Report Maven project Sửa EC2Manager.java để truy vấn đúng region Chạy JUnit Test để lấy thông tin EC2 instances Thực hành đọc Tags, thông tin instance, và tạo instance mới bằng AWS SDK Có khả năng quản lý toàn bộ quy trình từ local development, build, deploy tới quản lý và query tài nguyên AWS.\nB - Building Microservices\nHiểu được cách tạo và triển khai microservice serverless trên AWS sử dụng Lambda.\nChuẩn bị môi trường và cấu hình Eclipse IDE để phát triển Lambda function.\nTạo microservice Lambda và test cục bộ:\nTạo project Lambda Java trong Eclipse Cập nhật pom.xml để sử dụng phiên bản Mockito mới Chạy JUnit Test với payload JSON giả lập sự kiện S3 Xử lý các key URL-encoded trong LambdaFunctionHandler Upload và test Lambda function trên AWS Lambda:\nTạo Lambda function mới với tên TestLambda Upload code từ Eclipse và chọn IAM role LambdaRole Kết nối Lambda function với S3 bucket để trigger tự động Mở rộng serverless microservices:\nTạo Lambda ImageManager để tự động tạo thumbnail cho file ảnh JPG và xóa file khác Sử dụng AWS SAM và CloudFormation để tự động triển khai Lambda, trigger và S3 bucket (Optional) Cập nhật quyền cho Lambda nếu cần Cấu hình orchestration với CodeStar:\nTạo branch mới và quản lý CI/CD pipeline Redeploy microservice khi có cập nhật code Cập nhật target region cho API Optional Advanced Exercise:\nTạo Lambda function xử lý các loại file khác nhau, ví dụ chuyển file không hợp lệ sang thư mục khác Tạo S3 trigger gọi Lambda function để xử lý ảnh khi upload Triển khai và cấu hình Lambda function tự động Tạo microservice kết nối với RDS trong VPC Triển khai microservices bằng AWS Developer Tools và CI/CD automation C - Serverless Backend with Lambda, S3, and DynamoDB\nThực hành làm quen với serverless architecture và AWS Lambda. Tạo Lambda function xử lý sự kiện từ S3 để resize và quản lý hình ảnh. Cấu hình S3 bucket nguồn và đích, thiết lập event notification. Thiết lập IAM role và policy để Lambda truy cập S3 với nguyên tắc least privilege. Cài đặt memory, timeout, và môi trường biến cho Lambda function. Thực hành triển khai Node.js Lambda function, kiểm tra pipeline xử lý hình ảnh, logging và CloudWatch monitoring. Tạo bảng DynamoDB và thiết lập write capacity phù hợp. Tạo Lambda function bằng Python để ghi dữ liệu vào DynamoDB. Cấu hình function settings: runtime Python 3.11, function name book_create. Viết code Lambda để nhận dữ liệu từ event[\u0026ldquo;body\u0026rdquo;] và ghi vào bảng Books, xử lý lỗi và trả response HTTP. Triển khai và deploy Lambda function, kiểm tra hoạt động ghi dữ liệu. Cấu hình permission: gán IAM role cho Lambda để truy cập DynamoDB. Áp dụng best practices serverless: error handling, logging, least privilege, throughput management. D - Deployment Automation with AWS SAM\nCài đặt SAM CLI và cấu hình AWS credentials cho người dùng sam-admin.\nTạo project SAM mẫu bằng lệnh sam init và chọn các tuỳ chọn cơ bản.\nTạo S3 bucket front-end với Static Web Hosting và chính sách truy cập công khai bằng SAM template.\nXây dựng, validate và deploy SAM application bằng lệnh sam build, sam validate và sam deploy \u0026ndash;guided.\nTạo bảng DynamoDB phục vụ lưu trữ dữ liệu sách.\nTạo và triển khai Lambda function bằng Python:\nListing data từ DynamoDB Writing data vào DynamoDB Deleting data từ DynamoDB Resizing ảnh và quản lý object trong S3 Cấu hình API Gateway với GET, POST, DELETE API để tương tác với Lambda functions.\nThử nghiệm APIs bằng Postman:\nKiểm tra listing API trả dữ liệu từ bảng Books Kiểm tra writing API tạo mới item và upload ảnh vào S3 Kiểm tra deleting API xoá dữ liệu và ảnh tương ứng Kết nối front-end với REST API:\nCập nhật APP_API_URL và isAdmin trong config.js và App.js Build front-end, upload lên S3 và kiểm tra ứng dụng hiển thị thông tin sách Thử writing và deleting dữ liệu trực tiếp từ front-end E - User Authentication with Amazon Cognito\nTiến hành tham khảo tài liệu, cài đặt và cấu hình SAM CLI, AWS CLI, AWS credentials để chuẩn bị môi trường.\nTải và build front-end từ repository FCJ-Serverless-Workshop, upload build folder lên S3 bucket fcj-book-shop-by-myself.\nTạo User Pool trên Amazon Cognito:\nChọn Traditional web application và email làm tuỳ chọn xác thực Tạo App client cognito-fcj-book-shop, lưu lại Client ID và Client Secret Bật Authentication flow ALLOW_USER_PASSWORD_AUTH Cập nhật template.yaml với Cognito Client ID và Secret, triển khai Lambda function phục vụ đăng ký và đăng nhập.\nTạo Registration function trên SAM bằng tham số registerPathPart và thêm vào template.yaml.\nDeploy Lambda function và API Gateway:\nBuild, validate và deploy SAM project Lấy Invoke URL của API Gateway để kết nối với front-end Kiểm tra front-end:\nThay APP_API_URL trong config.js bằng Invoke URL Build và upload front-end lên S3 Thực hiện đăng ký người dùng, xác nhận email Thực hiện đăng nhập, kiểm tra các tính năng: Create new book, Management, Order hiển thị đúng theo quyền truy cập Hoàn thiện authentication flow với Cognito, Lambda và API Gateway, đảm bảo người dùng chỉ sử dụng tính năng khi đã đăng nhập.\n"},{"uri":"https://giaphazzz.github.io/aws/vi/1-worklog/1.12-week12/","title":"Worklog Tuần 12","tags":[],"description":"","content":"Mục tiêu tuần 12: Hiểu khái niệm Data Lake và các thành phần cơ bản trên AWS (S3, Glue, Athena, QuickSight)\nThực hành ingest, xử lý, truy vấn và trực quan hóa dữ liệu trên AWS\nLàm quen với serverless analytics và machine learning workflow bằng SageMaker\nCác công việc cần triển khai trong tuần này: Thứ Công việc Ngày bắt đầu Ngày hoàn thành Nguồn tài liệu 2 - Đọc về giới thiệu Data Lake trên AWS 24/11/2025 24/11/2025 https://000035.awsstudygroup.com/ 3 - Truy vấn dữ liệu bằng Athena - Thực hành thống kê, phân tích dữ liệu 25/11/2025 25/11/2025 https://000070.awsstudygroup.com/ 4 - Trực quan hóa dữ liệu bằng QuickSight - Tạo Dataset, Visual, Analysis, Dashboard cơ bản - Chia sẻ Dashboard với người dùng khác 26/11/2025 26/11/2025 https://000073.awsstudygroup.com/ 5 - Thực hành Athena Spark cho ETL và xử lý dữ liệu - Tạo federated query kết nối nhiều nguồn - Theo dõi session, DPU, lịch sử notebook 27/11/2025 27/11/2025 https://000106.awsstudygroup.com/ 6 - Làm quen SageMaker Studio và Feature Store - Feature engineering với Data Wrangler 28/11/2025 28/11/2025 https://000200.awsstudygroup.com/ Kết quả đạt được tuần 12: A - Data Lake Fundamentals on AWS\nHiểu về Data Lake và nắm được các thành phần cơ bản:\nAmazon S3 để lưu trữ dữ liệu AWS Glue để quản lý dữ liệu và ETL Amazon Athena để truy vấn dữ liệu Amazon QuickSight để trực quan hóa dữ liệu Tạo IAM role cho AWS Glue và attach chính sách cần thiết.\nTạo S3 bucket để lưu trữ dữ liệu và thiết lập Delivery Stream để thu thập dữ liệu.\nTạo dữ liệu mẫu để thử nghiệm quy trình ingest và phân tích dữ liệu.\nSử dụng AWS Glue Crawler để ingest dữ liệu từ S3 vào Data Catalog:\nTạo Crawler summitcrawler Tạo database summitdb Chạy Crawler và kiểm tra bảng dữ liệu raw đã xuất hiện Sử dụng Amazon Athena để truy vấn dữ liệu:\nChạy các câu lệnh SQL kiểm tra dữ liệu Thực hiện các truy vấn thống kê, ví dụ đếm số lượng theo activity_type Tạo và sử dụng SageMaker Notebook để xử lý và biến đổi dữ liệu:\nKhởi tạo Interactive Session Chạy code Python để làm sạch, biến đổi và phân tích dữ liệu Sử dụng Amazon QuickSight để trực quan hóa dữ liệu:\nTạo Data source và Dataset từ S3/Athena Tạo Visual, Analysis và Dashboard Chia sẻ Dashboard với người dùng khác Có khả năng triển khai một quy trình Data Lake trên AWS, từ thu thập, ingest, xử lý, truy vấn đến trực quan hóa dữ liệu.\nB - Building a Data Lake with Your Own Data\nKhám phá cách xây dựng Data Lake serverless trên AWS và nắm được các thành phần cơ bản:\nAmazon S3 để lưu trữ dữ liệu gốc và dữ liệu đã xử lý AWS Glue DataBrew để chuẩn hóa, làm sạch và biến đổi dữ liệu AWS Glue Crawler và Jobs để tạo Data Catalog và chuyển đổi dữ liệu sang định dạng Parquet Amazon Athena để truy vấn dữ liệu bằng SQL Amazon QuickSight để trực quan hóa dữ liệu Sử dụng Glue DataBrew để chuẩn hóa và biến đổi dữ liệu:\nData profiling, clean \u0026amp; transform Chuẩn bị dataset tiếp theo Upload dữ liệu đã xử lý sang S3 khác Thiết lập AWS Glue cho quy trình ingest dữ liệu:\nTạo IAM Role với quyền cần thiết Tạo Data Catalog với Glue Crawler Chạy Glue Jobs để chuyển dữ liệu CSV sang Parquet Tạo Data Catalog mới cho dữ liệu Parquet Kiểm tra schema dữ liệu chuẩn bị cho Athena Truy vấn dữ liệu với Amazon Athena:\nThực hiện các truy vấn cơ bản và nâng cao (join, partition, view) So sánh dữ liệu theo columnar vs row-based Trực quan hóa dữ liệu với Amazon QuickSight:\nĐăng ký và cấu hình quyền truy cập Kết nối dataset và chỉnh sửa dữ liệu Tạo Visual, Analysis và Dashboard để trình bày dữ liệu Thực hiện cleanup các tài nguyên sau workshop:\nHủy đăng ký QuickSight và xóa IAM Roles liên quan Xóa Workflows, Jobs, Crawlers và Databases trên AWS Glue Empty và xóa các S3 bucket Xóa Cloud9 instance C - Business Intelligence with Amazon QuickSight\nTham khảo cách sử dụng Amazon QuickSight để xây dựng dashboard và trực quan hóa dữ liệu:\nNắm các khái niệm cơ bản: Data source, Dataset, Analysis, Visual, Dashboard Biết cách kết nối dữ liệu từ S3, Athena hoặc các nguồn khác Chuẩn bị môi trường QuickSight:\nTạo tài khoản QuickSight Enterprise Kết nối và đăng ký dữ liệu mẫu (sales.csv) Thiết lập quyền truy cập và vùng hoạt động (Region Singapore) Xây dựng dashboard cơ bản:\nCập nhật Dataset Tạo Line Chart, Pie Chart, Pivot Table và thống kê quan trọng Hoàn thiện dashboard hiển thị tổng hợp thông tin Cải tiến dashboard:\nSử dụng Sheets để tổ chức các trang thông tin Áp dụng Theme để tùy chỉnh màu sắc, font chữ, khoảng cách hiển thị Cấu hình định dạng trường (Field format) và định dạng trực quan (Visual format) cho từng chart Thêm chi tiết bảng dữ liệu và biểu đồ phụ để nâng cao trực quan hóa Tạo dashboard tương tác:\nLưu bản backup của dashboard Thiết lập filter layers và navigation action để dashboard có thể tương tác Xuất bản dashboard và chia sẻ với các người dùng khác D - Serverless Analytics with Amazon Athena\nTìm hiểu tổng quan về Amazon Athena và các tính năng chính:\nAthena là dịch vụ phân tích tương tác serverless, hỗ trợ SQL và Python để truy vấn dữ liệu trực tiếp trên S3 hoặc các nguồn dữ liệu khác. Hỗ trợ nhiều nguồn dữ liệu: S3, RDS, Redshift, on-premises, và các dịch vụ đám mây khác. Tích hợp sẵn với AWS Glue Data Catalog để quản lý metadata và schema. Chuẩn bị môi trường và quyền truy cập:\nTạo IAM Role cho Glue, CloudFormation và Athena Spark workgroup. Sử dụng CloudFormation để triển khai các tài nguyên cần thiết nhanh chóng. Sử dụng Amazon Athena for Apache Spark:\nTạo Workgroup sử dụng Spark engine. Tạo Notebook, chạy các phép tính, sử dụng CloudWatch Logs để giám sát và debug. Tương tác với dữ liệu từ Glue Data Catalog, S3 và các nguồn dữ liệu khác. Thực hiện ETL, chuẩn hóa dữ liệu và lưu kết quả vào S3. Trực quan hóa dữ liệu trong Athena Spark:\nSử dụng Matplotlib và Seaborn để tạo biểu đồ thống kê, phân tích dữ liệu và xuất báo cáo. Tích hợp Python libraries bổ sung vào Athena Spark qua pip và S3 để mở rộng khả năng phân tích. Quản lý phiên (Session) và Workgroup:\nTheo dõi chi tiết phiên, lịch sử tính toán, DPU sử dụng, trạng thái thực thi, và kết quả của các notebook. Sử dụng Workgroup để quản lý các Notebook, Session và các phép tính liên quan. Athena Federation:\nThực hiện truy vấn liên kết (federated query) trên nhiều nguồn dữ liệu khác nhau bằng SQL quen thuộc. Hỗ trợ các connector cho RDS, MySQL, PostgreSQL, Redshift. Kết hợp dữ liệu từ nhiều nguồn, lưu kết quả về S3 để tiếp tục phân tích. Tạo Lambda function và VPC endpoint để kết nối dữ liệu federated. E - Machine Learning with Amazon SageMaker\nBiết được các kiến thức về Amazon SageMaker Immersion Day:\nGiúp học viên nắm từ đầu đến cuối quá trình xây dựng workflow ML: feature engineering, train, tune, deploy model ML. Hướng dẫn chuyển workload ML từ môi trường truyền thống sang SageMaker. Cung cấp kiến thức cơ bản về Model Debugging, Model Monitoring, AutoML và đánh giá workload theo AWS ML Well-Architected lens. Chuẩn bị môi trường SageMaker:\nTạo Amazon SageMaker Studio, chọn region Singapore. Tạo user sagemakeruser và role Execution role mặc định. Khởi tạo Notebook Python 3 đầu tiên và mở SageMaker Studio. Tải GitHub repo amazon-sagemaker-immersion-day về Studio. Feature Engineering với Data Wrangler:\nImport dataset bank-additional-full.csv từ S3. Khám phá dữ liệu, xác định kiểu dữ liệu, tạo phân tích summary. Phân tích tương quan giữa các feature và biến mục tiêu y. Sử dụng SageMaker Feature Store:\nLưu trữ các feature đã được chuẩn hóa để dùng chung trong team và cho training/inference. Theo dõi metadata và versioning của các feature. Export feature sang Feature Store offline để chuẩn bị dữ liệu train. Export dữ liệu sang S3:\nTruy xuất dữ liệu từ Feature Store vào Pandas DataFrame. Chia dữ liệu thành train, test, validation. Chuyển đổi dữ liệu về định dạng CSV/libSVM phù hợp với thuật toán XGBoost. Upload dữ liệu lên S3 để chuẩn bị cho bước train. Train, Tune và Deploy XGBoost:\nSử dụng thuật toán XGBoost tích hợp sẵn trên SageMaker. Thực hiện training, hyperparameter tuning tự động. Deploy model vào endpoint và đánh giá hiệu suất. "},{"uri":"https://giaphazzz.github.io/aws/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://giaphazzz.github.io/aws/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]